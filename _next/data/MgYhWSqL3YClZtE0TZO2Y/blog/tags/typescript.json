{"pageProps":{"tag":"typescript","postsForTag":[{"title":"Next.js Tag Pages","slug":"nextjs-tag-pages","date":"March 25, 2024","hero":"/images/posts/tag-page-screenshot.png","excerpt":"My goal with this project was to make the tags I'm already displaying alongside articles to be clickable links that filter my posts by that tag. Try to click one!","tags":["nextjs","javascript","typescript","webdev","static-site-generators"],"id":19,"readTimeInMinutes":6,"content":"This article was written around July 2023.\n\nIf you'd like to learn how to deploy a static site using Next.js to GitHub Pages, [check out a previous article of mine on the topic](https://superflux.dev/blog/github-pages-using-nextjs).\n\nThis functionality for my website was heavily inspired by [Bionic Julia's post on the same topic](https://dev.to/bionicjulia/creating-dynamic-tag-pages-with-nextjs-nested-routes-nah).\n\n![black next js logo on a plain white background](next-js-logo.png)\n\n## Tl;dr\n- [Goal](#goal): To make tag pages that filter my articles by a tag\n- [Get tags from posts](#get-tags-from-posts): First step is to collate all the unique tags from my markdown article files.\n- [Build the pages for tags](#build-the-pages-for-tags)\n\t- [getStaticPaths](#getstaticpaths): Get the unique list of tags to build the routes for.\n\t- [getStaticProps](#getstaticprops): For each tag, get the filtered list of posts.\n\t- [Tags page template](#tags-page-template): Render the filtered list of posts on a new page.\n- [Link to tag pages](#link-to-tag-pages): I altered my hashtag component to link to the appropriate tag route.\n- [Small gotcha](#small-gotcha): Need to strip some character from tags since they need to be URL safe now.\n- [Conclusion](#conclusion)\n- [Resources](#resources)\n\n## Goal\n\nMy goal with this project was to make the tags I'm already displaying alongside articles to be clickable links that filter my posts by that tag.\n\nMy markdown posts already contain metadata that includes tags, so luckily I don't need to go back and tag all my posts.\n\n## Get tags from posts\n\nThe first step is to get a list of the tags from our posts. This is so we can build the pages for each.\n\nI built a function to read the tags from all my post markdown files. The tags are contained in their frontmatter. I use a `Set` to only get the unique tags with no duplicates.\n\n```tsx\nimport { PostData } from \"../dtos/PostData\";\n\nexport const getTagsFromPostDataList = (postData: PostData[]): string[] => {\n  const tags = new Set<string>(); // Set forces only unique tags\n  postData.forEach(function (postDatum) {\n    postDatum.tags.forEach(function (tag) {\n      tags.add(tag);\n    });\n  }); \n  return Array.from(tags);\n}\n```\n\nAnd I get the posts using an existing method that reads the posts from the files system, and parses the markdown and frontmatter from them into a list of custom `PostData` objects.\n\n```tsx\nimport matter from \"gray-matter\";\nimport fs from \"fs\";\nimport path from \"path\";\nimport { PostData } from \"../dtos/PostData\";\nimport { calculateReadTimeOfText } from \"./textUtils\";\n\nexport const getPostData = (): PostData[] => {\n  const files = fs.readdirSync(path.join(\"posts\"));\n  const postDataList: PostData[] = files.map((filename) => {\n    const slug = filename.replace(\".md\", \"\");\n    const markdownWithMeta = fs.readFileSync(\n      path.join(\"posts\", filename),\n      \"utf-8\"\n    );\n    const { data: frontmatter, content } = matter(markdownWithMeta);\n    const readTimeInMinutes = calculateReadTimeOfText(content);\n    const postData: PostData = {\n      title: frontmatter?.title,\n      slug: slug,\n      date: frontmatter?.date,\n      hero: frontmatter?.hero,\n      excerpt: frontmatter?.excerpt,\n      tags: frontmatter?.tags ? frontmatter.tags.split(\" \") : null,\n      readTimeInMinutes: readTimeInMinutes,\n      content: content\n    };\n    return postData;\n  });\n  return postDataList\n}\n```\n\nOk, so now I have a list of all the unique tags. Now what?\n\n## Build the pages for tags\n\nI wanted to have the tag pages follow the */blog/tags/\\<tag\\>* URL scheme. So I created a *tags* folder nested in */pages/blog* and created a new file named *\\[tag\\].tsx*. The square brackets mean this is a template file for the tag page. There will be a page generated for each unique tag.\n\n[Next.js docs on Dynamic Routes](https://nextjs.org/docs/pages/building-your-application/routing/dynamic-routes)\n\n### getStaticPaths\n\nWithin the tag template we need two methods. `getStaticPaths` will gather a list of all the paths that need to be generated. In this case it's a list of all the unique tags since they'll be used in the url path for each tag page in the format */blog/tags/\\<tag\\>*.\n\n```tsx\nexport const getStaticPaths: GetStaticPaths = async (context): Promise<GetStaticPathsResult> => {\n  const postData: PostData[] = getPostData();\n  const tags = getTagsFromPostDataList(postData);\n  const paths = tags.map((tag: string) => ({\n    params: { tag }\n  }));\n  return {\n    paths: paths,\n    fallback: false\n  };\n};\n```\n\nI use the functions I defined above to pull the unique tags from my markdown articles and generate the paths.\n\n[Next.js docs on *getStaticPaths*](https://nextjs.org/docs/pages/building-your-application/data-fetching/get-static-paths)\n\n### getStaticProps\n\nNext is `getStaticProps`. This function gathers the props that are passed to each tag page to render. In this case we want to pass a list of the articles that have a given tag which comes in through `params`.\n\nI use the same function again to get all the post data, then I filter the posts to only the sunset that have the given tag.\n\n```tsx\nexport async function getStaticProps({ params }: Params) {\n  const postDataList: PostData[] = getPostData();\n  const postsForTag: PostData[] = postDataList.filter((post: PostData) => \n    post.tags.includes(params.tag)\n  );\n  return {\n    props: {\n      tag: params.tag,\n      postsForTag: postsForTag.sort(sortPostsByDate)\n    },\n  }\n}\n```\n\nWhen returning the subset of posts I also make sure they're sorted by date so that I can render them in decending order on the tag page.\n\n[Next.js docs on *getStaticProps*](https://nextjs.org/docs/pages/building-your-application/data-fetching/get-static-props)\n\n### Tags page template\n\nThe last thing to do is build the template for the tag page itself. This was extremely simple as I was able to reuse components I already had.\n\nI have a `ArticlePreviewList` component from the homepage that generates a list of previews for a given list of post data. Other than that there are some headings and misc.\n\n```tsx\nexport default function TagPage({tag, postsForTag}) {\n  return (\n    <>\n      <HeadW title=\"superflux\" />\n      <StickyHeader title={tag} path={[\"blog\",\"tags\"]}/>\n      <SectionHeading>\n        #{tag}\n      </SectionHeading>\n      <ArticlePreviewList articleMetadataList={postsForTag} />\n      <SectionHeading>\n        Get in touch\n      </SectionHeading>\n      <p>\n        Feel free to contact me via <Anchor href=\"https://twitter.com/tyreldelaney\">Twitter</Anchor>!\n      </p>\n    </>\n  );\n}\n```\n\nAnd that's it! With those few pieces Next.js will handle the rest for us. During the build step it will generate all the pages on all the routes for each tag.\n\n![](tag-page-screenshot.png)\n\n## Link to tag pages\n\nOne last piece is to make it easy to navigate to these new pages. I already had a visual tag component I was using within the article previews, just for informational purposes.\n\nI created a new Hashtag component that wraps Ant Design's Tag component. So now I can apply a Next `Link` within that. I also have a custom `Anchor` component that obfuscates the Next `Link` away. Since it's a hashtag component I can hard code the route with just the tag prop itself being the final portion of the route.\n\n```tsx\nimport { Tag } from \"antd\"\nimport Anchor from \"./Anchor\"\n\nexport interface Props {\n  tag: string\n}\n\nexport default function Hashtag(props: Props) {\n  return (\n    <Anchor key={props.tag} href={`/blog/tags/${props.tag}`}>\n      <Tag key={props.tag}>#{props.tag}</Tag>\n    </Anchor>\n  )\n}\n```\n\n## Small gotcha\n\nOne small issue I ran into is one tag I was using contained a `/` character, `ci/cd`. This wasn't a very forward thinking decision on my part.\n\nI just needed to search through my articles and remove the `/` character from that tag, making it just `cicd`. Much simpler than trying to code for it.\n\n## Conclusion\n\nI've had tags on my posts for some time now, but this functionality makes them much more useful. Clicking a tag now brings you to a page that contains articles curated by that tag.\n\nIt's basic functionality, but it's still rewarding to build it yourself.\n\n## Resources\n\n- [Creating Dynamic Tag Pages With NextJS Nested Routes](https://bionicjulia.com/blog/creating-dynamic-tag-page-nextjs-nested-routes) \n- [Next.js docs on Dynamic Routes](https://nextjs.org/docs/pages/building-your-application/routing/dynamic-routes)\n- [Next.js docs on *getStaticPaths*](https://nextjs.org/docs/pages/building-your-application/data-fetching/get-static-paths)\n- [Next.js docs on *getStaticProps*](https://nextjs.org/docs/pages/building-your-application/data-fetching/get-static-props)"},{"title":"Deploy a Next.js Static Site to GitHub Pages","slug":"github-pages-using-nextjs","date":"July 23, 2023","hero":"/images/posts/NextJSGitHubPagesHero.png","excerpt":"I cover the config and deployment steps necessary to easily deploy a static site built with Next.js to GitHub Pages.","tags":["github-pages","nextjs","react","static-site-generators","typescript","javascript"],"id":16,"readTimeInMinutes":8,"content":"\nLet's say you've built an nice new static site using Next.js and you want to host it on GitHub Pages. Well there's a few steps to get it working, but it isn't too hard.\n\n![next js logo and github logo](./NextJSGitHubPagesHero.png)\n\nThis article assumes you already have a website built locally and you're just looking to host it on [GitHub Pages](https://docs.github.com/en/pages/getting-started-with-github-pages). In the future I may write some how-tos for creating a blog using markdown and Next.js.\n\nIn this example I'm going to outline how I deploy to my main GitHub Pages repo for [superflux.dev](https://superflux.dev). It's hosted in my GitHub account's [main Pages repository](https://github.com/tyrelh/tyrelh.github.io). Everyone has access to this special repo. Just create a new repo with the title _your-github-username.github.io_. GitHub will serve the static content there on your own subdomain `https://your-github-username.github.io`. You can even connect a custom domain like I did, I'll talk about that optionally at the end.\n\nYou can also use this tutorial to push repo-specific pages. Google for that if your unfamiliar.\n\n## Tl;dr\n\n* [Static content](#static-content): A quick overview of how to build static assets for a Next.js site.\n* [Install gh-pages package](#install-gh-pages-package): There's a lovely NPM package that makes it very simple to deploy static assets to GitHub Pages.\n* [Branch setup](#branch-setup): I use two repositories on GitHub, one for my source code and one that is the Pages repository that gets hosted under your username.\n* [Deploy script](#deploy-script): The deploy script uses the *gh-pages* package.\n\t* [Static content directory](#static-content-directory): Set the *out* directory in the deploy script that Next.js outputs static assets to when building and exporting.\n\t* [Remote & branch](#remote--branch): Set the remote and the branch that you want *gh-pages* to push your static assets to.\n\t* [Force push to remote](#force-push-to-remote): Allow the deploy script to force-push changes to your GitHub Pages repo.\n\t* [\\_next hidden folder](#_next-hidden-folder): Some tweaks to make GitHub Pages play nicely with Next.js\n* [\\[Optional\\] Configure a custom domain](#optional-configure-a-custom-domain): Allow a GitHub Pages site to be served over a custom domain name.\n* [Resources](#resources)\n* [Conclusion](#conclusion)\n\n## Static content\n\nGitHub Pages can only serve static content. You need to be able to export your Next.js project to static code. You can do this by running\n\n```shell\nnext build && next export\n```\n\n`next export` will export the static code for your project to the _out/_ directory. This is the code we're going to want to host on GitHub Pages.\n\nTo simplify and make it easy to remember I added this as a `build` script in my *package.json*. Add/edit the `build` script:\n\n```json\n\"build\": \"next build && next export\"\n```\n\n## Install gh-pages package\n\nI've used this package in the past and it works well for GitHub Pages websites. *[gh-pages](https://github.com/tschaub/gh-pages)* is a simple little tool that makes it easy to push projects to GitHub Pages repos or branches.\n\n```shell\nnpm install gh-pages --save-dev\n```\n\n## Branch setup\n\nI store my website source in a separate repository, in my case a repo called [personal-site-nextjs](https://github.com/tyrelh/personal-site-nextjs). By default *gh-pages* will deploy your static site to the `origin` remote. But we can change that. I like to keep the `origin` for my source repo pointing to the source remote.\n\n* `personal-site-nextjs`: repo containing the source code for my website. I do development here\n* `tyrelh.github.io`: my main GitHub Pages repo. This is were the compiled static assets are served from\n\nYou can also just use separate branches in the same GitHub Pages repository if you prefer. One for the source and one for the public assets. That feels messy to me so I prefer to keep them separate.\n\n## Deploy script\n\nNext we'll setup a deploy script in our _package.json_ to deploy our static content!\n\nIn your _package.json_ create a new script. Remember it should be on the same level as the other scripts, in the `\"scripts\"` block:\n\n```json\n\"deploy\": \"gh-pages\"\n```\n\nNow this by itself wont work yet, but I'm going to step you through each additional step to get the `gh-pages` command working. If you want to [skip to the end and just see the final script](#conclusion), go ahead!\n\n### Static content directory\n\nFirst you want to tell it what directory that your static assets are in. Remember this is the directory that `next export` in your `build` script outputs to. By default this is the _out/_ directory in your project. Make sure you run your build script first so that your static files are here.\n\nUse the `-d` flag to set the directory.\n\n```json\n\"deploy\": \"gh-pages -d out\n```\n\n### Remote & branch\n\nWe want to make sure `gh-pages` knows where it should push our static code to for hosting. It's good to set this up first so you don't accidentally push code somewhere you don't intend to.\n\nFor the `gh-pages` command, you can use the `-b` flag to tell it the remote branch you want to push to. Whatever the default branch of your _username.github.io_ repo is will work. `main` or `master` for example.\n\n```json\n\"deploy\": \"gh-pages -d out -b main\"\n```\n\nNext you'll want to set the remote. I like to hard code this in the script itself. Since it's going to be static for this project I don't see any reason not to. You can use the `-r` flag to set a remote URL. Copy the remote URL from your _username.github.io_ repo.\n\n```json\n\"deploy\": \"gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git\"\n```\n\n### Force Push to Remote\n\nWhen deploying new static content to your GitHub Pages repo, generally you're going to want to overwrite what is there. At least this is the simplest way to do it. Before setting this just double check that your branch and remote are set correctly. You don't want to overwrite anything you don't intend to!\n\nUse the `-f` flag to force the push to the remote, overwriting files and changes that may exist on the remote.\n\n```json\n\"deploy\": \"gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git -f\"\n```\n\nOk! We're almost there! If this was a Jekyll project, or maybe a standard React project this would probably be all you need. But since we're using Next.js there is one more piece of config we need to do.\n\n### \\_next Hidden Folder\n\nIn your _out/_ directory of static assets, you should see a folder called _\\_next/_. This is where Next.js puts your compiled JavaScript and CSS.\n\nBy default, GitHub pages actually ignores folders beginning with a \\_. This is because GitHub Pages is setup to use Jekyll. Jekyll considers folders beginning with \\_ to be hidden folders, so GitHub Pages just doesn't serve them.\n\nYou can deploy the code as is, and it will look like it worked since you can see the _\\_next/_ directory in you _username.github.io_ repo. But any requests to those assets when you visit your website will result in a 404 not found error.\n\nTo fix this you need to add a file named _.nojekyll_ to the root of your _username.github.io_ repo. You can do this right on the GitHub website to test it out. Once that file is there and you give it a couple minutes to take effect, your website should work without 404 errors!\n\nBut now if you deploy your static code again that file will get erased, breaking your website. We need to incorporate this file into our deploy or build scripts. I put it at the beginning of my deploy script, but you could also put it at the end of your build script too if that makes more sense to you.\n\nWe want to create that `.nojekyll` file in our _out/_ directory after our code is built, but before we deploy it using `gh-pages`.\n\nAt the beginning of your deploy script, add an `echo` command to create the file. The file can contain anything, I just echo the string `true`. Use the `&&` between the `echo` and `gh-pages` commands so that they will run sequentially.\n\n```json\n\"deploy\": \"echo 'true' > ./out/.nojekyll && gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git -f\"\n```\n\nThis wont quite work, because by default `gh-pages` ignores hidden dotfiles! To tell `gh-pages` you want to include dotfiles (that's files beginning with a .), use the `-t` flag on the `gh-pages` command.\n\n```json\n\"deploy\": \"echo 'true' > ./out/.nojekyll && gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git -f -t\"\n```\n\nAnd that's basically it!\n\n## Configure your repo for GitHub Pages\n\nYou'll need to make sure your repo is configured for Pages. Go to your repo, click on the repo _Settings_, and click _Pages_ on the settings side bar. See the [GitHub Pages docs](https://docs.github.com/en/pages/getting-started-with-github-pages) for more general info about hosting static content.\n\n## \\[Optional\\] Configure a custom domain\n\nAfter you follow the [instructions here](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site) to setup your custom domain with your GitHub Pages website, you'll notice that you need a _CNAME_ file in the root of your repo for the domain to map correctly.\n\nSince our deploy process overwrites all the files in our GitHub Pages repo on each deploy, we need to add this file to our deploy/build process so it will be included each time. This is similar to what we needed to do for the _.nojekyll_ file.\n\nAt the beginning of your deploy script, add another `echo` command. You want to output the root domain for your website to a file called _CNAME_. In my case my root domain is `superflux.dev`.\n\n```json\n\"deploy\": \"echo 'superflux.dev' > ./out/CNAME && echo 'true' > ./out/.nojekyll && gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git -f -t\"\n```\n\nMake sure to include the `&&` between each command so they run sequentially!\n\n## Resources\n\n* Allow the _\\_next_ folder to get picked up in repo: https://github.blog/2009-12-29-bypassing-jekyll-on-github-pages/\n* `gh-pages` package to easily deploy to GitHub Pages repositories: https://github.com/tschaub/gh-pages\n* GitHub Pages docs: https://docs.github.com/en/pages/getting-started-with-github-pages\n* GitHub Pages custom domain docs: https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site\n\n## Conclusion\n\nAnd now that's it! To summarize we built a deploy script in our _package.json_ that looks like this\n\n```json\n\"deploy\": \"echo 'true' > ./out/.nojekyll && gh-pages -d out -b main -r https://github.com/tyrelh/tyrelh.github.io.git -f -t\"\n```\n\nYou'll want to make sure your `-b` branch is pointing to the branch being served on your GitHub Pages repo, and that the `-r` remote is the URL of your GitHub Pages repo.\n\nAfter building your website locally just run `npm run deploy` to push your static code to your GitHub Pages site! Remember the `gh-pages` package uses _git_ to push code to the remotes, so you'll need to configure your username, email, and credentials to authenticate the push to your GitHub Pages repo.\n\nReach out to me on Twitter [@tyreldelaney](https://twitter.com/tyreldelaney) if you have any questions, comments, or suggestions!\n\n*Note: this article was written in April 2022. It sat for a while in my queue of articles as we were gearing up to have our first child. Hopefully nothing has changed drastically with Next.js and GitHub Pages that renders this info unusable.*"},{"title":"Node CI/CD Pipeline using GitHub Actions & AWS Elastic Beanstalk","slug":"node-cicd-pipeline","date":"May 30, 2020","hero":"/images/posts/node-cicd-pipeline-hero.png","excerpt":"Here is my journey into creating an automated continuous integration and continuous deployment workflow for a project using GitHub Actions.","tags":["github-actions","cicd","typescript","aws","automation"],"id":6,"readTimeInMinutes":24,"content":"\nHere is my journey into creating an automated workflow to test, build, and deploy a project I have been working on using Github Actions and Elastic Beanstalk.\n\n![Github Actions logo with colourful background and text that says GitHub Actions now with built-in CI/CD](node-cicd-pipeline-hero.png)\n\n## Tl;dr\n* [Background](#background-on-the-project): I was converting a JavaScript project to TypeScript and I decided to set up continuous integration and continuous deployment at the same time using [Github Actions](https://github.com/features/actions).\n* [Testing](#testing): I am using [Mocha](https://mochajs.org/) for the first time to run my TypeScript tests.\n* [Automation](#automation): The intention is to create a Github workflow that will test my code, build my project, and deploy it to Elastic Beanstalk automatically whenever I push to the master branch. \n* [Create a new IAM user](#create-a-new-iam-user): First step is to create a new AWS IAM User to automate interactions with AWS.\n* [Save AWS User credentials in Github](#save-aws-user-credentials-in-github): Github provides and encrypted secret store that you can use to securely access 3rd-party credentials within a Github Workflow.\n* [Create a S3 bucket to store deployment artifacts](#create-a-s3-bucket-to-store-deployment-artifacts): Setup a bucket to store our deployment artifacts so they can be easily deployed and archived.\n* [Create an Elastic Beanstalk Application and Environment](#create-an-elastic-beanstalk-application-and-environment): Create an new application and environment that we can deploy our app to.\n* [Create a Workflow file within your repo](#create-a-workflow-file-within-your-repo): Workflows live in your repo in the *.github/workflows/* directory.\n* [Setup the yaml file](#setup-the-yaml-file): Setup your workflow with a trigger and some environment variables for readability and maintainability.\n* [Test job](#test-job): A job that will test our project.\n* [Build job](#build-job): A job to build our code, bundle it in a zip, and push that to AWS S3.\n* [Deploy job](#deploy-job):  A job to deploy our project to Elastic Beanstalk\n* [Testing the workflow](#testing-the-workflow): Push this new workflow file to your master branch and see the workflow in action.\n\n## Background on the project\nI have recently been working on converting my JavaScript [battlesnake](https://play.battlesnake.com/) over to TypeScript. This can be done in a gradual process but I've been finding that difficult to do, so this was more of a tear of the band-aid quickly kind of situation.\n\nI decided that I would use [Deno](https://deno.land/) for this project rather than Node. Deno 1.0 had [just recently come out](https://deno.land/v1) and I was all over that hype train. I really think Deno makes sense in it's core philosophy. It also happens to not only have TypeScript support by default, but the strictest possible TypeScript support is default. This encouraged me to translate my JavaScript to TypeScript properly and to fix some of the wrong design choices I had made over the last two years.\n\nEventually I became frustrated with Deno's, frankly, lack of polish. It isn't a true 1.0 if basic features, like `fetch`, don't work correctly yet. Over the course of around two weeks of using Deno I got to the point where I decided to just take all the TypeScript I had just written and move it back to Node.\n\nHopefully I will have by now put together a small article here about migrating a JavaScript Node project to TypeScript. If not check back soon!\n\n## Testing\nDuring development of my Deno TypeScript battlesnake I actually [already set up automated testing using Github Actions](https://superflux.dev/blog/deno-tests-and-github-actions). That worked really well and Deno's included test runner is really simple and easy to use.\n\nBringing my tests over to Node I used what seems like the most popular option which is [Mocha](https://mochajs.org/). I've never used it before but it seems fine.\n\nI can run my tests with the following command which I entered as a `test` script within my *package.json*:\n\n```bash\nmocha -r ts-node/register src/tests/**/*-test.ts\n```\n\nGreat. So with this in place my project is back to a place where I can run it locally, test it, and build it for deployment to AWS.\n\n## Automation\nBeyond automating testing when pushing to my master branch I decided to give the whole CI/CD pipeline a try. I use AWS Elastic Beanstalk to host my project and up to this point I have always been manually zipping the production build and using the AWS Web Console to manually deploy that to Elastic Beanstalk.\n\nNow I have fully automated the whole process!\n\nUsing Github Actions, whenever I push to my master branch I have 3 jobs that run:\n\n1. The repo is tested with my suite of tests using Mocha\n2. If the tests pass, the project is built, zipped, and pushed to AWS S3\n3. If the tests and build are successful, the zip is deployed to AWS Elastic Beanstalk.\n\nIf this fails at any point I get an email and red warnings on Github notifying me.\n\nGithub actions are powerful and you can do far more complicated things than I am doing. But if this interests you, or lines up with a project you are working on, read on and I'll go over step-by-step how I did this.\n\n## Create a new IAM User\nI decided to create a specific IAM User for Github Actions, and specifically this repo.\n\nLog into you AWS Console using your admin account (you created an admin account right? Try not to use you root account) and navigate to IAM.\n\n![Screenshot of the amazon web services IAM page](node-cicd-pipeline-iam-1.png)\n\nClick on Users and then Add User.\n\nChoose a name that makes sense to you. For example `github-actions-battlesnake-test` makes sense in my case as this user exists to authenticate Github Actions for my Battlesnake project. Be as specific as you would like, the name doesn't matter too much.\n\nAlso choose *programmatic access* as the *access type*. This will allow us to generate an *access key ID* and *secret key* that we will pass to Github Actions so that we can use the AWS CLI.\n\n![Screenshot of the interface for entering a user name and choosing the access type](node-cicd-pipeline-iam-2.png)\n\nThen click *Next: Permissions*.\n\nOn the next screen choose *Attach existing policies directly*. In the future you may want to to create a Group or Role to house these permissions and add this User to that Group or grant them that Role. For now, applying the permissions directly to the User will work fine.\n\nYou want to grant this user permission to use S3 and Elastic Beanstalk. Search for \"s3\" and check the option called *AmazonS3FullAccess*. Next search for \"elasticbeanstalk\" and check the option for\n*AWSElasticBeanstalkFullAccess*. You can probably grant even more granular access than these for this account, but I'll let you sort that out if you like. Double check you have the correct permissions selected and then click *Next: Tags*.\n\n![Screenshot of list of possible permissions showing two selected](node-cicd-pipeline-iam-3.png)\n\nYou can give this User tags if you wish, or leave it blank. Click *Next: Review*.\n\nDouble check that everything looks as you expect and then click *Create user*.\n\nImportant‚ùóThis page shows your new user's *access key ID* and *secret key*. This is private information that you should strive to keep private. Someone who has access to this information has access to use this user and anything you have granted it permission to use.\n\nWe want to save this info as a secret on Github. I would recommend not saving this in any other way as you are likely to forget about it or mishandle it. The keys shown in this article and these screenshots have long been deactivated before this post went live.\n\n![Screenshot of user creation success screen showing the access key ID and secret key](node-cicd-pipeline-iam-4.png)\n\n**While leaving this tab open**, open a new tab and navigate to the Github repo of your project.\n\n## Save AWS User credentials in Github\nNext you want to save these AWS credentials as a Secret on your Github repo. This will allow you to securely access them in your Github Workflow later on.\n\nIn the Github repo of the project you want to automate, click the *Settings* tab near the top right of the page. Choose *Secrets* in the left menu. Then click the *New Secret* button in the upper right.\n\n![Screenshot of Github showing the secret creation screen with text fields for the secret and the name of the secret](node-cicd-pipeline-github-secret-creation.png)\n\nCopy your *access key ID* from the AWS Console tab you have open into the *Value* field. Give it a name that makes sense to you such as *AWS_ACCESS_KEY_ID*. I believe this name just needs to be unique to this repo and not your Github account. Double check that you copied the *access key ID* over correctly and then click *Add secret*.\n\nDo the same for the *secret key*, naming it something like *AWS_SECRET_KEY*. Make sure you double check that you copied the *secret key* over correctly as once we are done with this process these keys are no longer accessible. If you make a mistake somewhere through this key transfer you can invalidate those keys and generate new ones.\n\n![Screenshot of Github showing a list of all saved secrets for this repository](node-cicd-pipeline-github-secrets.png)\n\nThats it for the user creation! Next we want to prepare a couple other resources in AWS.\n\n## Create a S3 bucket to store deployment artifacts\nWe are going to store our deployment artifact in S3 so we can easily deploy it to Elastic Beanstalk. Let's create that bucket now.\n\nIn your AWS Console, navigate to S3. Click the *Create bucket* button.\n\nYou will need to choose a globally unique (or region unique? I can't remember) name for your bucket. The UI will warn you if you need to pick a different name. Call it whatever you like, and make note of the name you choose. Click *Create*.\n\n![Screenshot of AWS console showing s3 bucket creation where you are choosing a name](node-cicd-pipeline-s3.png)\n\n## Create an Elastic Beanstalk Application and Environment\nNext we want to create an Elastic Beanstalk Application. In the AWS Console, navigate to Elastic Beanstalk.\n\nThere are many different states your Elastic Beanstalk Console can be in so it is hard to say exactly where this option is but you want to *Create a new application*.\n\nChoose a name and click *Create*.\n\nNext you want to create an Environment within this Application. With the Application you just created selected, find the option to *Create a new environment*.\n\nChoose *Web server environment* and click *Select*.\n\nChoose a unique *Environment name* and *Domain*. I use this URL for my Battlesnake application so I choose something that is easy to use.\n\n![Screenshot of AWS console showing elastic beanstalk environment creation](node-cicd-pipeline-eb-environment-creation.png)\n\nIn the *Platform* section choose *Node.js* as the platform and leave the other options as their defaults. This will be different if you are running a different software stack or need a specific version of Node.\n\nIn the *Application code* section leave the *Sample application* selected. We will deploy our own application here in soon.\n\nClick *Create environment* after you double check your details are correct.\n\nNow we are done with the AWS setup. The last piece of this is to create a workflow in our repo that outlines the entire Github Action.\n\n## Create a Workflow file within your repo\nGithub Actions work off of [*workflows*](https://help.github.com/en/actions/configuring-and-managing-workflows). *Workflows* are yaml files that live within *.github/workflows/* on your master branch. These yaml files describe the series of actions you want to perform.\n\nThere are a few options for creating your first workflow yaml file. The simplest is to use the Github GUI. You can click the *Actions* tab from within your repo. Find the option that says *Skip this and set up a workflow yourself*. This will present you with a web editor and a skeleton workflow file.\n\n![Screenshot of AWS console showing elastic beanstalk environment creation](node-cicd-pipeline-github-actions-getting-started.png)\n\nThe other option is to just use whatever IDE or text editor you normally use and create a new yaml file in your repo within *.github/workflows/*.\n\nI am going to start from a blank file to describe what each piece means.\n\n## Setup the yaml file\nIf this yaml file gets confusing at all just reference the [Github docs](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions) for the proper syntax.\n\nThe first line of your workflow file is the name of your workflow. Choose a name that describes what this workflow is doing, be as specific as you like.\n\n```yaml\nname: CICD_Pipeline\n```\n\nNext we are going to set up some environment variables to make the rest of this file cleaner and more maintainable. I have seven environment variables total in my workflow. These get placed in the `env` namespace.\n\nThe first two are taken right from AWS Elastic Beanstalk. We want to save the Elastic Beanstalk Application name and Environment name that we created earlier. Make sure these are exactly the same as you used when setting up the Application and Environment.\n\n```yaml\nEB_APPLICATION: \"Battlesnake\"\nEB_ENVIRONMENT: \"Battlesnake-env\"\n```\n\nNext You want to create a variable for your S3 bucket name.\n\n```yaml\nEB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n```\n\nAdd a variable for the AWS region you are using.\n\n```yaml\nAWS_REGION: \"us-west-2\"\n```\n\nAnd lastly we will add 3 strings that we will use during the build and deploy process. These will use the the latest commit hash from our repo to create unique strings for deployment versioning. The commit hash can be accessed via `${{ github.sha }}`.\n\n```yaml\nEB_VERSION: \"Version-${{ github.sha }}\"\nEB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\nDEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\n```\n\nSo so far we have a name for our workflow and a series of environnement variables that we can use.\n\nNext we want to describe the trigger we want to use to initiate our workflow. This is one of the reasons Github Actions are so powerful as there are so many [different triggers available](https://help.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow#triggering-a-workflow-with-events). We simply want to trigger this action whenever we push to our master branch. You describe your triggers in the `on` namespace like so:\n\n```yaml\non:\n  push:\n    branches: [ master ]\n```\n\nSo putting all this together, our yaml workflow should look something like this so far:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n```\n\n## Test job\nWith the basics of our workflow file setup we can get into the interesting bits. A workflow file can have a series of [*jobs*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobs) that Github can run in parallel or in sequence. For our purposes we are going to have 3 jobs, *test*, *build*, and *deploy*, that we want to run in sequence where each job depends on the previous job succeeding.\n\nThe first job we will create is the *test* job. This will simply run our test suite and report back if tests passed or failed.\n\nJobs are defined in the `jobs` namespace which is essentially a list of jobs, each starting with their name. You don't need to use the `name` keyword. I called this first job `test`.\n\n```yaml\njobs:\n  test:\n```\n\nNow the first piece of a job describes what operating system you want to run this workflow on. [Github has options](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idruns-on) for Ubuntu, MacOS, and Windows. We will use Ubuntu for our workflow.\n\n```yaml\nruns-on: ubuntu-latest\n```\n\nNext we want to describe the [*steps*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idsteps) of this job. This is a list of steps each with a name describing what is being done. A step can be a predefined action that we reference from another repo or could be something like shell command. We can install almost any software we want and use it within our jobs via shell commands.\n\n```yaml\nsteps:\n```\n\nThe first step we want to do is to pull down our code from Github. For this we can use an action provided by Github to handle that easily. `actions` is a [Github owned organization](https://github.com/actions), `checkout` the [repo](https://github.com/actions/checkout) we want to use, and `@v2` is the version tag. By adding this action we now have access to all our code in our repo.\n\n```yaml\n- name: Git clone repo\n  uses: actions/checkout@v2\n```\n\nSince our project uses Node, we want to install that next. We will use another [provided action](https://github.com/actions/setup-node) called `setup-node`. We also specify the Node version that we want to use.\n\n```yaml\n- name: Install node\n  uses: actions/setup-node@v1\n  with:\n    node-version: '12.x'\n```\n\nNext let's install our project dependencies. We can use the `run` command to run `npm` as we would do on any other machine. We will use `npm ci` instead of `npm install` [since we are in an automated environment](https://docs.npmjs.com/cli/ci). It's effectively the same just a bit quicker and cleaner.\n\n```yaml\n- name: Install dependencies\n  run: npm ci\n```\n\nLastly, lets run our tests! Our environment is set up now so all we need to do is run our test command. I have this set up as a `test` script in my *package.json* to run my Mocha tests (`\"test\": \"mocha -r ts-node/register src/tests/**/*-test.ts\"`). So I just need to run `npm run test`. We pass an optional `CI: true` environment variable to ensure tests will fail the job if they throw warnings.\n\n```yaml\n- name: Run tests\n  run: npm run test\n  env:\n    CI: true\n```\n\nPutting this all together our workflow file should look like this:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n\njobs:\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm run test\n        env:\n          CI: true\n```\n\nGreat, that is our first job complete! If you are just looking to automate your tests this is all you really need. But we also want to build and deploy our app, so lets write the `build` job next.\n\n## Build job\nI'll get to the point a little quicker this time and then describe what you are seeing.\n\n```yaml\nbuild:\n  runs-on: ubuntu-latest\n  needs: [test]\n  steps:\n    - name: Git clone repo\n      uses: actions/checkout@v2\n\n    - name: Install node\n      uses: actions/setup-node@v1\n      with:\n        node-version: '12.x'\n\n    - name: Install dependencies\n      run: npm ci\n\n    - name: Build project\n      run: npm run build\n\n    - name: Create zip deployment artifact\n      run: zip -r ${{ env.DEPLOY_ARTIFACT }} build package.json package-lock.json\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Push deploy artifact to S3\n      run: aws s3 cp ${{ env.DEPLOY_ARTIFACT }} s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/\n```\n\nAt the top of this job we use the [*needs*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idneeds) parameter on the previous `test` job. This is what allows us to run our jobs in sequence each relying on the previous job ending successfully.\n\nNext you can see that the first three steps are identical to the previous job. We checkout our code, install Node, and install our dependencies.\n\nThen we run our build script defined in our *package.json*. Since I am using TypeScript I am using the TypeScript compiler to build my code, so my build script is `\"build\": \"tsc -p .\"`.\n\nNext we use the zip command included with Ubuntu to package our code into a deployment artifact. `-r` in means we want to recurse into directories, `${{ env.DEPLOY_ARTIFACT }}` is the name of the file we are creating that we defined earlier as an environment variable, and lastly we pass the files we want to include. For my deployment I include everything in my *build/* directory as well as my *package.json* and *package-lock.json*. You need to include whatever files you want for your deployment.\n\nFor my deployment I want to store my deploy artifact in AWS S3. In order to push this file to S3 we first need to configure our credentials that we setup earlier with our IAM User and Github Secrets.\n\nThis next step uses an [action](https://github.com/aws-actions/configure-aws-credentials) [provided by AWS](https://github.com/aws-actions). We pass it our `aws-access-key-id` and `aws-secret-access-key` that we stored in our repo's secrets earlier. These are accessed by `${{ secrets.NAME_OF_SECRET }}` where `NAME_OF_SECRET` is what you named it when you created it. We also need to pass the `aws-region` that we set earlier in our environment variables.\n\nLastly, now that our AWS credentials are set up, we can push our deployment artifact up to S3. I believe as part of setting up the AWS credentials that action also installs the AWS CLI for us. So we want to copy our file to S3 using `aws s3 cp` and by passing the name of the file as `${{ env.DEPLOY_ARTIFACT }}` and the location we want to push to as `s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/`. Both the artifact name and bucket name we set earlier as environment variables.\n\n## Deploy job\nNow we have our deployment artifact built and saved to S3. We can write our last job to deploy this package to AWS Elastic Beanstalk.\n\n```yaml\ndeploy:\n  runs-on: ubuntu-latest\n  needs: [build]\n  steps:\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Create new ElasticBeanstalk Application version\n      run: |\n        aws elasticbeanstalk create-application-version \\\n        --application-name ${{ env.EB_APPLICATION }} \\\n        --source-bundle S3Bucket=\"${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}\",S3Key=\"${{ env.DEPLOY_ARTIFACT }}\" \\\n        --version-label ${{ env.EB_VERSION }} \\\n        --description ${{ env.EB_DESCRIPTION }}\n\n    - name: Deploy artifact to ElasticBeanstalk\n      run: |\n        aws elasticbeanstalk update-environment \\\n        --environment-name ${{ env.EB_ENVIRONMENT }} \\\n        --version-label ${{ env.EB_VERSION }}\n```\n\nYou can see at the beginning of this job that it depends on the `build` job. That way it will only start once the build has completed successfully.\n\nThe first step is just copied from the previous job. We are going to use the AWS CLI to deploy our app so we need to set up our credentials again.\n\nThe second step uses the AWS CLI to create a fresh Application version for this deployment. You can see it uses `aws elasticbeanstalk create-application-version` with a few flags. We pass in the `application-name`, `version-label`, and `description` we set earlier as environment variables. We also pass in the `source-bundle` which is the location in S3 that we stored our deployment artifact. Both the name of the bucket and the name of the file (the key) we saved in environment variables as well.\n\nThe last step is to update the environment version in Elastic Beanstalk. We use `aws elasticbeanstalk update-environment` and pass it the `environment-name` and `version-label` that we saved earlier as environment variables.\n\nAnd thats it! The workflow file all together should look something like this:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n\njobs:\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm run test\n        env:\n          CI: true\n\n  build:\n    runs-on: ubuntu-latest\n    needs: [test]\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build project\n        run: npm run build\n\n      - name: Create zip deployment artifact\n        run: zip -r ${{ env.DEPLOY_ARTIFACT }} build package.json package-lock.json\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Push deploy artifact to S3\n        run: aws s3 cp ${{ env.DEPLOY_ARTIFACT }} s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [build]\n    steps:\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Create new ElasticBeanstalk Application version\n        run: |\n          aws elasticbeanstalk create-application-version \\\n          --application-name ${{ env.EB_APPLICATION }} \\\n          --source-bundle S3Bucket=\"${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}\",S3Key=\"${{ env.DEPLOY_ARTIFACT }}\" \\\n          --version-label ${{ env.EB_VERSION }} \\\n          --description ${{ env.EB_DESCRIPTION }}\n\n      - name: Deploy artifact to ElasticBeanstalk\n        run: |\n          aws elasticbeanstalk update-environment \\\n          --environment-name ${{ env.EB_ENVIRONMENT }} \\\n          --version-label ${{ env.EB_VERSION }}\n```\n\n## Testing the workflow\nLet's give it a try and see it in action. If you push this file to your master branch it should trigger the workflow.\n\nIn these screenshots I pushed a change where I removed some logging that I had previously in my workflow since it is triggered based on pushes to master. If for some reason it doesn't trigger when you push the workflow try pushing something else to master after the workflow already exists in master.\n\nYou can then navigate to the *Actions* tab of your repo to see the workflow running.\n\n![Screenshot of the Github Actions interface showing past executions of workflows](node-cicd-pipeline-github-running-actions.png)\n\nYou can click into the running workflow and see the console output of each job and step. If there are any errors along the way you should see some red failure symbols and console output describing what when wrong. If nothing goes wrong you should see green success messages.\n\n![Screenshot of completed Github action showing green check marks on the three jobs indicating they completed successfully](node-cicd-pipeline-github-workflow-success.png)\n\nIf you pop over to your AWS Console you can peek into S3 and see the deployment artifact just uploaded to your bucket.\n\n![Screenshot of AWS S three bucket showing list of successfully uploaded files](node-cicd-pipeline-s3-uploaded-files.png)\n\nAnd if you navigate to Elastic Beanstalk you should see your application running or perhaps in start-up.\n\n![Screenshot of AWS elastic beanstalk showing the running environment just deployed](node-cicd-pipeline-eb-running-environment.png)\n\nSo there you go! If that all went well now you have a completely automated CI/CD pipeline. Every time you push to your master branch your repo will be tested, built, and deployed automatically. You can change the triggers if you like depending on your workflow to instead trigger on pull request or whatever else.\n\nThis workflow is specific for a Node app being deployed to AWS Elastic Beanstalk but it can be adapted to basically any software stack and cloud provider. [Github has many Actions](https://github.com/actions) you can leverage for all kinds of things, and a lot of third parties are creating their own actions for their software as well.\n\nAutomate all the things!"},{"title":"Deno Tests & GitHub Actions CI","slug":"deno-and-github-actions","date":"May 23, 2020","hero":"/images/posts/DenoTestsAndGithubActionsCI.png","excerpt":"As part of translating my JavaScript and Node Battlesnake to TypeScript and Deno I wanted to setup continuous integration. It was som much easier than I imagined using GitHub Actions.","tags":["javascript","typescript","node","deno","github-actions","cicd","devops"],"id":5,"readTimeInMinutes":6,"content":"\nDuring a recent project to convert my JavaScript & Node [Battlesnake](https://play.battlesnake.com/) over to TypeScript & [Deno](https://deno.land/), I decided I would also create a more robust suite of tests for it.\n\n![Deno and Github logos with an addition symbol between them](DenoTestsAndGithubActionsCI.png)\n\nIf you are unfamiliar with [Battlesnake](https://play.battlesnake.com/), it is an online and in-person programming competition where you build a AI in the form of a REST API that can play a multiplayer version of the classic game [Snake](https://en.wikipedia.org/wiki/Snake_(video_game_genre). You can check out details on their [website](https://play.battlesnake.com/) to learn more, and even watch some past events on their [Twitch channel](https://www.twitch.tv/BattlesnakeOfficial).\n\n## Tl;dr\n* [Deno Tests](#deno-tests): Deno includes a very simple test runner framework.\n* [Github Actions](#github-actions): Github actions allow you to automate tasks based on triggers within your Github repo.\n* [Create the workflow](#create-the-workflow): A .yml file describes a series of actions you would like to perform based on a trigger.\n* [Automate Deno tests](#automate-deno-tests): Just add a `run: deno test` command to your workflow .yml.\n\n## Deno Tests\n[Deno](https://deno.land/) includes a simple test runner for tests in js, ts, jsx, or tsx files. It can be run with:\n\n```bash\ndeno test\n```\n\nTo create tests, all you need to use is use the `Deno.test()` method included with Deno within files ending in *test* (`{*_,}test.{js,ts,jsx,tsx}`) anywhere in your project structure. I put mine in *tests/*.\n\nExample of a basic test:\n\n```typescript\nimport { assert } from \"https://deno.land/std/testing/asserts.ts\";\nimport { root } from \"../app/main.ts\";\n\nDeno.test(\"Root response contains expected fields\", () => {\n  // when\n  const result = root();\n  // then\n  assert(result?.apiversion);\n  assert(result?.author);\n  assert(result?.head);\n  assert(result?.tail);\n  assert(result?.color);\n});\n```\n\nThis test is simply asserting that values exist for these specified fields.\n\nYou can add many tests to single files by calling `Deno.test()` over and over again. You can also make as many test files as you like, Deno will automatically execute all the files it recognizes ending in *test* (`{*_,}test.{js,ts,jsx,tsx}`).\n\nVisit the [Deno Testing docs](https://deno.land/manual/testing) for more info about creating tests.\n\nEasy! So now I can create a robust set of unit tests for my Battlesnake AI.\n\nSince the game Battlesnake works by [sending you the entire game state for every move](https://docs.battlesnake.com/references/api), I can also save the game state JSON from particularly tricky moves and use them within their own tests. The output can be compared against the single best move, or even a set of equally good moves if their are multiple. Creating tests like this tests the behaviour of the AI overall and ensures that changes to the behaviour aren't making the AI perform worse on moves it previously was able to do correctly.\n\nSo now that I have tests up and working, I wanted to automate them using Github Actions.\n\n## Github Actions\nGithub Actions are still quite new to me and I hadn't touched them at all before this project. I just assumed it would be complicated to set up.\n\nFor what I wanted to do for this project it was actually trivial. Couldn't have been easier.\n\nWhat I wanted was to run these tests automatically whenever pushing to my repository. I figured this Deno app is pretty simple all things considered, so I shouldn't have to mess around with Docker or anything like that.\n\nI'll step you through what I did.\n\n## Create the workflow\nGithub Actions are based around these things called workflows. They are essentially .yml scripts that describe the series of events you want to perform in your action.\n\nIf you click the Actions tab within the repo you want to create the Action you will be presented with a Get started with GitHub Actions page. This page has many example actions you get you started for so many different languages, frameworks, and platforms. It will even suggest actions to you based on the contents of your repo. I chose the *Skip this asn set up a workflow yourself* option.\n\n![Get started with Github Actions](DenoAndGithubActions-get-started-with-github-actions.png)\n\nThis plops you into a web editor and gives you a basic example workflow .yml file to start with. It looks something like this:\n\n```yaml\n# This is a basic workflow to help you get started with Actions\n\nname: CI\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n  build:\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it\n    - uses: actions/checkout@v2\n\n    # Runs a single command using the runners shell\n    - name: Run a one-line script\n      run: echo Hello, world!\n\n    # Runs a set of commands using the runners shell\n    - name: Run a multi-line script\n      run: |\n        echo Add other actions to build,\n        echo test, and deploy your project.\n\n```\n\nWith this you can actually click the *Start commit* button and that will guide you to commit this .yml file to your repo within the *.github/workflows/* directory.\n\nYou can see near the top of that file that there are triggers for `on push` and `on pull_request` attached to the master branch. You can try to push something to master and see it work!\n\nIf you visit the Actions tab of your repo now you will see your Actions and the history of all the times they have run. You can click into them for more details and to see the console outputs. Also by default it will email your Github account email whenever an action fails. I imagine this can be changed somewhere if you don't like that.\n\n![Github Actions](DenoAndGithubActions-github-actions.png)\n\n## Automate Deno tests\nNow I wanted to try to run my tests using Deno. I knew this would involve installing Deno somehow so I searched around.\n\nI found [this repo](https://github.com/denolib/setup-deno) from [denolib](https://github.com/denolib) with exactly what I wanted.\n\nReally all you need to do is add the `uses` line pointing to this repo to your workflow .yml file under the `steps` section. You can also include the Deno version you prefer. Then within the `run` section you now have access to `deno` and all of its functions.\n\nSo now my workflow .yml file looks like this:\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@master\n    - uses: denolib/setup-deno@master\n      with:\n        deno-version: v1.x\n    - run: deno run https://deno.land/std/examples/welcome.ts\n```\n\nOne really cool feature of Deno is that you can run scripts from the web right in the terminal, and you can also do this right within Github Actions. That is what the URL is doing in\n\n```yaml\n- run: deno run https://deno.land/std/examples/welcome.ts\n```\n\nYou can run this and then look within your Github Actions for the console output from this example *welcome.ts* file.\n\nSo now to run my tests, all I needed to do was change that `deno run` command to `deno test`. My final .yml workflow looks something like this:\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  run-tests:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@master\n    - uses: denolib/setup-deno@master\n      with:\n        deno-version: v1.x\n    - run: deno test\n```\n\nNow every time I push to my master branch all my tests will be run, including any new tests I just committed, and I will be notified both on the Github UI and in my email if any tests fail. I can then log into Github and look at the output to see what failed.\n\nI hope this small guide helped you out and showed you just how simple both Deno and Github Actions are!"}],"searchIndexJson":"[[\"1\",[2,8,22,20,21]],[\"2\",[2,3,4,10,14,9,22,21,12]],[\"3\",[3,8,22]],[\"4\",[2]],[\"5\",[8]],[\"7\",[8]],[\"10\",[2]],[\"13\",[8]],[\"20\",[2,4,10,14,22,12]],[\"24\",[9]],[\"30\",[8]],[\"40\",[2]],[\"58\",[8]],[\"100\",[2]],[\"135\",[8]],[\"201\",[2,4]],[\"202\",[10,14,12]],[\"240\",[9]],[\"308\",[8]],[\"400\",[2]],[\"580\",[8]],[\"1000\",[2]],[\"2018\",[2,4]],[\"2020\",[10]],[\"2021\",[10]],[\"2022\",[14,12]],[\"2023\",[14]],[\"3080\",[8]],[\"4000\",[2]],[\"5800\",[8]],[\"a\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"aw\",[11,6,12]],[\"aws\",[11,6,12]],[\"d\",[11,18,7,5,16,3,4,1,10,19,6,14,22,20,21,17,15,12,13]],[\"dd\",[11]],[\"ddn\",[11]],[\"ddns\",[11]],[\"n\",[11,18,5,16,4,1,10,19,6,14,22,20,21,17,15,12]],[\"no\",[11,18,5,4,1,10,6,22,17]],[\"nod\",[11,5,6]],[\"node\",[11,5,6]],[\"r\",[11,2,18,7,16,14,8,9,15,12,13]],[\"ra\",[11,14,9]],[\"ras\",[11,14]],[\"rasp\",[11,14]],[\"raspb\",[11,14]],[\"raspbe\",[11,14]],[\"raspber\",[11,14]],[\"raspberr\",[11,14]],[\"raspberry\",[11,14]],[\"p\",[11,2,18,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15]],[\"pi\",[11,3,10,6,14]],[\"i\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"in\",[11,2,18,5,4,1,10,6,14,8,22,20,21,17,15,12,13]],[\"inf\",[11,18,1]],[\"infr\",[11,18]],[\"infra\",[11,18]],[\"infras\",[11,18]],[\"infrast\",[11,18]],[\"infrastr\",[11,18]],[\"infrastru\",[11,18]],[\"infrastruc\",[11,18]],[\"infrastructure\",[11,18]],[\"dy\",[11]],[\"dyn\",[11]],[\"dyna\",[11]],[\"dynam\",[11]],[\"dynami\",[11]],[\"dynamic\",[11]],[\"dn\",[11]],[\"dns\",[11]],[\"is\",[11,2,3,1,10,6,22,21,17,15,12,13]],[\"h\",[11,2,18,3,4,1,10,6,14,8,9,20,21,17,15,12,13]],[\"ha\",[11,18,3,1,14,8,9,17,15,12]],[\"han\",[11,18]],[\"hand\",[11,18]],[\"handy\",[11]],[\"if\",[11]],[\"y\",[11]],[\"yo\",[11]],[\"you\",[11]],[\"w\",[11,2,18,7,5,16,4,1,19,6,14,9,22,20,21,17,15,12,13]],[\"wa\",[11,5,19,9,22]],[\"wan\",[11,5]],[\"want\",[11,5]],[\"t\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"to\",[11,2,7,5,16,3,4,1,10,19,14,9,22,20,21,17,12,13]],[\"ho\",[11,2,10,20,17,13]],[\"hos\",[11]],[\"host\",[11]],[\"s\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"so\",[11,18,5,14,22,17,12,13]],[\"som\",[11,18,5,14,22,17,12]],[\"some\",[11,18,14,22,17,12]],[\"somet\",[11]],[\"someth\",[11]],[\"somethi\",[11]],[\"somethin\",[11]],[\"something\",[11]],[\"o\",[11,2,7,5,3,4,1,10,19,9,22,20,21,17,15,12]],[\"or\",[11,4]],[\"ac\",[11,2,5,6,12,13]],[\"acc\",[11]],[\"acce\",[11]],[\"acces\",[11]],[\"access\",[11]],[\"on\",[11,3,19,22,21,15]],[\"your\",[11]],[\"hom\",[11,2]],[\"home\",[11,2]],[\"ne\",[11,16,19,14,22,20,21,12]],[\"net\",[11]],[\"netw\",[11]],[\"netwo\",[11]],[\"networ\",[11]],[\"network\",[11]],[\"b\",[11,2,18,7,5,16,3,4,1,10,19,6,8,9,20,21,15,13]],[\"bu\",[11,7,16,4,1,8,9,20,21,13]],[\"but\",[11,4,1,13]],[\"do\",[11,22,15,12,13]],[\"don\",[11]],[\"dont\",[11]],[\"hav\",[11,12]],[\"have\",[11,12]],[\"st\",[11,16,3,4,10,19,14,22,20,21,12]],[\"sta\",[11,16,3,4,10,19,22,20,21,12]],[\"stat\",[11,16,3,19,22,20,21,12]],[\"stati\",[11,16,3,19,22,20,21,12]],[\"static\",[11,16,3,19,22,20,21,12]],[\"ip\",[11]],[\"ad\",[11]],[\"add\",[11]],[\"addr\",[11]],[\"addre\",[11]],[\"addres\",[11]],[\"address\",[11]],[\"f\",[11,2,18,7,3,4,1,10,19,6,14,8,9,22,20,21,17,12]],[\"fr\",[11,2,18,3,4,1,10,14,8,9,22,20]],[\"fro\",[11,2,18,3,1,14,8,9,22,20]],[\"from\",[11,18,3,1,14,8,9,22,20]],[\"isp\",[11]],[\"bui\",[11,7,16,1,8,9,20,21]],[\"buil\",[11,7,16,1,8,9,20,21]],[\"built\",[11,7,16,21]],[\"l\",[11,2,18,7,3,4,1,10,19,20,21,17,12]],[\"li\",[11,2,7,4,1,10,19,21,17,12]],[\"lit\",[11,10]],[\"litt\",[11,10]],[\"littl\",[11,10]],[\"little\",[11,10]],[\"sc\",[11,1,20]],[\"scr\",[11,1,20]],[\"scri\",[11]],[\"scrip\",[11]],[\"script\",[11]],[\"fo\",[11,18,7,4,6,14,8,9,22,20,21,17,12]],[\"for\",[11,18,7,4,6,8,9,22,20,21,12]],[\"ro\",[11,2,13]],[\"rou\",[11,2]],[\"rout\",[11]],[\"route\",[11]],[\"route5\",[11]],[\"route53\",[11]],[\"u\",[11,2,7,5,3,4,10,6,8,9,21,17]],[\"us\",[11,7,5,4,6,8,17]],[\"usi\",[11,5,4,6]],[\"usin\",[11,5,4,6]],[\"using\",[11,5,4,6]],[\"th\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"tha\",[11,2,5,3,19,22,21,17,15,13]],[\"that\",[11,2,3,19,22,21,17,15,13]],[\"ru\",[11,12]],[\"run\",[11,12]],[\"runs\",[11]],[\"py\",[2]],[\"pyt\",[2]],[\"pyth\",[2]],[\"pytho\",[2]],[\"python\",[2]],[\"ai\",[2]],[\"e\",[2,5,16,4,6,8,9,20,17,15,13]],[\"ev\",[2,8,17,15,13]],[\"eve\",[2,17,15,13]],[\"even\",[2,15,13]],[\"event\",[2]],[\"events\",[2]],[\"ba\",[2,5,9]],[\"bat\",[2,5]],[\"batt\",[2,5]],[\"battl\",[2,5]],[\"battle\",[2,5]],[\"battles\",[2,5]],[\"battlesn\",[2,5]],[\"battlesna\",[2,5]],[\"battlesnak\",[2,5]],[\"battlesnake\",[2,5]],[\"pr\",[2,3,4,1,19,6,8,9,20,21,17]],[\"pro\",[2,3,4,1,19,6,8,9,20,21]],[\"prog\",[2,4,1]],[\"progr\",[2,4,1]],[\"progra\",[2,4,1]],[\"program\",[2,4,1]],[\"programm\",[2,4,1]],[\"programmi\",[2,4,1]],[\"programmin\",[2,4,1]],[\"programming\",[2,4,1]],[\"c\",[2,18,7,5,16,4,1,19,6,8,9,20,21,17,15,12,13]],[\"co\",[2,18,5,16,1,6,9,21,15]],[\"com\",[2,1,9,21]],[\"comp\",[2,1,9,21]],[\"compe\",[2]],[\"compet\",[2]],[\"competi\",[2]],[\"competit\",[2]],[\"competiti\",[2]],[\"competitio\",[2]],[\"competition\",[2]],[\"wh\",[2,9,17,15,12,13]],[\"whe\",[2,9]],[\"wher\",[2]],[\"where\",[2]],[\"pa\",[2,18,5,16,1,19,8,9,22,20,21,15]],[\"par\",[2,5,1,8,9,22,20,21,15]],[\"part\",[2,5,1,8,9,22,20,21,15]],[\"parti\",[2]],[\"partic\",[2]],[\"partici\",[2]],[\"particip\",[2]],[\"participa\",[2]],[\"participan\",[2]],[\"participants\",[2]],[\"cr\",[2,6,20,21]],[\"cre\",[2,6,20,21]],[\"crea\",[2,6,20,21]],[\"creat\",[2,6,20,21]],[\"create\",[2,20,21]],[\"an\",[2,18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"se\",[2,7,5,8,9,22,20,21,13]],[\"ser\",[2,20,21]],[\"serv\",[2]],[\"serve\",[2]],[\"server\",[2]],[\"act\",[2,5,6,12,13]],[\"acts\",[2]],[\"as\",[2,18,5,3,10,9,17,13]],[\"the\",[2,18,7,16,4,10,19,14,8,9,22,20,21,17,15]],[\"br\",[2,13]],[\"bra\",[2]],[\"brai\",[2]],[\"brain\",[2]],[\"of\",[2,5,3,10,9,20,21,17,15,12]],[\"sn\",[2]],[\"sna\",[2]],[\"snak\",[2]],[\"snake\",[2]],[\"cl\",[2,19,20,17]],[\"cla\",[2]],[\"clas\",[2]],[\"class\",[2]],[\"classi\",[2]],[\"classic\",[2]],[\"g\",[2,18,5,16,3,4,10,19,6,14,8,9,22,20,21,15,12,13]],[\"ga\",[2,4,10,8,9]],[\"gam\",[2,4,10,8,9]],[\"game\",[2,4,10]],[\"compete\",[2]],[\"roun\",[2]],[\"round\",[2]],[\"rob\",[2]],[\"robi\",[2]],[\"robin\",[2]],[\"tou\",[2]],[\"tour\",[2]],[\"tourn\",[2]],[\"tourna\",[2]],[\"tournam\",[2]],[\"tourname\",[2]],[\"tournamen\",[2]],[\"tournament\",[2]],[\"pl\",[2,17]],[\"pla\",[2]],[\"play\",[2]],[\"playe\",[2]],[\"played\",[2]],[\"ou\",[2,3,20]],[\"out\",[2,20]],[\"liv\",[2,21]],[\"live\",[2,21]],[\"fron\",[2,3]],[\"front\",[2,3]],[\"au\",[2,18,6,13]],[\"aud\",[2]],[\"audi\",[2]],[\"audie\",[2]],[\"audien\",[2]],[\"audienc\",[2]],[\"audience\",[2]],[\"roug\",[2]],[\"rough\",[2]],[\"roughl\",[2]],[\"roughly\",[2]],[\"pe\",[2,17]],[\"peo\",[2]],[\"peop\",[2]],[\"peopl\",[2]],[\"people\",[2]],[\"wi\",[2,18,16,4,1,19,9,21,15]],[\"win\",[2]],[\"winn\",[2]],[\"winne\",[2]],[\"winner\",[2]],[\"ta\",[2,18,10,19,17,15]],[\"tak\",[2,18,10,17]],[\"take\",[2,18]],[\"takes\",[2]],[\"up\",[2,3,4,10,9,17]],[\"bo\",[18,9]],[\"boo\",[18]],[\"book\",[18]],[\"not\",[18,4,1,17]],[\"note\",[18,17]],[\"notes\",[18]],[\"de\",[18,7,5,16,4,1,10,6,14,20,21,17,13]],[\"dev\",[18,7,5,4,10,14,13]],[\"devo\",[18,5,14,13]],[\"devop\",[18,5,14,13]],[\"devops\",[18,5,14,13]],[\"aut\",[18,6,13]],[\"auto\",[18,6,13]],[\"autom\",[18,6,13]],[\"automa\",[18,6,13]],[\"automat\",[18,6,13]],[\"automati\",[18,6,13]],[\"automatio\",[18,6,13]],[\"automation\",[18,6,13]],[\"te\",[18,5,4,13]],[\"tes\",[18,5]],[\"test\",[18,5]],[\"testi\",[18]],[\"testin\",[18]],[\"testing\",[18]],[\"con\",[18,5,16,6,9]],[\"cont\",[18,5,6]],[\"conti\",[18,5,6]],[\"contin\",[18,5,6]],[\"continu\",[18,5,6]],[\"continuo\",[18,5,6]],[\"continuou\",[18,5,6]],[\"continuous\",[18,5,6]],[\"int\",[18,5,10,6,20,21,17,13]],[\"inte\",[18,5,6,21,17,13]],[\"integ\",[18,5,6]],[\"integr\",[18,5,6]],[\"integra\",[18,5,6]],[\"integrat\",[18,5,6]],[\"integrati\",[18,5,6]],[\"integratio\",[18,5,6]],[\"integration\",[18,5,6]],[\"dep\",[18,16,6]],[\"depl\",[18,16,6]],[\"deplo\",[18,16,6]],[\"deploy\",[18,16,6]],[\"deploym\",[18,16,6]],[\"deployme\",[18,16,6]],[\"deploymen\",[18,16,6]],[\"deployment\",[18,16,6]],[\"ci\",[18,5,6,12]],[\"cic\",[18,5,6,12]],[\"cicd\",[18,5,6,12]],[\"cod\",[18]],[\"code\",[18]],[\"gi\",[18,5,16,6,12,13]],[\"git\",[18,5,16,6,12,13]],[\"fe\",[18,20]],[\"fee\",[18]],[\"feed\",[18]],[\"feedb\",[18]],[\"feedba\",[18]],[\"feedbac\",[18]],[\"feedback\",[18]],[\"lo\",[18,3,4,20]],[\"loo\",[18,4,20]],[\"loop\",[18,4]],[\"loops\",[18,4]],[\"le\",[18,10,12]],[\"lea\",[18,10,12]],[\"lear\",[18,10,12]],[\"learn\",[18,10,12]],[\"learni\",[18,10,12]],[\"learnin\",[18,10,12]],[\"learning\",[18,10,12]],[\"handb\",[18]],[\"handbo\",[18]],[\"handboo\",[18]],[\"handbook\",[18]],[\"he\",[18,4,6,14,21,12]],[\"her\",[18,6,14,21,12]],[\"here\",[18,6,14,21,12]],[\"ar\",[18,1,10,19,14,9,20,21]],[\"are\",[18,14,9]],[\"po\",[18,19,22,17]],[\"poi\",[18]],[\"poin\",[18]],[\"point\",[18]],[\"form\",[18,8,9]],[\"takea\",[18]],[\"takeaw\",[18]],[\"takeawa\",[18]],[\"takeaway\",[18]],[\"takeaways\",[18]],[\"m\",[18,7,5,3,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"my\",[18,5,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"re\",[18,7,16,14,15,13]],[\"rea\",[18,7,16]],[\"read\",[18]],[\"readi\",[18]],[\"readin\",[18]],[\"reading\",[18]],[\"by\",[18,19,9]],[\"j\",[18,7,5,16,3,4,1,19,6,22,20,21,12,13]],[\"jo\",[18,1,6,13]],[\"joh\",[18]],[\"john\",[18]],[\"wil\",[18]],[\"will\",[18]],[\"willi\",[18]],[\"willis\",[18]],[\"ge\",[18,16,4,19,22,20,21,12,13]],[\"gen\",[18,16,4,19,22,20,21,12]],[\"gene\",[18,16,4,19,22,20,21,12]],[\"k\",[18,1,14,12,13]],[\"ki\",[18,1,14]],[\"kim\",[18]],[\"and\",[18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"pat\",[18]],[\"patr\",[18]],[\"patri\",[18]],[\"patric\",[18]],[\"patrick\",[18]],[\"deb\",[18]],[\"debo\",[18]],[\"deboi\",[18]],[\"debois\",[18]],[\"reac\",[7,16]],[\"react\",[7,16]],[\"da\",[7,17,15,13]],[\"dar\",[7]],[\"dark\",[7]],[\"mo\",[7,10,20,17,13]],[\"mod\",[7]],[\"mode\",[7]],[\"ja\",[7,5,16,4,19,22,20,21]],[\"jav\",[7,5,16,4,19,22,20,21]],[\"java\",[7,5,16,4,19,22,20,21]],[\"javas\",[7,5,16,4,19,22,20,21]],[\"javasc\",[7,5,16,4,19,22,20,21]],[\"javascr\",[7,5,16,4,19,22,20,21]],[\"javascri\",[7,5,16,4,19,22,20,21]],[\"javascrip\",[7,5,16,4,19,22,20,21]],[\"javascript\",[7,5,16,4,19,22,20,21]],[\"we\",[7,19,14,20,21]],[\"web\",[7,19,14,20,21]],[\"webd\",[7,19,14]],[\"webde\",[7,19,14]],[\"webdev\",[7,19,14]],[\"tog\",[7]],[\"togg\",[7]],[\"toggl\",[7]],[\"toggle\",[7]],[\"deve\",[7,10,13]],[\"devel\",[7,10,13]],[\"develo\",[7,10,13]],[\"develop\",[7,10,13]],[\"develope\",[7,13]],[\"developed\",[7]],[\"lig\",[7,4,17]],[\"ligh\",[7,4,17]],[\"light\",[7,4,17]],[\"them\",[7]],[\"theme\",[7]],[\"thi\",[7,4,1,10,19,8,9,22,20,21,17,15,12,13]],[\"this\",[7,4,1,10,19,8,9,22,20,21,17,15,13]],[\"si\",[7,16,19,22,20,21,12]],[\"sit\",[7,16,19,22,20,21,12]],[\"site\",[7,16,19,22,20,21,12]],[\"sw\",[7]],[\"swi\",[7]],[\"swit\",[7]],[\"switc\",[7]],[\"switch\",[7]],[\"be\",[7,3,4,1,10,19,6,20,13]],[\"bet\",[7,4]],[\"betw\",[7]],[\"betwe\",[7]],[\"betwee\",[7]],[\"between\",[7]],[\"al\",[7,19,8,9,22]],[\"als\",[7]],[\"also\",[7]],[\"use\",[7,8,17]],[\"used\",[7]],[\"me\",[7,1,8,15,13]],[\"med\",[7]],[\"medi\",[7]],[\"media\",[7]],[\"q\",[7,21]],[\"qu\",[7,21]],[\"que\",[7]],[\"quer\",[7]],[\"queri\",[7]],[\"querie\",[7]],[\"queries\",[7]],[\"set\",[7,5]],[\"def\",[7]],[\"defa\",[7]],[\"defau\",[7]],[\"defaul\",[7]],[\"default\",[7]],[\"ma\",[7,19,8]],[\"mat\",[7]],[\"matc\",[7]],[\"match\",[7]],[\"v\",[7,4,14,12]],[\"vi\",[7]],[\"vis\",[7]],[\"visi\",[7]],[\"visit\",[7]],[\"visito\",[7]],[\"visitor\",[7]],[\"visitors\",[7]],[\"op\",[7,22,20]],[\"ope\",[7]],[\"oper\",[7]],[\"opera\",[7]],[\"operat\",[7]],[\"operati\",[7]],[\"operatin\",[7]],[\"operating\",[7]],[\"sy\",[7,14,9,17,15,12]],[\"sys\",[7,9]],[\"syst\",[7,9]],[\"syste\",[7,9]],[\"system\",[7,9]],[\"ch\",[7,20]],[\"cho\",[7]],[\"choi\",[7]],[\"choic\",[7]],[\"choice\",[7]],[\"ty\",[5,16,19,6,22,20,21]],[\"typ\",[5,16,19,6,22,20,21]],[\"type\",[5,16,19,6,22,20,21]],[\"types\",[5,16,19,6,22,20,21]],[\"typesc\",[5,16,19,6]],[\"typescr\",[5,16,19,6]],[\"typescri\",[5,16,19,6]],[\"typescrip\",[5,16,19,6]],[\"typescript\",[5,16,19,6]],[\"den\",[5]],[\"deno\",[5]],[\"gith\",[5,16,6,12,13]],[\"githu\",[5,16,6,12,13]],[\"github\",[5,16,6,12,13]],[\"acti\",[5,6,12,13]],[\"actio\",[5,6,12,13]],[\"action\",[5,6,12,13]],[\"actions\",[5,6,12,13]],[\"tests\",[5]],[\"tr\",[5,19,13]],[\"tra\",[5,13]],[\"tran\",[5]],[\"trans\",[5]],[\"transl\",[5]],[\"transla\",[5]],[\"translat\",[5]],[\"translati\",[5]],[\"translatin\",[5]],[\"translating\",[5]],[\"wante\",[5]],[\"wanted\",[5]],[\"setu\",[5]],[\"setup\",[5]],[\"it\",[5,10,9,21,13]],[\"was\",[5,19,22]],[\"mu\",[5]],[\"muc\",[5]],[\"much\",[5]],[\"ea\",[5,16]],[\"eas\",[5,16]],[\"easi\",[5,16]],[\"easie\",[5]],[\"easier\",[5]],[\"than\",[5]],[\"im\",[5,4,19,22,21,12]],[\"ima\",[5]],[\"imag\",[5]],[\"imagi\",[5]],[\"imagin\",[5]],[\"imagine\",[5]],[\"imagined\",[5]],[\"pag\",[16,19]],[\"page\",[16,19]],[\"pages\",[16,19]],[\"nex\",[16,19,14,22,20,21]],[\"next\",[16,19,14,22,20,21]],[\"nextj\",[16,19,14,22,20,21]],[\"nextjs\",[16,19,14,22,20,21]],[\"gener\",[16,4,19,22,20,21,12]],[\"genera\",[16,4,19,22,20,21,12]],[\"generat\",[16,19,22,20,21,12]],[\"generato\",[16,19,22,20,21,12]],[\"generator\",[16,19,22,20,21,12]],[\"generators\",[16,19,22,20,21,12]],[\"cov\",[16,9]],[\"cove\",[16,9]],[\"cover\",[16,9]],[\"conf\",[16]],[\"confi\",[16]],[\"config\",[16]],[\"ste\",[16]],[\"step\",[16]],[\"steps\",[16]],[\"nec\",[16]],[\"nece\",[16]],[\"neces\",[16]],[\"necess\",[16]],[\"necessa\",[16]],[\"necessar\",[16]],[\"necessary\",[16]],[\"easil\",[16]],[\"easily\",[16]],[\"wit\",[16,4,1,19,9,21,15]],[\"with\",[16,4,1,19,9,21,15]],[\"gr\",[3,8]],[\"gra\",[3,8]],[\"grai\",[3]],[\"grail\",[3]],[\"grails\",[3]],[\"mi\",[3,15]],[\"mig\",[3]],[\"migr\",[3]],[\"migra\",[3]],[\"migrat\",[3]],[\"migrati\",[3]],[\"migratin\",[3]],[\"migrating\",[3]],[\"fronte\",[3]],[\"fronten\",[3]],[\"frontend\",[3]],[\"ass\",[3,9]],[\"asse\",[3,9]],[\"asset\",[3]],[\"assets\",[3]],[\"du\",[3]],[\"dur\",[3]],[\"duri\",[3]],[\"durin\",[3]],[\"during\",[3]],[\"upg\",[3,9]],[\"upgr\",[3,9]],[\"upgra\",[3,9]],[\"upgrad\",[3,9]],[\"upgrade\",[3,9]],[\"upgradi\",[3]],[\"upgradin\",[3]],[\"upgrading\",[3]],[\"our\",[3]],[\"ap\",[3]],[\"app\",[3]],[\"appl\",[3]],[\"appli\",[3]],[\"applic\",[3]],[\"applica\",[3]],[\"applicat\",[3]],[\"applicati\",[3]],[\"applicatio\",[3]],[\"application\",[3]],[\"has\",[3]],[\"bee\",[3,13]],[\"been\",[3,13]],[\"lon\",[3]],[\"long\",[3]],[\"proc\",[3,8]],[\"proce\",[3,8]],[\"proces\",[3,8]],[\"process\",[3,8]],[\"ju\",[3,12]],[\"jus\",[3,12]],[\"just\",[3,12]],[\"one\",[3,19,15]],[\"pie\",[3]],[\"piec\",[3]],[\"piece\",[3]],[\"p5\",[4]],[\"p5j\",[4]],[\"p5js\",[4]],[\"lights\",[4]],[\"lightsh\",[4]],[\"lightshi\",[4]],[\"lightshif\",[4]],[\"lightshift\",[4]],[\"star\",[4,10]],[\"start\",[4,10]],[\"starte\",[4,10]],[\"started\",[4,10]],[\"proj\",[4,19,6,20,21]],[\"proje\",[4,19,6,20,21]],[\"projec\",[4,19,6,20,21]],[\"project\",[4,19,6,20,21]],[\"hel\",[4]],[\"help\",[4]],[\"tea\",[4,13]],[\"teac\",[4]],[\"teach\",[4]],[\"mys\",[4,15]],[\"myse\",[4,15]],[\"mysel\",[4,15]],[\"myself\",[4,15]],[\"bett\",[4]],[\"bette\",[4]],[\"better\",[4]],[\"ob\",[4,17]],[\"obj\",[4]],[\"obje\",[4]],[\"objec\",[4]],[\"object\",[4]],[\"ori\",[4]],[\"orie\",[4]],[\"orien\",[4]],[\"orient\",[4]],[\"oriente\",[4]],[\"oriented\",[4]],[\"str\",[4]],[\"stru\",[4]],[\"struc\",[4]],[\"struct\",[4]],[\"structu\",[4]],[\"structur\",[4]],[\"structure\",[4]],[\"upd\",[4]],[\"upda\",[4]],[\"updat\",[4]],[\"update\",[4]],[\"updated\",[4]],[\"updatedr\",[4]],[\"updatedra\",[4]],[\"updatedraw\",[4]],[\"general\",[4]],[\"imp\",[4,22,21]],[\"impl\",[4,22]],[\"imple\",[4,22]],[\"implem\",[4,22]],[\"impleme\",[4,22]],[\"implemen\",[4,22]],[\"implement\",[4,22]],[\"implemente\",[4,22]],[\"implemented\",[4,22]],[\"fra\",[4]],[\"fram\",[4]],[\"frame\",[4]],[\"framew\",[4]],[\"framewo\",[4]],[\"framewor\",[4]],[\"framework\",[4]],[\"dr\",[4]],[\"dra\",[4]],[\"draw\",[4]],[\"ca\",[4,8,13]],[\"can\",[4]],[\"canv\",[4]],[\"canva\",[4]],[\"canvas\",[4]],[\"drawi\",[4]],[\"drawin\",[4]],[\"drawing\",[4]],[\"fu\",[4,9,22,17]],[\"fun\",[4,22,17]],[\"func\",[4,22,17]],[\"funct\",[4,22,17]],[\"functi\",[4,22,17]],[\"functio\",[4,22,17]],[\"function\",[4,22,17]],[\"functiona\",[4,22,17]],[\"functional\",[4,22,17]],[\"functionality\",[4,22,17]],[\"noth\",[4]],[\"nothi\",[4]],[\"nothin\",[4]],[\"nothing\",[4]],[\"el\",[4,6]],[\"els\",[4]],[\"else\",[4]],[\"va\",[4,14]],[\"van\",[4]],[\"vani\",[4]],[\"vanil\",[4]],[\"vanill\",[4]],[\"vanilla\",[4]],[\"mec\",[1]],[\"mech\",[1]],[\"mecha\",[1]],[\"mechan\",[1]],[\"mechani\",[1]],[\"mechanic\",[1]],[\"mechanica\",[1]],[\"mechanical\",[1]],[\"ke\",[1]],[\"key\",[1]],[\"keyb\",[1]],[\"keybo\",[1]],[\"keyboa\",[1]],[\"keyboar\",[1]],[\"keyboard\",[1]],[\"keyboards\",[1]],[\"ard\",[1]],[\"ardu\",[1]],[\"ardui\",[1]],[\"arduin\",[1]],[\"arduino\",[1]],[\"c+\",[1]],[\"c++\",[1]],[\"har\",[1,14,8,9,17,15]],[\"hard\",[1,14,8,9,17,15]],[\"hardw\",[1,14,8,9,17,15]],[\"hardwa\",[1,14,8,9,17,15]],[\"hardwar\",[1,14,8,9,17,15]],[\"hardware\",[1,14,8,9,17,15]],[\"build\",[1,8,9,20,21]],[\"buildi\",[1,21]],[\"buildin\",[1,21]],[\"building\",[1,21]],[\"scra\",[1,20]],[\"scrat\",[1,20]],[\"scratc\",[1,20]],[\"scratch\",[1,20]],[\"af\",[1,20]],[\"aft\",[1,20]],[\"afte\",[1,20]],[\"after\",[1,20]],[\"bec\",[1]],[\"beco\",[1]],[\"becom\",[1]],[\"becomi\",[1]],[\"becomin\",[1]],[\"becoming\",[1]],[\"infa\",[1]],[\"infat\",[1]],[\"infatu\",[1]],[\"infatua\",[1]],[\"infatuat\",[1]],[\"infatuate\",[1]],[\"infatuated\",[1]],[\"cu\",[1,9]],[\"cus\",[1,9]],[\"cust\",[1,9]],[\"custo\",[1,9]],[\"custom\",[1,9]],[\"dec\",[1,20]],[\"deci\",[1,20]],[\"decid\",[1,20]],[\"decide\",[1,20]],[\"decided\",[1,20]],[\"ow\",[1,20,17,15]],[\"own\",[1,20,17,15]],[\"kit\",[1]],[\"lik\",[1,12]],[\"like\",[1,12]],[\"jou\",[1,6]],[\"jour\",[1,6]],[\"journ\",[1,6]],[\"journe\",[1,6]],[\"journey\",[1,6]],[\"thr\",[1]],[\"thro\",[1]],[\"throu\",[1]],[\"throug\",[1]],[\"through\",[1]],[\"des\",[1,21,17]],[\"desi\",[1]],[\"desig\",[1]],[\"design\",[1]],[\"designi\",[1]],[\"designin\",[1]],[\"designing\",[1]],[\"aq\",[1]],[\"aqu\",[1]],[\"aqui\",[1]],[\"aquir\",[1]],[\"aquiri\",[1]],[\"aquirin\",[1]],[\"aquiring\",[1]],[\"parts\",[1,9]],[\"compl\",[1]],[\"comple\",[1]],[\"complet\",[1]],[\"complete\",[1]],[\"la\",[1]],[\"lay\",[1]],[\"layo\",[1]],[\"layou\",[1]],[\"layout\",[1]],[\"designe\",[1]],[\"designed\",[1]],[\"un\",[10]],[\"uni\",[10]],[\"unit\",[10]],[\"unity\",[10]],[\"go\",[10,19,14,15]],[\"god\",[10]],[\"godo\",[10]],[\"godot\",[10]],[\"pix\",[10]],[\"pixe\",[10]],[\"pixel\",[10]],[\"art\",[10,19,20,21]],[\"intr\",[10]],[\"intro\",[10]],[\"introd\",[10]],[\"introdu\",[10]],[\"introduc\",[10]],[\"introduct\",[10]],[\"introducti\",[10]],[\"introduction\",[10]],[\"developm\",[10,13]],[\"developme\",[10,13]],[\"developmen\",[10,13]],[\"development\",[10,13]],[\"beg\",[10]],[\"bega\",[10]],[\"began\",[10]],[\"hob\",[10]],[\"hobb\",[10]],[\"hobby\",[10]],[\"now\",[10,22]],[\"begi\",[10]],[\"begin\",[10]],[\"beginn\",[10]],[\"beginni\",[10]],[\"beginnin\",[10]],[\"beginning\",[10]],[\"taki\",[10,17]],[\"takin\",[10,17]],[\"taking\",[10,17]],[\"mos\",[10]],[\"most\",[10]],[\"fre\",[10]],[\"free\",[10]],[\"ti\",[10,12]],[\"tim\",[10,12]],[\"time\",[10,12]],[\"into\",[10,6,20,21,13]],[\"how\",[10,20,17,13]],[\"got\",[10,14,15]],[\"too\",[10]],[\"tool\",[10]],[\"tools\",[10]],[\"learne\",[10]],[\"learned\",[10]],[\"tag\",[19]],[\"goa\",[19]],[\"goal\",[19]],[\"mak\",[19]],[\"make\",[19]],[\"tags\",[19]],[\"alr\",[19]],[\"alre\",[19]],[\"alrea\",[19]],[\"alread\",[19]],[\"already\",[19]],[\"di\",[19,20]],[\"dis\",[19,20]],[\"disp\",[19]],[\"displ\",[19]],[\"displa\",[19]],[\"display\",[19]],[\"displayi\",[19]],[\"displayin\",[19]],[\"displaying\",[19]],[\"alo\",[19]],[\"alon\",[19]],[\"along\",[19]],[\"alongs\",[19]],[\"alongsi\",[19]],[\"alongsid\",[19]],[\"alongside\",[19]],[\"arti\",[19,20,21]],[\"artic\",[19,20,21]],[\"articl\",[19,20,21]],[\"article\",[19,20,21]],[\"articles\",[19,20,21]],[\"cli\",[19,20]],[\"clic\",[19]],[\"click\",[19]],[\"clicka\",[19]],[\"clickab\",[19]],[\"clickabl\",[19]],[\"clickable\",[19]],[\"lin\",[19]],[\"link\",[19]],[\"links\",[19]],[\"fi\",[19,8,22,20,21]],[\"fil\",[19]],[\"filt\",[19]],[\"filte\",[19]],[\"filter\",[19]],[\"pos\",[19,22,17]],[\"post\",[19,22,17]],[\"posts\",[19,22]],[\"try\",[19]],[\"pip\",[6]],[\"pipe\",[6]],[\"pipel\",[6]],[\"pipeli\",[6]],[\"pipelin\",[6]],[\"pipeline\",[6]],[\"ela\",[6]],[\"elas\",[6]],[\"elast\",[6]],[\"elasti\",[6]],[\"elastic\",[6]],[\"bea\",[6]],[\"bean\",[6]],[\"beans\",[6]],[\"beanst\",[6]],[\"beansta\",[6]],[\"beanstal\",[6]],[\"beanstalk\",[6]],[\"creati\",[6]],[\"creatin\",[6]],[\"creating\",[6]],[\"automate\",[6]],[\"automated\",[6]],[\"wo\",[6,20,12]],[\"wor\",[6]],[\"work\",[6]],[\"workf\",[6]],[\"workfl\",[6]],[\"workflo\",[6]],[\"workflow\",[6]],[\"syn\",[14,17,15,12]],[\"syno\",[14,17,15,12]],[\"synol\",[14,17,15,12]],[\"synolo\",[14,17,15,12]],[\"synolog\",[14,17,15,12]],[\"synology\",[14,17,15,12]],[\"kid\",[14]],[\"kids\",[14]],[\"res\",[14]],[\"reso\",[14]],[\"resou\",[14]],[\"resour\",[14]],[\"resourc\",[14]],[\"resource\",[14]],[\"resources\",[14]],[\"fou\",[14]],[\"foun\",[14]],[\"found\",[14]],[\"val\",[14]],[\"valu\",[14]],[\"valua\",[14]],[\"valuab\",[14]],[\"valuabl\",[14]],[\"valuable\",[14]],[\"resouc\",[14]],[\"resouce\",[14]],[\"resouces\",[14]],[\"value\",[14]],[\"top\",[14]],[\"topi\",[14]],[\"topic\",[14]],[\"topics\",[14]],[\"inc\",[14]],[\"incl\",[14]],[\"inclu\",[14]],[\"includ\",[14]],[\"include\",[14]],[\"stu\",[14]],[\"stuf\",[14]],[\"stuff\",[14]],[\"pc\",[8,9]],[\"gami\",[8,9]],[\"gamin\",[8,9]],[\"gaming\",[8,9]],[\"sm\",[8,9,13]],[\"sma\",[8,9,13]],[\"smal\",[8,9,13]],[\"small\",[8,9,13]],[\"fa\",[8,9]],[\"fac\",[8,9]],[\"fact\",[8,9]],[\"facto\",[8,9]],[\"factor\",[8,9]],[\"fir\",[8,20,21]],[\"firs\",[8,20,21]],[\"first\",[8,20,21]],[\"sec\",[8,9]],[\"seco\",[8,9]],[\"secon\",[8,9]],[\"second\",[8,9]],[\"prop\",[8]],[\"prope\",[8]],[\"proper\",[8]],[\"mac\",[8]],[\"mach\",[8]],[\"machi\",[8]],[\"machin\",[8]],[\"machine\",[8]],[\"uses\",[8]],[\"ry\",[8]],[\"ryz\",[8]],[\"ryze\",[8]],[\"ryzen\",[8]],[\"5800x\",[8]],[\"processo\",[8]],[\"processor\",[8]],[\"evg\",[8]],[\"evga\",[8]],[\"rt\",[8]],[\"rtx\",[8]],[\"x\",[8]],[\"xc\",[8]],[\"xc3\",[8]],[\"ul\",[8]],[\"ult\",[8]],[\"ultr\",[8]],[\"ultra\",[8]],[\"grap\",[8]],[\"graph\",[8]],[\"graphi\",[8]],[\"graphic\",[8]],[\"graphics\",[8]],[\"car\",[8,13]],[\"card\",[8]],[\"all\",[8,9,22]],[\"135l\",[8]],[\"met\",[8]],[\"meta\",[8]],[\"metal\",[8]],[\"metalf\",[8]],[\"metalfi\",[8]],[\"metalfis\",[8]],[\"metalfish\",[8]],[\"s5\",[8]],[\"cas\",[8]],[\"case\",[8]],[\"ali\",[8]],[\"alie\",[8]],[\"aliex\",[8]],[\"aliexp\",[8]],[\"aliexpr\",[8]],[\"aliexpre\",[8]],[\"aliexpres\",[8]],[\"aliexpress\",[8]],[\"wat\",[9]],[\"wate\",[9]],[\"water\",[9]],[\"coo\",[9,15]],[\"cool\",[9,15]],[\"cooli\",[9]],[\"coolin\",[9]],[\"cooling\",[9]],[\"covers\",[9]],[\"ful\",[9]],[\"full\",[9]],[\"bot\",[9]],[\"both\",[9]],[\"cp\",[9]],[\"cpu\",[9]],[\"gp\",[9]],[\"gpu\",[9]],[\"coole\",[9]],[\"cooled\",[9]],[\"240m\",[9]],[\"240mm\",[9]],[\"rad\",[9]],[\"radi\",[9]],[\"radia\",[9]],[\"radiat\",[9]],[\"radiato\",[9]],[\"radiator\",[9]],[\"ek\",[9]],[\"ekw\",[9]],[\"ekwb\",[9]],[\"bar\",[9]],[\"barr\",[9]],[\"barro\",[9]],[\"barrow\",[9]],[\"compo\",[9,21]],[\"compon\",[9,21]],[\"compone\",[9,21]],[\"componen\",[9,21]],[\"component\",[9,21]],[\"components\",[9]],[\"pros\",[9]],[\"cons\",[9]],[\"en\",[9,20]],[\"enc\",[9]],[\"enco\",[9]],[\"encou\",[9]],[\"encoun\",[9]],[\"encount\",[9]],[\"encounte\",[9]],[\"encounter\",[9]],[\"encountere\",[9]],[\"encountered\",[9]],[\"when\",[9]],[\"assem\",[9]],[\"assemb\",[9]],[\"assembl\",[9]],[\"assembli\",[9]],[\"assemblin\",[9]],[\"assembling\",[9]],[\"typese\",[22,20,21]],[\"typesen\",[22,20,21]],[\"typesens\",[22,20,21]],[\"typesense\",[22,20,21]],[\"sea\",[22,20,21]],[\"sear\",[22,20,21]],[\"searc\",[22,20,21]],[\"search\",[22,20,21]],[\"opt\",[22,20]],[\"opti\",[22,20]],[\"optim\",[22]],[\"optimi\",[22]],[\"optimiz\",[22]],[\"optimizi\",[22]],[\"optimizin\",[22]],[\"optimizing\",[22]],[\"ind\",[22,20,21]],[\"inde\",[22,20,21]],[\"index\",[22,20,21]],[\"fin\",[22]],[\"fina\",[22]],[\"final\",[22]],[\"optimiza\",[22]],[\"optimizat\",[22]],[\"optimizati\",[22]],[\"optimizations\",[22]],[\"allu\",[22]],[\"allud\",[22]],[\"allude\",[22]],[\"alluded\",[22]],[\"ab\",[22,15]],[\"abl\",[22]],[\"able\",[22]],[\"get\",[22,13]],[\"ish\",[22]],[\"~\",[22]],[\"~7\",[22]],[\"~70\",[22]],[\"~700\",[22]],[\"~700k\",[22]],[\"~700kb\",[22]],[\"dow\",[22]],[\"down\",[22]],[\"~2\",[22]],[\"~22\",[22]],[\"~22k\",[22]],[\"~22kb\",[22]],[\"pre\",[20,17]],[\"prep\",[20]],[\"prepr\",[20]],[\"prepro\",[20]],[\"preproc\",[20]],[\"preproce\",[20]],[\"preproces\",[20]],[\"preprocess\",[20]],[\"preprocessing\",[20]],[\"seri\",[20,21]],[\"serie\",[20,21]],[\"series\",[20,21]],[\"disc\",[20]],[\"discu\",[20]],[\"discus\",[20]],[\"discuss\",[20]],[\"created\",[20]],[\"clie\",[20]],[\"clien\",[20]],[\"client\",[20]],[\"sid\",[20]],[\"side\",[20]],[\"webs\",[20,21]],[\"websi\",[20,21]],[\"websit\",[20,21]],[\"website\",[20,21]],[\"look\",[20]],[\"looki\",[20]],[\"lookin\",[20]],[\"looking\",[20]],[\"at\",[20,13]],[\"few\",[20]],[\"optio\",[20]],[\"option\",[20]],[\"options\",[20]],[\"ther\",[20]],[\"there\",[20]],[\"sites\",[20]],[\"projects\",[20]],[\"cha\",[20]],[\"chal\",[20]],[\"chall\",[20]],[\"challe\",[20]],[\"challen\",[20]],[\"challeng\",[20]],[\"challenge\",[20]],[\"wou\",[20]],[\"woul\",[20]],[\"would\",[20]],[\"mor\",[20,17,13]],[\"more\",[20,17,13]],[\"enj\",[20]],[\"enjo\",[20]],[\"enjoy\",[20]],[\"enjoya\",[20]],[\"enjoyab\",[20]],[\"enjoyabl\",[20]],[\"enjoyable\",[20]],[\"discusse\",[20]],[\"discusses\",[20]],[\"fol\",[21,17]],[\"foll\",[21,17]],[\"follo\",[21,17]],[\"follow\",[21,17]],[\"followu\",[21]],[\"followup\",[21]],[\"qui\",[21]],[\"quic\",[21]],[\"quick\",[21]],[\"searchi\",[21]],[\"searchin\",[21]],[\"searching\",[21]],[\"il\",[21,15]],[\"ill\",[21,15]],[\"impo\",[21]],[\"impor\",[21]],[\"import\",[21]],[\"ui\",[21]],[\"inter\",[21,17,13]],[\"intera\",[21]],[\"interac\",[21]],[\"interact\",[21]],[\"desc\",[21,17]],[\"descr\",[21,17]],[\"descri\",[21,17]],[\"describ\",[21,17]],[\"describe\",[21,17]],[\"described\",[21]],[\"na\",[17,15]],[\"nas\",[17,15]],[\"dat\",[17,15]],[\"data\",[17,15]],[\"owne\",[17,15]],[\"owner\",[17,15]],[\"owners\",[17,15]],[\"ownersh\",[17,15]],[\"ownershi\",[17,15]],[\"ownership\",[17,15]],[\"ph\",[17]],[\"pho\",[17]],[\"phot\",[17]],[\"photo\",[17]],[\"photos\",[17]],[\"obs\",[17]],[\"obsi\",[17]],[\"obsid\",[17]],[\"obsidi\",[17]],[\"obsidia\",[17]],[\"obsidian\",[17]],[\"ple\",[17]],[\"plex\",[17]],[\"lightr\",[17]],[\"lightro\",[17]],[\"lightroo\",[17]],[\"lightroom\",[17]],[\"per\",[17]],[\"pers\",[17]],[\"perso\",[17]],[\"person\",[17]],[\"persona\",[17]],[\"personal\",[17]],[\"clo\",[17]],[\"clou\",[17]],[\"cloud\",[17]],[\"prev\",[17]],[\"previ\",[17]],[\"previo\",[17]],[\"previou\",[17]],[\"previous\",[17]],[\"describi\",[17]],[\"describin\",[17]],[\"describing\",[17]],[\"wha\",[17,15,12,13]],[\"what\",[17,15,12,13]],[\"intere\",[17,13]],[\"interes\",[17,13]],[\"interest\",[17,13]],[\"interesti\",[17]],[\"interestin\",[17]],[\"interesting\",[17]],[\"ever\",[17]],[\"every\",[17]],[\"day\",[17,13]],[\"rec\",[15]],[\"rece\",[15]],[\"recen\",[15]],[\"recent\",[15]],[\"recentl\",[15]],[\"recently\",[15]],[\"doe\",[15,13]],[\"does\",[15,13]],[\"mea\",[15,13]],[\"mean\",[15,13]],[\"tw\",[15]],[\"two\",[15]],[\"tal\",[15]],[\"talk\",[15]],[\"bi\",[15]],[\"bit\",[15]],[\"abo\",[15]],[\"abou\",[15]],[\"about\",[15]],[\"thin\",[15,12]],[\"thing\",[15,12]],[\"things\",[15,12]],[\"min\",[15]],[\"mine\",[15]],[\"doc\",[12]],[\"dock\",[12]],[\"docke\",[12]],[\"docker\",[12]],[\"neo\",[12]],[\"neov\",[12]],[\"neovi\",[12]],[\"neovim\",[12]],[\"vp\",[12]],[\"vpn\",[12]],[\"ss\",[12]],[\"ssl\",[12]],[\"rund\",[12]],[\"rundo\",[12]],[\"rundow\",[12]],[\"rundown\",[12]],[\"id\",[12]],[\"kn\",[12,13]],[\"kno\",[12,13]],[\"know\",[12,13]],[\"won\",[12]],[\"wont\",[12]],[\"rol\",[13]],[\"role\",[13]],[\"sof\",[13]],[\"soft\",[13]],[\"softw\",[13]],[\"softwa\",[13]],[\"softwar\",[13]],[\"software\",[13]],[\"developer\",[13]],[\"job\",[13]],[\"i‚Äô\",[13]],[\"i‚Äôv\",[13]],[\"i‚Äôve\",[13]],[\"gett\",[13]],[\"getti\",[13]],[\"gettin\",[13]],[\"getting\",[13]],[\"intereste\",[13]],[\"interested\",[13]],[\"care\",[13]],[\"caree\",[13]],[\"career\",[13]],[\"traj\",[13]],[\"traje\",[13]],[\"trajec\",[13]],[\"traject\",[13]],[\"trajecto\",[13]],[\"trajector\",[13]],[\"trajectory\",[13]],[\"bri\",[13]],[\"brie\",[13]],[\"brief\",[13]],[\"ex\",[13]],[\"exp\",[13]],[\"expl\",[13]],[\"explo\",[13]],[\"explor\",[13]],[\"explora\",[13]],[\"explorat\",[13]],[\"explorati\",[13]],[\"exploratio\",[13]],[\"exploration\",[13]],[\"see\",[13]],[\"rel\",[13]],[\"rela\",[13]],[\"relat\",[13]],[\"relati\",[13]],[\"relatin\",[13]],[\"relating\",[13]],[\"team\",[13]]]","postMetadataList":[{"title":"AWS Dynamic DNS","slug":"aws-ddns","date":"March 20, 2022","hero":"/images/posts/aws-ddns.jpg","excerpt":"A dynamic DNS is handy if you want to host something or access something on your home network but you don't have a static IP address from your ISP. I built a little dynamic DNS script for AWS Route53 using Node that runs on a Raspberry Pi.","tags":["aws","ddns","node","raspberry-pi","infrastructure"],"id":11,"readTimeInMinutes":5},{"title":"Battlesnake Programming Competition 2018","slug":"battlesnake-2018","date":"June 11, 2018","hero":"/images/posts/Battlesnake2018-1.jpg","excerpt":"Battlesnake is a programming competition where participants create an AI server that acts as the brain of a snake in the classic game Snake. Participants compete in a round-robin tournament played out live in front of an audience of roughly 1000 people. The winner takes home up to $4,000!","tags":["python","ai","events","battlesnake"],"id":2,"readTimeInMinutes":18},{"title":"Book Notes: DevOps Handbook, The","slug":"book-notes-devops-handbook","date":"August 27, 2023","hero":"/images/posts/devopshandbook.png","excerpt":"Here are some point-form takeaways from my notes from reading The DevOps Handbook by John Willis, Gene Kim, and Patrick Debois.","tags":["book-notes","devops","automation","testing","continuous-integration","continuous-deployment","cicd","infrastructure","infrastructure-as-code","git","feedback-loops","continuous-learning"],"id":18,"readTimeInMinutes":8},{"title":"Dark Mode React Toggle","slug":"dark-mode-react-toggle","date":"June 28, 2020","hero":"/images/posts/DarkModeToggle-1.svg","excerpt":"I developed a dark and light theme for this site and built a toggle to switch between them. Also I used media queries to set the default theme to match the visitors operating system choice.","tags":["react","dark-mode","javascript","webdev"],"id":7,"readTimeInMinutes":6},{"title":"Deno Tests & GitHub Actions CI","slug":"deno-and-github-actions","date":"May 23, 2020","hero":"/images/posts/DenoTestsAndGithubActionsCI.png","excerpt":"As part of translating my JavaScript and Node Battlesnake to TypeScript and Deno I wanted to setup continuous integration. It was som much easier than I imagined using GitHub Actions.","tags":["javascript","typescript","node","deno","github-actions","cicd","devops"],"id":5,"readTimeInMinutes":6},{"title":"Deploy a Next.js Static Site to GitHub Pages","slug":"github-pages-using-nextjs","date":"July 23, 2023","hero":"/images/posts/NextJSGitHubPagesHero.png","excerpt":"I cover the config and deployment steps necessary to easily deploy a static site built with Next.js to GitHub Pages.","tags":["github-pages","nextjs","react","static-site-generators","typescript","javascript"],"id":16,"readTimeInMinutes":8},{"title":"Migrating Frontend Assets During Grails 2 ‚Üí 3 Upgrade","slug":"grails-asset-migration","date":"Dec 15, 2019","hero":"/images/posts/GrailsAssetMigration.svg","excerpt":"Upgrading our application from Grails 2 to Grails 3 has been a long process. Migrating our static frontend assets is just one piece of that process.","tags":["grails"],"id":3,"readTimeInMinutes":4},{"title":"Lightshift Game","slug":"lightshift-game","date":"Feb 1, 2020","hero":"/images/posts/lightshift-game-2.png","excerpt":"I started this project in 2018 to help teach myself better object-oriented programming structure, game update/draw loops, and JavaScript in general. Implemented using the P5.js framework for the draw loop and canvas drawing functionality with nothing else but vanilla JavaScript.","tags":["javascript","game-dev","p5js"],"id":4,"readTimeInMinutes":1},{"title":"Building a Mechanical Keyboard from Scratch","slug":"mechanical-keyboard","date":"Apr 20, 2017","hero":"/images/posts/MechanicalKeyboard-12.jpg","excerpt":"After becoming infatuated with custom mechanical keyboards I decided to build my own. Not from a kit, but like from scratch. This is my journey through designing, aquiring parts, building, and programming my own mechanical keyboard complete with a custom layout I designed.","tags":["mechanical-keyboards","arduino","c++","hardware"],"id":1,"readTimeInMinutes":17},{"title":"My Introduction to Game Development","slug":"my-introduction-to-game-development","date":"Mar 25, 2021","hero":"/images/posts/game-dev-godot.jpg","excerpt":"In 2020 I began learning game development as a hobby. Now in the beginning of 2021 it is taking up most of my free time. This is a little intro into how I got started and the tools I learned","tags":["game-dev","unity","godot","pixel-art"],"id":10,"readTimeInMinutes":8},{"title":"Next.js Tag Pages","slug":"nextjs-tag-pages","date":"March 25, 2024","hero":"/images/posts/tag-page-screenshot.png","excerpt":"My goal with this project was to make the tags I'm already displaying alongside articles to be clickable links that filter my posts by that tag. Try to click one!","tags":["nextjs","javascript","typescript","webdev","static-site-generators"],"id":19,"readTimeInMinutes":6},{"title":"Node CI/CD Pipeline using GitHub Actions & AWS Elastic Beanstalk","slug":"node-cicd-pipeline","date":"May 30, 2020","hero":"/images/posts/node-cicd-pipeline-hero.png","excerpt":"Here is my journey into creating an automated continuous integration and continuous deployment workflow for a project using GitHub Actions.","tags":["github-actions","cicd","typescript","aws","automation"],"id":6,"readTimeInMinutes":24},{"title":"Resources I Found Valuable in 2022","slug":"resources-2022","date":"Jan 20 2023","hero":"/images/posts/resources-2022-hero.jpg","excerpt":"Here are the resouces I got value from in 2023. Topics include kids, devops, web dev, and some hardware stuff.","tags":["devops","nextjs","hardware","raspberry-pi","synology","kids","webdev"],"id":14,"readTimeInMinutes":2},{"title":"Small Form Factor PC Build Part 1","slug":"sff-pc-part-1","date":"Jan 2 2021","hero":"/images/posts/sff-pc-part-1-5.jpg","excerpt":"My first small form factor gaming PC and my second proper gaming PC. This machine uses a Ryzen 7 5800X processor and a EVGA RTX 3080 XC3 Ultra graphics card, all in the 13.5L Metalfish S5 case from AliExpress.","tags":["pc","gaming","hardware"],"id":8,"readTimeInMinutes":5},{"title":"Small Form Factor PC Part 2 - Water Cooling","slug":"sff-pc-part-2","date":"Jan 25 2021","hero":"/images/posts/sff-pc-part-2-6.jpeg","excerpt":"This second part of my small form factor gaming PC build covers my upgrade to a full custom water cooling system. Both the CPU and GPU are cooled by a 240mm radiator with parts from EKWB and Barrow. I cover all of the components and all the pros and cons I encountered when assembling it.","tags":["pc","gaming","hardware"],"id":9,"readTimeInMinutes":29},{"title":"Static Site Search Part 3 - Optimizing the Index","slug":"static-site-search-optimizing-the-index","date":"April 18, 2024","hero":"/images/posts/static-site-search-optimizing-the-index.jpg","excerpt":"This is the final part (for now) on the search functionality for my site. I implemented some optimizations that I alluded to in part 1 & 2. I was able to get my search index for my 20-ish posts from ~700kb down to ~22kb!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":22,"readTimeInMinutes":8},{"title":"Static Site Search Part 1 - Preprocessing Articles","slug":"static-site-search-preprocessing-articles","date":"April 3, 2024","hero":"/images/posts/static-site-search-preprocessing-articles.jpg","excerpt":"In this series of articles I discuss how I created a client-side search for my static website. After looking at a few options out there for static sites and Next.js projects, I decided the challenge to build my own search from scratch would be more enjoyable. This first article discusses how I preprocess my articles into a search index.","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":20,"readTimeInMinutes":15},{"title":"Static Site Search Part 2 - Search Component","slug":"static-site-search-search-component","date":"April 10, 2024","hero":"/images/posts/static-site-search-search-component.jpg","excerpt":"This is the followup to Part 1 in this series on building a Static Site Search for my website. In the first part I built a search index of my articles for quick searching. In this part I'll import that search index into my Next project and create a UI to interact with it. The search component described here is live on this site!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":21,"readTimeInMinutes":7},{"title":"How I use my Synology NAS as my personal cloud","slug":"synology-nas-how-i-use-it-as-my-personal-cloud","date":"August 15, 2023","hero":"/images/posts/synology-dsm-desktop.png","excerpt":"This is a follow-up to my previous post describing what a Synology NAS is. In this post I describe some of the more interesting functionality that I use every day.","tags":["synology","nas","data-ownership","hardware","photos","note-taking","obsidian","plex","lightroom"],"id":17,"readTimeInMinutes":10},{"title":"What is a Synology NAS?","slug":"synology-nas-what-is-it","date":"July 18, 2023","hero":"/images/posts/synology-nas.png","excerpt":"I recently got myself a Synology NAS. What does that even mean? In this part one of two, I talk a bit about what a Synology NAS is. In part two, I'll talk about the cool things I do with mine.","tags":["synology","nas","data-ownership","hardware"],"id":15,"readTimeInMinutes":3},{"title":"What I'm Learning in 2022","slug":"what-im-learning-in-2022","date":"March 23, 2022","hero":"/images/posts/what-im-learning-in-2022.jpg","excerpt":"Here is a rundown of what I'm learning in 2022, what I'd like to learn in 2022, and some things I know I just wont have time for in 2022.","tags":["docker","github-actions","neovim","vpn","synology","ssl","static-site-generators","cicd","aws"],"id":12,"readTimeInMinutes":5},{"title":"What is DevOps?","slug":"what-is-devops","date":"April 10, 2022","hero":"/images/posts/development-cycle.jpg","excerpt":"In my role as a software developer at my day job, I‚Äôve been getting more interested in DevOps as a career trajectory. But what does that even mean? Do I even know? This is a brief exploration into what DevOps is and how I see it relating to a small development team.","tags":["devops","automation","github-actions"],"id":13,"readTimeInMinutes":7}]},"__N_SSG":true}