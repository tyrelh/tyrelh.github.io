<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Static Site Search Part 1 - Preprocessing Articles</title><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/78bfec90b4d3c4e5.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/78bfec90b4d3c4e5.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ba82427db781dc33.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-314c182fa7e2bf37.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-a767d6d8830842fe.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-2085c830db7ccac4.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/6597-3cf49726e8a20d02.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/669-3f18346b2147b7a6.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-c69e29c8ee91091d.js" defer="" crossorigin=""></script><script src="/_next/static/MgYhWSqL3YClZtE0TZO2Y/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/MgYhWSqL3YClZtE0TZO2Y/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><div class="ant-layout app css-djtmh8"><main class="ant-layout-content fadeIn css-djtmh8"><div id="sticky-header" class="sticky-header sticky-header-visible"><div class="breadcrumbs"><div class="toggle-container"><span role="img" aria-label="moon" tabindex="-1" class="anticon anticon-moon"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="moon" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M489.5 111.66c30.65-1.8 45.98 36.44 22.58 56.33A243.35 243.35 0 00426 354c0 134.76 109.24 244 244 244 72.58 0 139.9-31.83 186.01-86.08 19.87-23.38 58.07-8.1 56.34 22.53C900.4 745.82 725.15 912 512.5 912 291.31 912 112 732.69 112 511.5c0-211.39 164.29-386.02 374.2-399.65l.2-.01zm-81.15 79.75l-4.11 1.36C271.1 237.94 176 364.09 176 511.5 176 697.34 326.66 848 512.5 848c148.28 0 274.94-96.2 319.45-230.41l.63-1.93-.11.07a307.06 307.06 0 01-159.73 46.26L670 662c-170.1 0-308-137.9-308-308 0-58.6 16.48-114.54 46.27-162.47z"></path></svg></span></div><div class="search-affix" style="right:70px;top:2px"><div class="ant-select ant-select-outlined css-djtmh8 ant-select-single ant-select-show-arrow ant-select-show-search" style="width:300px"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" value=""/></span><span class="ant-select-selection-placeholder">Search</span></div><span class="ant-select-arrow" style="user-select:none;-webkit-user-select:none" unselectable="on" aria-hidden="true"><span role="img" aria-label="search" class="anticon anticon-search"><svg viewBox="64 64 896 896" focusable="false" data-icon="search" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0011.6 0l43.6-43.5a8.2 8.2 0 000-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></span></span></div></div><span class="anchor"><a href="/">superflux.dev</a></span><span> / <!-- -->blog</span> / <!-- -->static-site-search-preprocessing-articles</div></div><h1>Static Site Search Part 1 - Preprocessing Articles</h1><h4><span role="img" aria-label="calendar" class="anticon anticon-calendar"><svg viewBox="64 64 896 896" focusable="false" data-icon="calendar" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 184H712v-64c0-4.4-3.6-8-8-8h-56c-4.4 0-8 3.6-8 8v64H384v-64c0-4.4-3.6-8-8-8h-56c-4.4 0-8 3.6-8 8v64H144c-17.7 0-32 14.3-32 32v664c0 17.7 14.3 32 32 32h736c17.7 0 32-14.3 32-32V216c0-17.7-14.3-32-32-32zm-40 656H184V460h656v380zM184 392V256h128v48c0 4.4 3.6 8 8 8h56c4.4 0 8-3.6 8-8v-48h256v48c0 4.4 3.6 8 8 8h56c4.4 0 8-3.6 8-8v-48h128v136H184z"></path></svg></span> <!-- -->April 3, 2024</h4><p><span class="anchor"><a href="/blog/tags/static-site-generators"><span class="ant-tag css-djtmh8">#<!-- -->static-site-generators</span></a></span><span class="anchor"><a href="/blog/tags/nextjs"><span class="ant-tag css-djtmh8">#<!-- -->nextjs</span></a></span><span class="anchor"><a href="/blog/tags/javascript"><span class="ant-tag css-djtmh8">#<!-- -->javascript</span></a></span><span class="anchor"><a href="/blog/tags/typesense"><span class="ant-tag css-djtmh8">#<!-- -->typesense</span></a></span><span class="anchor"><a href="/blog/tags/search"><span class="ant-tag css-djtmh8">#<!-- -->search</span></a></span></p><p><img src="/images/posts/./static-site-search-preprocessing-articles.jpg" alt="" class="article-image"/></p><h2 id="Overview"><span class="underline">Overview</span></h2><p>So, I want a search feature for this blog. Simple as that. I need it to run client side since my website is statically compiled and served from GitHub. And I want it to be somewhat light weight.</p><p>I only have 19 posts as of writing this (this is the 20th), so the search space is relatively small now. But I&#x27;m contemplating re-writing my <a href="https://www.theverdigris.ca/" target="_blank">partners food blog</a> in my custom Next + markdown CMS. She has 100&#x27;s of posts so eventually it needs to be able to handle that amount.</p><p>I also like the idea of building it myself as much as I can. Building this website is a learning exercise and I don&#x27;t learn much by running <code class="inline-code">npm install tool-that-solves-your-problem</code>.</p><h2 id="Static Site Search Series"><span class="underline">Static Site Search Series</span></h2><p>This is the first part in a series of articles which covers creating the search index from my markdown articles.</p><p><a href="https://superflux.dev/blog/static-site-search-search-component" target="_blank">The second part is now live</a>. There I cover creating the search component and UI that uses this search index to perform searches.</p><h2 id="Pagefind"><span class="underline">Pagefind</span></h2><p>In my initial research I came across <a href="https://pagefind.app/" target="_blank">Pagefind</a>. It seems like what I wanted. Static site search with a default but customizable UI.</p><p>I tried for maybe an hour or two to get this running locally on my static site without success. I think it&#x27;s tricky to get working with Next dev mode. I found <a href="https://www.petemillspaugh.com/nextjs-search-with-pagefind" target="_blank">this article from Pete Millspaugh</a> on using Pagefind with Next. It was short on detail and didn&#x27;t help much though.</p><p>So I decided to build something myself from scratch. How hard could it be?</p><h2 id="My plan"><span class="underline">My plan</span></h2><p>Taking inspiration from Ahmad Rosid&#x27;s post on <a href="https://ahmadrosid.com/blog/fulltext-search-with-inverted-index" target="_blank">Writing full text search in Javascript for Next.js static site</a>, what I&#x27;m going to do is build an inverted index, of sorts, of the article data.</p><p>This index will contain all of my valid search terms as keys, and each key&#x27;s value will be a list of objects representing the articles that match that search term.</p><p>Building this index will happen as a preprocessing step as part of my static site&#x27;s build process.</p><p>The idea being on the static site, in a search component, you&#x27;re just taking the current value of the search term and using that as a key into this search index map to get the corresponding articles.</p><p>The benefit to this approach is the actions on the client side, on my site itself, are very quick. I&#x27;m just taking the current search term as a key and retrieving the corresponding values from an map/object.</p><p>The downside is you need to load this search index at some point, hopefully lazily, and it could be quite big.</p><h2 id="Preprocessing article data"><span class="underline">Preprocessing article data</span></h2><p>I write my articles in markdown with front matter metadata. I use the following format for my metadata:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">---
title: &quot;Some apples are too sour&quot;
date: &quot;October 27, 2197&quot;
author: &quot;Tyrel Delaney&quot;
excerpt: &quot;Some apples are just too sour and I don&#x27;t like them. Don&#x27;t @ me.&quot;
hero: &quot;badapple.jpg&quot;
tags: &quot;apples apple bleh sour&quot;
---</code></span><p>I&#x27;ll use this metadata from each article to create my search index.</p><h2 id="Creating a Typescript script to parse article data into an index"><span class="underline">Creating a Typescript script to parse article data into an index</span></h2><p>This script is going to be separate my Next project and be run on its own as a pre-build step. I&#x27;ll output the resulting index in some format that my Next project can import and use, probably just JSON.</p><p>In my project root, I created a directory called <em>preprocessors/search-index/</em>, and a <em>search-index.ts</em> file. Using Typescript allows me to use my utility functions and DTOs I already have from my Next project.</p><p>For example, the first thing I want to do is read all my posts from the filesystem and parse their metadata out. I already have a function that does this so I just import it. I needed to refactor it slightly to take in an optional path, since this script is running in a different place relative to my posts directory that contains my markdown articles.</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);</code></span><p>Just for reference, my <code class="inline-code">PostData</code> looks like this. I should probably just be using <code class="inline-code">PostMetadata</code>, but I&#x27;ll leave that for a future optimization.</p><p><em>dtos/PostData.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">export interface PostMetadata {
    title: string;
    slug: string;
    date: string;
    excerpt: string;
    hero: string;
    tags: string[];
    readTimeInMinutes?: number;
}

export interface PostData extends PostMetadata {
    content: string
}</code></span><p>Note: One thing I needed to do was create a <em>tsconfig.json</em> file in my <em>preprocessors/search-index/</em> directory with the following:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">{
    &quot;compilerOptions&quot;: {
        &quot;esModuleInterop&quot;: true
    }
}</code></span><p>I think I might have removed the imports that necessitated this addition. But if you run into import errors related to ESModules you may need this as well.</p><h2 id="Create index from Titles, Tags, and Excerpt"><span class="underline">Create index from Titles, Tags, and Excerpt</span></h2><p>Now that I have the <code class="inline-code">postDataList</code> I want to build an index from the relevant tokens. First I&#x27;ll do Tags since it&#x27;s relatively simple.</p><p>I&#x27;ll just iterate over each Tag and add it along with it&#x27;s corresponding post slug to the index. I use a <code class="inline-code">Set&lt;string&gt;</code> to ensure duplicate slugs aren&#x27;t saved.</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, Set&lt;string&gt;&gt; =&gt; {
    const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            addToIndex(searchIndex, tag, post.slug);
        });
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, Set&lt;string&gt;&gt;, key: string, value: string) =&gt; {
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Set());
    }
    searchIndex.get(key).add(value);
}

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);
const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = createSearchIndex(postDataList);
console.log(&quot;Search Index: &quot;, searchIndex);</code></span><p>Cool, now lets do the same for the Title and the Excerpt since I want those to contribute to the search index as well.</p><p>Since the Title and Excerpt are just regular sentences, I&#x27;ll need to tokenize them first. I also want to strip out most special characters, as well as convert some characters like <code class="inline-code">-</code> to spaces.</p><p>A little helper function accomplishes this. It strips special characters, replaces <code class="inline-code">&quot;-&quot;</code> with <code class="inline-code">&quot; &quot;</code>, splits the string on spaces, then filters out any empty strings.</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">export const tokenizeText = (text: string): string[] =&gt; {
    const tokens = text.replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;).replace(/-/g, &#x27; &#x27;).split(&#x27; &#x27;);
    return tokens.filter((token: string) =&gt; token.length &gt; 0);
}</code></span><p>With this <code class="inline-code">tokenizeText</code> function, I can do the same thing I did for Tags with the Title and Excerpt.</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, Set&lt;string&gt;&gt; =&gt; {
    const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            addToIndex(searchIndex, tag, post.slug);
        });
        // parse titles
        const titleTokens = tokenizeText(post.title);
        titleTokens.forEach((token: string) =&gt; {
            addToIndex(searchIndex, token, post.slug);
        });
        // parse excerpts
        const excerptTokens = tokenizeText(post.excerpt);
        excerptTokens.forEach((token: string) =&gt; {
            addToIndex(searchIndex, token, post.slug);
        });
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, Set&lt;string&gt;&gt;, key: string, value: string) =&gt; {
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Set());
    }
    searchIndex.get(key).add(value);
}

export const tokenizeText = (text: string): string[] =&gt; {
    const tokens = text.replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;).replace(/-/g, &#x27; &#x27;).split(&#x27; &#x27;);
    return tokens.filter((token: string) =&gt; token.length &gt; 0);
}

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);
const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = createSearchIndex(postDataList);
console.log(&quot;Search Index: &quot;, searchIndex);
console.log(&quot;Search Index Size: &quot;, searchIndex.size);</code></span><p>Great start! With my current small set of 19 articles this script generates an index with 452 tokens/keys.</p><p>We could stop here, but one thing I&#x27;d like to do is support partial searches. With this search index, you couldn&#x27;t find &quot;docker&quot; by searching &quot;dock&quot;.</p><h2 id="Ngrams"><span class="underline">Ngrams</span></h2><p>Again building off of the work of Ahmad Rosid in <a href="https://ahmadrosid.com/blog/fulltext-search-with-inverted-index" target="_blank">Writing full text search in Javascript for Next.js static site</a>, I&#x27;ll create ngrams of each token. I didn&#x27;t do much digging into ngrams beyond Ahmad&#x27;s article, but they&#x27;re essentially just sub-tokens of a given token.</p><p>For example, a token I already have is &quot;cool&quot;. The 2 and 3 ngrams of &quot;cool&quot; would be <code class="inline-code">[ &quot;co&quot;, &quot;oo&quot;, &quot;ol&quot;, &quot;coo&quot;, &quot;ool&quot;]</code>. I&#x27;ll start with ngrams of lengths 1 to 10. I might go beyond 10 in the future as well, but lets start there and see.</p><p>I&#x27;ll create a helper function to generate the ngrams of a given token. This function contains a max <code class="inline-code">n</code> const. I&#x27;ll iterate over each value from 1 -&gt; <code class="inline-code">n</code> and create the corresponding ngram substrings using <code class="inline-code">slice()</code>.</p><p>My <code class="inline-code">createNGrams</code> function looks like this:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">export const createNGrams = (token: string): Set&lt;string&gt; =&gt; {
    const n = 10;
    const nGrams: Set&lt;string&gt; = new Set();
    for (let nx = 1; nx &lt;= n; nx++) {
        for (let i = 0; i &lt; token.length - nx + 1; i++) {
            const nGram = token.slice(i, i + nx);
            nGrams.add(nGram);
        }
    };
    if (token.length &gt; n) {
        nGrams.add(token);
    }
    return nGrams;
}</code></span><p>So then back in my <code class="inline-code">createSearchIndex</code> function, I&#x27;ll use this <code class="inline-code">createNGrams</code> function to add all the ngrams to the index rather than just the token.</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, Set&lt;string&gt;&gt; =&gt; {
    const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            // addToIndex(searchIndex, tag, post.slug);
            const nGrams = createNGrams(tag);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
        // parse titles
        const titleTokens = tokenizeText(post.title);
        titleTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
        // parse excerpts
        const excerptTokens = tokenizeText(post.excerpt);
        excerptTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, Set&lt;string&gt;&gt;, key: string, value: string) =&gt; {
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Set());
    }
    searchIndex.get(key).add(value);
}

export const tokenizeText = (text: string): string[] =&gt; {
    const tokens = text.replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;).replace(/-/g, &#x27; &#x27;).split(&#x27; &#x27;);
    return tokens.filter((token: string) =&gt; token.length &gt; 0);
}

export const createNGrams = (token: string): Set&lt;string&gt; =&gt; {
    const n = 10;
    const nGrams: Set&lt;string&gt; = new Set();
    for (let nx = 1; nx &lt;= n; nx++) {
        for (let i = 0; i &lt; token.length - nx + 1; i++) {
            const nGram = token.slice(i, i + nx);
            nGrams.add(nGram);
        }
    };
    if (token.length &gt; n) {
        nGrams.add(token);
    }
    return nGrams;
}

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);
const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = createSearchIndex(postDataList);
// console.log(&quot;Search Index: &quot;, searchIndex);
console.log(&quot;Search Index Size: &quot;, searchIndex.size);</code></span><p>Just a few things I need to clean up with this.</p><h2 id="Tokenizing tags"><span class="underline">Tokenizing tags</span></h2><p>First, I need to tokenize the individual tags as well. Some tags contain <code class="inline-code">-</code>s, so removing those and splitting the tag into tokens will work better.</p><p>In the above code within <code class="inline-code">createSearchIndex</code> I&#x27;ll refactor the loop over the tags to also tokenize each individual tag:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">// parse tags
post.tags.forEach((tag: string) =&gt; {
    const tagTokens = tokenizeText(tag);
    tagTokens.forEach((token: string) =&gt; {
        const nGrams = createNGrams(token);
        nGrams.forEach((nGram: string) =&gt; {
            addToIndex(searchIndex, nGram, post.slug);
        });
    });
});</code></span><h2 id="Lowercase all tokens"><span class="underline">Lowercase all tokens</span></h2><p>Next, I noticed that I&#x27;m not treating capitalized letters appropriately. I think what I&#x27;ll do is lower-case all the ngrams. Then when I implement the search function I&#x27;ll also make sure to lower-case the search string. I&#x27;ll do this in my <code class="inline-code">tokenizeText</code> function</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">export const tokenizeText = (text: string): string[] =&gt; {
    return text
        .replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;)
        .replace(/-/g, &#x27; &#x27;)
        .split(&#x27; &#x27;)
        .filter((token: string) =&gt; token.length &gt; 0)
        .map((token: string) =&gt; token.toLowerCase());
}</code></span><p>Oh so functional.</p><p>My script so far looks like this:</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, Set&lt;string&gt;&gt; =&gt; {
    const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            const tagTokens = tokenizeText(tag);
            tagTokens.forEach((token: string) =&gt; {
                const nGrams = createNGrams(token);
                nGrams.forEach((nGram: string) =&gt; {
                    addToIndex(searchIndex, nGram, post.slug);
                });
            });
        });
        // parse titles
        const titleTokens = tokenizeText(post.title);
        titleTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
        // parse excerpts
        const excerptTokens = tokenizeText(post.excerpt);
        excerptTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, Set&lt;string&gt;&gt;, key: string, value: string) =&gt; {
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Set());
    }
    searchIndex.get(key).add(value);
}

export const tokenizeText = (text: string): string[] =&gt; {
    return text
        .replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;)
        .replace(/-/g, &#x27; &#x27;)
        .split(&#x27; &#x27;)
        .filter((token: string) =&gt; token.length &gt; 0)
        .map((token: string) =&gt; token.toLowerCase());
}

export const createNGrams = (token: string): Set&lt;string&gt; =&gt; {
    const n = [2, 3, 4, 5];
    const nGrams: Set&lt;string&gt; = new Set();
    n.forEach((nx: number) =&gt; {
        for (let i = 0; i &lt; token.length - nx + 1; i++) {
            const nGram = token.slice(i, i + nx);
            nGrams.add(nGram);
        }
    });
    if (token.length &gt; Math.max(...n) || token.length &lt; Math.min(...n)) {
        nGrams.add(token);
    }
    return nGrams;
}

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);
const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = createSearchIndex(postDataList);
// console.log(&quot;Search Index: &quot;, searchIndex);
console.log(&quot;Search Index Size: &quot;, searchIndex.size);</code></span><p>After implementing ngrams and adding these couple improvements my search index has 3833 keys now for 19 articles. Not sure how performant this will be, but we&#x27;ll find out. A quick estimation showed this search index is around 340 kilobytes as JSON, so ideally I can lazy load it after the page renders?</p><h2 id="Save index as a JSON file"><span class="underline">Save index as a JSON file</span></h2><p>The last step of this script is to simply save this search index to a JSON file that will be used later by our static site.</p><p>First I need to convert this index map to a JSON string. <code class="inline-code">JSON.stringify</code> was acting weird with my index object, I think because I am using <code class="inline-code">Set</code>s 🤷🏻‍♂️. So I first convert my index to a more generic object with simple arrays instead of sets. Then I can pass this object to <code class="inline-code">JSON.stringify</code>. Heres the code in a little function:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">const convertMapToJson = (map: Map&lt;string, Set&lt;string&gt;&gt;): string =&gt; {
    const obj: { [key: string]: string[] } = {};
    map.forEach((value, key) =&gt; {
        obj[key] = Array.from(value);
    });
    return JSON.stringify(obj);
}</code></span><p>In my case I just saved this JSON file in my <em>/public</em> directory in the project. May move this later if it&#x27;s not the best place. Just use <code class="inline-code">fs</code> to save it.</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">fs.writeFileSync(&quot;./public/search-index.json&quot;, searchIndexJsonString, &quot;utf8&quot;);</code></span><p>My final search index preprocessor script looks like this:</p><p><em>preprocessors/search-index/search-index.ts</em>:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, Set&lt;string&gt;&gt; =&gt; {
    const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            const tagTokens = tokenizeText(tag);
            tagTokens.forEach((token: string) =&gt; {
                const nGrams = createNGrams(token);
                nGrams.forEach((nGram: string) =&gt; {
                    addToIndex(searchIndex, nGram, post.slug);
                });
            });
        });
        // parse titles
        const titleTokens = tokenizeText(post.title);
        titleTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
        // parse excerpts
        const excerptTokens = tokenizeText(post.excerpt);
        excerptTokens.forEach((token: string) =&gt; {
            // addToIndex(searchIndex, token, post.slug);
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post.slug);
            })
        });
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, Set&lt;string&gt;&gt;, key: string, value: string) =&gt; {
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Set());
    }
    searchIndex.get(key).add(value);
}

export const tokenizeText = (text: string): string[] =&gt; {
    return text
        .replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;)
        .replace(/-/g, &#x27; &#x27;)
        .split(&#x27; &#x27;)
        .filter((token: string) =&gt; token.length &gt; 0)
        .map((token: string) =&gt; token.toLowerCase());
}

export const createNGrams = (token: string): Set&lt;string&gt; =&gt; {
    const n = [2, 3, 4, 5];
    const nGrams: Set&lt;string&gt; = new Set();
    n.forEach((nx: number) =&gt; {
        for (let i = 0; i &lt; token.length - nx + 1; i++) {
            const nGram = token.slice(i, i + nx);
            nGrams.add(nGram);
        }
    });
    if (token.length &gt; Math.max(...n) || token.length &lt; Math.min(...n)) {
        nGrams.add(token);
    }
    return nGrams;
}

const convertMapToJson = (map: Map&lt;string, Set&lt;string&gt;&gt;): string =&gt; {
    const obj: { [key: string]: string[] } = {};
    map.forEach((value, key) =&gt; {
        obj[key] = Array.from(value);
    });
    return JSON.stringify(obj);
}

const postDataList: PostData[] = getPostData(&quot;../../posts&quot;);
const searchIndex: Map&lt;string, Set&lt;string&gt;&gt; = createSearchIndex(postDataList);
// console.log(&quot;Search Index: &quot;, searchIndex);
console.log(&quot;Search Index Size: &quot;, searchIndex.size);
fs.writeFileSync(&quot;./public/search-index.json&quot;, searchIndexJsonString, &quot;utf8&quot;);</code></span><h2 id="Add NPM script to run this easily from the project root"><span class="underline">Add NPM script to run this easily from the project root</span></h2><p>The last-last step is to be able to automate running this preprocessor script during my build process. It technically is not included in the build, it will be included in the deployment, so it can happed before or after the build. Since I called it a &quot;preprocessor&quot; lets run it before the build.</p><p>First thing I did, to keep things a bit tidy, was add an out directory to my preprocessors <em>tsconfig.json</em>. The compiled Javascript is saved in <em>preprocessors/search-index/out/</em>. This is the tsconfig file located at <em>preprocessors/search-index/tsconfig.json</em>, not the one in the root of your project.</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">{
    &quot;compilerOptions&quot;: {
        &quot;esModuleInterop&quot;: true,
        &quot;outDir&quot;: &quot;./out&quot;
    }
}</code></span><p>In your <em>package.json</em>, add a new script definition to your <code class="inline-code">scripts</code> block. In my script I called <code class="inline-code">tsc</code> to compile my preprocessor and then <code class="inline-code">node</code> to immediately run the compiled files. My script looks like this:</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">{
    ...
    &quot;scripts&quot;: {
        ...
        &quot;compile-search-index&quot;: &quot;tsc -p ./preprocessors/search-index/ &amp;&amp; node ./preprocessors/search-index/out/preprocessors/search-index/search-index.js&quot;
    }
}</code></span><p>That path to the js file is a bit cumbersome, this is due to me storing the output in that <em>out</em> directory. But with this script you only need to run <code class="inline-code">npm run compile-search-index</code> and never need to type that path again. Much rather have that than compiled js all over the place.</p><p>Next I add this into my existing build script so that it runs automatically when I run a build.</p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">{
    ...
    &quot;scripts&quot;: {
        ...
        &quot;build&quot;: &quot;npm run compile-search-index &amp;&amp; next build&quot;,
        ...
        &quot;compile-search-index&quot;: &quot;tsc -p ./preprocessors/search-index/ &amp;&amp; node ./preprocessors/search-index/out/preprocessors/search-index/search-index.js&quot;
    }
}</code></span><p>And there you go!</p><h2 id="Including the post title"><span class="underline">Including the post title</span></h2><p>After moving on to the next step of creating the search component itself that will use this index, I realized I need the post title to display in the search results.</p><p>The way I decided to do it for this first iteration is to just come back to this script and refactor the title into the index, alongside the post slug. This increases the byte size of the index substantially and isn&#x27;t ideal.</p><p>I&#x27;ll show how I did it this way, but a better way to do it and something I might do in the future is simply store a unique post ID in the index, and then use that to reference any details I need from a separate list of post data. I&#x27;ll save that optimization for a future blog post.</p><p>For now I essentially replaced the <code class="inline-code">Set&lt;string&gt;</code> with a <code class="inline-code">{ title: string, slug: string }[]</code>. It&#x27;s not a Set anymore, so I need make sure I&#x27;m not adding duplicates myself.</p><p>Then in my <code class="inline-code">addToIndex</code> function I simply pass in the whole post object and inside I pull out the title and slug and add an entry to the index.</p><p>Here is the full refactored code with these changes:</p><p><em>preprocessors/search-index/search-index.ts</em></p><span style="font-size:inherit;font-family:inherit;background:#282a36;color:#f8f8f2;border-radius:3px;display:flex;line-height:1.4285714285714286;overflow-x:auto;white-space:pre"><code style="font-size:inherit;font-family:inherit;line-height:1.6666666666666667;padding:8px;white-space:pre">import { PostData } from &quot;../../dtos/PostData&quot;;
import { getPostData } from &quot;../../utils/articleFileUtils&quot;;
import * as fs from &quot;fs&quot;;

export const createSearchIndex = (postDataList: PostData[]): Map&lt;string, { title: string, slug: string }[]&gt; =&gt; {
    const searchIndex: Map&lt;string, { title: string, slug: string }[]&gt; = new Map();
    postDataList.forEach((post: PostData) =&gt; {
        
        // parse tags
        post.tags.forEach((tag: string) =&gt; {
            const tagTokens = tokenizeText(tag);
            tagTokens.forEach((token: string) =&gt; {
                const nGrams = createNGrams(token);
                nGrams.forEach((nGram: string) =&gt; {
                    addToIndex(searchIndex, nGram, post);
                });
            });
        });
        
        // parse titles
        const titleTokens = tokenizeText(post.title);
            titleTokens.forEach((token: string) =&gt; {
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post);
            });
        });
        
        // parse excerpts
        const excerptTokens = tokenizeText(post.excerpt);
        excerptTokens.forEach((token: string) =&gt; {
            const nGrams = createNGrams(token);
            nGrams.forEach((nGram: string) =&gt; {
                addToIndex(searchIndex, nGram, post);
            });
        });
        
    });
    return searchIndex;
}

const addToIndex = (searchIndex: Map&lt;string, { title: string, slug: string }[]&gt;, key: string, post: PostData) =&gt; {
    const value = {&quot;title&quot;: post.title, &quot;slug&quot;: post.slug};
    if (!searchIndex.has(key)) {
        searchIndex.set(key, new Array());
    }
    let found = false;
    for (let item of searchIndex.get(key)) {
        if (item.title === value.title) {
            found = true;
        }
    }
    if (!found) {
        searchIndex.get(key).push(value);
    }
}

export const tokenizeText = (text: string): string[] =&gt; {
    return text
        .replace(/[&quot;.,?!:;&#x27;[\]{\/}@#$%^&amp;*(→)]/g, &#x27;&#x27;)
        .replace(/-/g, &#x27; &#x27;)
        .split(&#x27; &#x27;)
        .filter((token: string) =&gt; token.length &gt; 0)
        .map((token: string) =&gt; token.toLowerCase());
}

export const createNGrams = (token: string): Set&lt;string&gt; =&gt; {
    const n = 10;
    const nGrams: Set&lt;string&gt; = new Set();
    for (let nx = 1; nx &lt;= n; nx++) {
        for (let i = 0; i &lt; token.length - nx + 1; i++) {
            const nGram = token.slice(i, i + nx);
            nGrams.add(nGram);
        }
    };
    if (token.length &gt; n) {
        nGrams.add(token);
    }
    return nGrams;
}

const startTime = performance.now();

const postDataList: PostData[] = getPostData(&quot;./posts&quot;);
// console.log(&quot;Post Data List: &quot;, postDataList);
const searchIndex: Map&lt;string, { title: string, slug: string }[]&gt; = createSearchIndex(postDataList);
// console.log(&quot;Search Index: &quot;, searchIndex);
const searchIndexJsonString = JSON.stringify(Object.fromEntries(searchIndex.entries()));
// console.log(&quot;Search Index JSON: &quot;, searchIndexJsonString);
const searchIndexLocation = &quot;./components/elements/search-index.json&quot;;
fs.writeFileSync(searchIndexLocation, searchIndexJsonString, &quot;utf8&quot;);
console.log(`⏺ Search index saved to ${searchIndexLocation}\n`);

const endTime = performance.now();

console.log(`⏺ ${postDataList.length} posts`);
console.log(`⏺ ${searchIndex.size} index entries`);
const sizeInBytes = searchIndexJsonString.length;
console.log(`⏺ ${Number(sizeInBytes/1000).toFixed(1)} KB JSON size`);
console.log(`⏺ ${Number(endTime - startTime).toFixed(1)} ms to process search index`);
console.log(&quot;\n✔ Done&quot;)</code></span><p>I also refactored and simplified how I was converting the index to JSON, and added some nice console output as well.</p><h2 id="References"><span class="underline">References</span></h2><ul><li><a href="https://ahmadrosid.com/blog/fulltext-search-with-inverted-index" target="_blank">Writing full text search in Javascript for Next.js static site</a> - Great article from Ahmad Rosid on creating a static site search. Heavily inpired my implementation.</li><li><a href="https://pagefind.app/" target="_blank">Pagefind</a> - a static site search tool that I didn&#x27;t end up using</li><li><a href="https://www.petemillspaugh.com/nextjs-search-with-pagefind" target="_blank">Add search to your Next.js static site with Pagefind</a> - article on using Pagefind with Next. Did not find it very helpful</li></ul><h2 id="Repository"><span class="underline">Repository</span></h2><p>This website in it&#x27;s entirety is viewable on <a href="https://github.com/tyrelh/personal-site-nextjs" target="_blank">GitHub</a>.</p><p>The search logic doesn&#x27;t have it&#x27;s own repo yet. But I&#x27;ll update that here if I ever split it out.</p><h2 id="Conclusion"><span class="underline">Conclusion</span></h2><p>Well thats it for the search index preprocessor. In an upcoming article I&#x27;ll discuss how I built a search component to use this search index on my Next static site (this site!).</p><p>Give the search a try! It&#x27;s near the top on desktop or bottom on mobile.</p><p>Hope you found this interesting or useful. 🙌🏻</p><footer class="ant-layout-footer css-djtmh8"><div class="ant-space css-djtmh8 ant-space-vertical ant-space-gap-row-middle ant-space-gap-col-middle" style="display:flex"><div class="ant-space-item"><p><a href="/">Return to homepage</a></p></div><div class="ant-space-item"><p>Made with <span role="img" aria-label="thunderbolt" class="anticon anticon-thunderbolt"><svg viewBox="64 64 896 896" focusable="false" data-icon="thunderbolt" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M848 359.3H627.7L825.8 109c4.1-5.3.4-13-6.3-13H436c-2.8 0-5.5 1.5-6.9 4L170 547.5c-3.1 5.3.7 12 6.9 12h174.4l-89.4 357.6c-1.9 7.8 7.5 13.3 13.3 7.7L853.5 373c5.2-4.9 1.7-13.7-5.5-13.7z"></path></svg></span> by Tyrel Delaney   <span class="anchor"><a href="https://github.com/tyrelh" target="_blank" rel="noopener noreferrer"><span role="img" aria-label="github" class="anticon anticon-github"><svg viewBox="64 64 896 896" focusable="false" data-icon="github" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M511.6 76.3C264.3 76.2 64 276.4 64 523.5 64 718.9 189.3 885 363.8 946c23.5 5.9 19.9-10.8 19.9-22.2v-77.5c-135.7 15.9-141.2-73.9-150.3-88.9C215 726 171.5 718 184.5 703c30.9-15.9 62.4 4 98.9 57.9 26.4 39.1 77.9 32.5 104 26 5.7-23.5 17.9-44.5 34.7-60.8-140.6-25.2-199.2-111-199.2-213 0-49.5 16.3-95 48.3-131.7-20.4-60.5 1.9-112.3 4.9-120 58.1-5.2 118.5 41.6 123.2 45.3 33-8.9 70.7-13.6 112.9-13.6 42.4 0 80.2 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.3-43.9 2.9 7.7 24.7 58.3 5.5 118 32.4 36.8 48.9 82.7 48.9 132.3 0 102.2-59 188.1-200 212.9a127.5 127.5 0 0138.1 91v112.5c.8 9 0 17.9 15 17.9 177.1-59.7 304.6-227 304.6-424.1 0-247.2-200.4-447.3-447.5-447.3z"></path></svg></span></a></span>  <span class="anchor"><a href="https://www.linkedin.com/in/tyrelhiebert/" target="_blank" rel="noopener noreferrer"><span role="img" class="anticon"><svg fill="currentColor" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="-10 -10 400 400"><path d="M347.445,0H34.555C15.471,0,0,15.471,0,34.555v312.889C0,366.529,15.471,382,34.555,382h312.889 C366.529,382,382,366.529,382,347.444V34.555C382,15.471,366.529,0,347.445,0z M118.207,329.844c0,5.554-4.502,10.056-10.056,10.056 H65.345c-5.554,0-10.056-4.502-10.056-10.056V150.403c0-5.554,4.502-10.056,10.056-10.056h42.806 c5.554,0,10.056,4.502,10.056,10.056V329.844z M86.748,123.432c-22.459,0-40.666-18.207-40.666-40.666S64.289,42.1,86.748,42.1 s40.666,18.207,40.666,40.666S109.208,123.432,86.748,123.432z M341.91,330.654c0,5.106-4.14,9.246-9.246,9.246H286.73 c-5.106,0-9.246-4.14-9.246-9.246v-84.168c0-12.556,3.683-55.021-32.813-55.021c-28.309,0-34.051,29.066-35.204,42.11v97.079 c0,5.106-4.139,9.246-9.246,9.246h-44.426c-5.106,0-9.246-4.14-9.246-9.246V149.593c0-5.106,4.14-9.246,9.246-9.246h44.426 c5.106,0,9.246,4.14,9.246,9.246v15.655c10.497-15.753,26.097-27.912,59.312-27.912c73.552,0,73.131,68.716,73.131,106.472 L341.91,330.654L341.91,330.654z"></path></svg></span></a></span><br/></p></div></div><p>I use <span class="anchor"><a href="https://plausible.io/superflux.dev" target="_blank" rel="noopener noreferrer">Plausible.io</a></span> to collect privacy respecting visitor analytics.</p><p><span class="anchor"><a href="https://www.github.com/tyrelh/personal-site-nextjs/" target="_blank" rel="noopener noreferrer"><span role="img" aria-label="github" class="anticon anticon-github"><svg viewBox="64 64 896 896" focusable="false" data-icon="github" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M511.6 76.3C264.3 76.2 64 276.4 64 523.5 64 718.9 189.3 885 363.8 946c23.5 5.9 19.9-10.8 19.9-22.2v-77.5c-135.7 15.9-141.2-73.9-150.3-88.9C215 726 171.5 718 184.5 703c30.9-15.9 62.4 4 98.9 57.9 26.4 39.1 77.9 32.5 104 26 5.7-23.5 17.9-44.5 34.7-60.8-140.6-25.2-199.2-111-199.2-213 0-49.5 16.3-95 48.3-131.7-20.4-60.5 1.9-112.3 4.9-120 58.1-5.2 118.5 41.6 123.2 45.3 33-8.9 70.7-13.6 112.9-13.6 42.4 0 80.2 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.3-43.9 2.9 7.7 24.7 58.3 5.5 118 32.4 36.8 48.9 82.7 48.9 132.3 0 102.2-59 188.1-200 212.9a127.5 127.5 0 0138.1 91v112.5c.8 9 0 17.9 15 17.9 177.1-59.7 304.6-227 304.6-424.1 0-247.2-200.4-447.3-447.5-447.3z"></path></svg></span> View website source</a></span></p></footer></main></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"post":{"title":"Static Site Search Part 1 - Preprocessing Articles","slug":"static-site-search-preprocessing-articles","date":"April 3, 2024","excerpt":"In this series of articles I discuss how I created a client-side search for my static website. After looking at a few options out there for static sites and Next.js projects, I decided the challenge to build my own search from scratch would be more enjoyable. This first article discusses how I preprocess my articles into a search index.","hero":"/images/posts/static-site-search-preprocessing-articles.jpg","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":20,"content":"\n![](./static-site-search-preprocessing-articles.jpg)\n\n## Overview\n\nSo, I want a search feature for this blog. Simple as that. I need it to run client side since my website is statically compiled and served from GitHub. And I want it to be somewhat light weight.\n\nI only have 19 posts as of writing this (this is the 20th), so the search space is relatively small now. But I'm contemplating re-writing my [partners food blog](https://www.theverdigris.ca/) in my custom Next + markdown CMS. She has 100's of posts so eventually it needs to be able to handle that amount.\n\nI also like the idea of building it myself as much as I can. Building this website is a learning exercise and I don't learn much by running `npm install tool-that-solves-your-problem`.\n\n## Static Site Search Series\n\nThis is the first part in a series of articles which covers creating the search index from my markdown articles.\n\n[The second part is now live](https://superflux.dev/blog/static-site-search-search-component). There I cover creating the search component and UI that uses this search index to perform searches.\n\n## Pagefind\n\nIn my initial research I came across [Pagefind](https://pagefind.app/). It seems like what I wanted. Static site search with a default but customizable UI.\n\nI tried for maybe an hour or two to get this running locally on my static site without success. I think it's tricky to get working with Next dev mode. I found [this article from Pete Millspaugh](https://www.petemillspaugh.com/nextjs-search-with-pagefind) on using Pagefind with Next. It was short on detail and didn't help much though.\n\nSo I decided to build something myself from scratch. How hard could it be?\n\n## My plan\n\nTaking inspiration from Ahmad Rosid's post on [Writing full text search in Javascript for Next.js static site](https://ahmadrosid.com/blog/fulltext-search-with-inverted-index), what I'm going to do is build an inverted index, of sorts, of the article data.\n\nThis index will contain all of my valid search terms as keys, and each key's value will be a list of objects representing the articles that match that search term.\n\nBuilding this index will happen as a preprocessing step as part of my static site's build process.\n\nThe idea being on the static site, in a search component, you're just taking the current value of the search term and using that as a key into this search index map to get the corresponding articles.\n\nThe benefit to this approach is the actions on the client side, on my site itself, are very quick. I'm just taking the current search term as a key and retrieving the corresponding values from an map/object.\n\nThe downside is you need to load this search index at some point, hopefully lazily, and it could be quite big.\n## Preprocessing article data\n\nI write my articles in markdown with front matter metadata. I use the following format for my metadata:\n\n```text\n---\ntitle: \"Some apples are too sour\"\ndate: \"October 27, 2197\"\nauthor: \"Tyrel Delaney\"\nexcerpt: \"Some apples are just too sour and I don't like them. Don't @ me.\"\nhero: \"badapple.jpg\"\ntags: \"apples apple bleh sour\"\n---\n```\nI'll use this metadata from each article to create my search index.\n## Creating a Typescript script to parse article data into an index\n\nThis script is going to be separate my Next project and be run on its own as a pre-build step. I'll output the resulting index in some format that my Next project can import and use, probably just JSON.\n\nIn my project root, I created a directory called *preprocessors/search-index/*, and a *search-index.ts* file. Using Typescript allows me to use my utility functions and DTOs I already have from my Next project.\n\nFor example, the first thing I want to do is read all my posts from the filesystem and parse their metadata out. I already have a function that does this so I just import it. I needed to refactor it slightly to take in an optional path, since this script is running in a different place relative to my posts directory that contains my markdown articles.\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\n```\nJust for reference, my `PostData` looks like this. I should probably just be using `PostMetadata`, but I'll leave that for a future optimization.\n\n*dtos/PostData.ts*:\n```typescript\nexport interface PostMetadata {\n\ttitle: string;\n\tslug: string;\n\tdate: string;\n\texcerpt: string;\n\thero: string;\n\ttags: string[];\n\treadTimeInMinutes?: number;\n}\n\nexport interface PostData extends PostMetadata {\n\tcontent: string\n}\n```\n\nNote: One thing I needed to do was create a *tsconfig.json* file in my *preprocessors/search-index/* directory with the following:\n```json\n{\n\t\"compilerOptions\": {\n\t\t\"esModuleInterop\": true\n\t}\n}\n```\nI think I might have removed the imports that necessitated this addition. But if you run into import errors related to ESModules you may need this as well.\n## Create index from Titles, Tags, and Excerpt\n\nNow that I have the `postDataList` I want to build an index from the relevant tokens. First I'll do Tags since it's relatively simple.\n\nI'll just iterate over each Tag and add it along with it's corresponding post slug to the index. I use a `Set\u003cstring\u003e` to ensure duplicate slugs aren't saved.\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, Set\u003cstring\u003e\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\taddToIndex(searchIndex, tag, post.slug);\n\t\t});\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e, key: string, value: string) =\u003e {\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Set());\n\t}\n\tsearchIndex.get(key).add(value);\n}\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\nconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = createSearchIndex(postDataList);\nconsole.log(\"Search Index: \", searchIndex);\n```\nCool, now lets do the same for the Title and the Excerpt since I want those to contribute to the search index as well.\n\nSince the Title and Excerpt are just regular sentences, I'll need to tokenize them first. I also want to strip out most special characters, as well as convert some characters like `-` to spaces.\n\nA little helper function accomplishes this. It strips special characters, replaces `\"-\"` with `\" \"`, splits the string on spaces, then filters out any empty strings.\n\n```typescript\nexport const tokenizeText = (text: string): string[] =\u003e {\n\tconst tokens = text.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '').replace(/-/g, ' ').split(' ');\n\treturn tokens.filter((token: string) =\u003e token.length \u003e 0);\n}\n```\n\nWith this `tokenizeText` function, I can do the same thing I did for Tags with the Title and Excerpt.\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, Set\u003cstring\u003e\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\taddToIndex(searchIndex, tag, post.slug);\n\t\t});\n\t\t// parse titles\n\t\tconst titleTokens = tokenizeText(post.title);\n\t\ttitleTokens.forEach((token: string) =\u003e {\n\t\t\taddToIndex(searchIndex, token, post.slug);\n\t\t});\n\t\t// parse excerpts\n\t\tconst excerptTokens = tokenizeText(post.excerpt);\n\t\texcerptTokens.forEach((token: string) =\u003e {\n\t\t\taddToIndex(searchIndex, token, post.slug);\n\t\t});\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e, key: string, value: string) =\u003e {\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Set());\n\t}\n\tsearchIndex.get(key).add(value);\n}\n\nexport const tokenizeText = (text: string): string[] =\u003e {\n\tconst tokens = text.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '').replace(/-/g, ' ').split(' ');\n\treturn tokens.filter((token: string) =\u003e token.length \u003e 0);\n}\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\nconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = createSearchIndex(postDataList);\nconsole.log(\"Search Index: \", searchIndex);\nconsole.log(\"Search Index Size: \", searchIndex.size);\n```\n\nGreat start! With my current small set of 19 articles this script generates an index with 452 tokens/keys.\n\nWe could stop here, but one thing I'd like to do is support partial searches. With this search index, you couldn't find \"docker\" by searching \"dock\".\n\n## Ngrams\n\nAgain building off of the work of Ahmad Rosid in [Writing full text search in Javascript for Next.js static site](https://ahmadrosid.com/blog/fulltext-search-with-inverted-index), I'll create ngrams of each token. I didn't do much digging into ngrams beyond Ahmad's article, but they're essentially just sub-tokens of a given token.\n\nFor example, a token I already have is \"cool\". The 2 and 3 ngrams of \"cool\" would be `[ \"co\", \"oo\", \"ol\", \"coo\", \"ool\"]`. I'll start with ngrams of lengths 1 to 10. I might go beyond 10 in the future as well, but lets start there and see.\n\nI'll create a helper function to generate the ngrams of a given token. This function contains a max `n` const. I'll iterate over each value from 1 -\u003e `n` and create the corresponding ngram substrings using `slice()`.\n\nMy `createNGrams` function looks like this:\n```typescript\nexport const createNGrams = (token: string): Set\u003cstring\u003e =\u003e {\n\tconst n = 10;\n\tconst nGrams: Set\u003cstring\u003e = new Set();\n\tfor (let nx = 1; nx \u003c= n; nx++) {\n\t\tfor (let i = 0; i \u003c token.length - nx + 1; i++) {\n\t\t\tconst nGram = token.slice(i, i + nx);\n\t\t\tnGrams.add(nGram);\n\t\t}\n\t};\n\tif (token.length \u003e n) {\n\t\tnGrams.add(token);\n\t}\n\treturn nGrams;\n}\n```\n\nSo then back in my `createSearchIndex` function, I'll use this `createNGrams` function to add all the ngrams to the index rather than just the token.\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, Set\u003cstring\u003e\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, tag, post.slug);\n\t\t\tconst nGrams = createNGrams(tag);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t\t// parse titles\n\t\tconst titleTokens = tokenizeText(post.title);\n\t\ttitleTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t\t// parse excerpts\n\t\tconst excerptTokens = tokenizeText(post.excerpt);\n\t\texcerptTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e, key: string, value: string) =\u003e {\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Set());\n\t}\n\tsearchIndex.get(key).add(value);\n}\n\nexport const tokenizeText = (text: string): string[] =\u003e {\n\tconst tokens = text.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '').replace(/-/g, ' ').split(' ');\n\treturn tokens.filter((token: string) =\u003e token.length \u003e 0);\n}\n\nexport const createNGrams = (token: string): Set\u003cstring\u003e =\u003e {\n\tconst n = 10;\n\tconst nGrams: Set\u003cstring\u003e = new Set();\n\tfor (let nx = 1; nx \u003c= n; nx++) {\n\t\tfor (let i = 0; i \u003c token.length - nx + 1; i++) {\n\t\t\tconst nGram = token.slice(i, i + nx);\n\t\t\tnGrams.add(nGram);\n\t\t}\n\t};\n\tif (token.length \u003e n) {\n\t\tnGrams.add(token);\n\t}\n\treturn nGrams;\n}\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\nconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = createSearchIndex(postDataList);\n// console.log(\"Search Index: \", searchIndex);\nconsole.log(\"Search Index Size: \", searchIndex.size);\n```\n\nJust a few things I need to clean up with this.\n\n## Tokenizing tags\n\nFirst, I need to tokenize the individual tags as well. Some tags contain `-`s, so removing those and splitting the tag into tokens will work better.\n\nIn the above code within `createSearchIndex` I'll refactor the loop over the tags to also tokenize each individual tag:\n```typescript\n// parse tags\npost.tags.forEach((tag: string) =\u003e {\n\tconst tagTokens = tokenizeText(tag);\n\ttagTokens.forEach((token: string) =\u003e {\n\t\tconst nGrams = createNGrams(token);\n\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t});\n\t});\n});\n```\n## Lowercase all tokens\n\nNext, I noticed that I'm not treating capitalized letters appropriately. I think what I'll do is lower-case all the ngrams. Then when I implement the search function I'll also make sure to lower-case the search string. I'll do this in my `tokenizeText` function\n\n```typescript\nexport const tokenizeText = (text: string): string[] =\u003e {\n\treturn text\n\t\t.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '')\n\t\t.replace(/-/g, ' ')\n\t\t.split(' ')\n\t\t.filter((token: string) =\u003e token.length \u003e 0)\n\t\t.map((token: string) =\u003e token.toLowerCase());\n}\n```\n\nOh so functional.\n\nMy script so far looks like this:\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, Set\u003cstring\u003e\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\tconst tagTokens = tokenizeText(tag);\n\t\t\ttagTokens.forEach((token: string) =\u003e {\n\t\t\t\tconst nGrams = createNGrams(token);\n\t\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\t\t// parse titles\n\t\tconst titleTokens = tokenizeText(post.title);\n\t\ttitleTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t\t// parse excerpts\n\t\tconst excerptTokens = tokenizeText(post.excerpt);\n\t\texcerptTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e, key: string, value: string) =\u003e {\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Set());\n\t}\n\tsearchIndex.get(key).add(value);\n}\n\nexport const tokenizeText = (text: string): string[] =\u003e {\n\treturn text\n\t\t.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '')\n\t\t.replace(/-/g, ' ')\n\t\t.split(' ')\n\t\t.filter((token: string) =\u003e token.length \u003e 0)\n\t\t.map((token: string) =\u003e token.toLowerCase());\n}\n\nexport const createNGrams = (token: string): Set\u003cstring\u003e =\u003e {\n\tconst n = [2, 3, 4, 5];\n\tconst nGrams: Set\u003cstring\u003e = new Set();\n\tn.forEach((nx: number) =\u003e {\n\t\tfor (let i = 0; i \u003c token.length - nx + 1; i++) {\n\t\t\tconst nGram = token.slice(i, i + nx);\n\t\t\tnGrams.add(nGram);\n\t\t}\n\t});\n\tif (token.length \u003e Math.max(...n) || token.length \u003c Math.min(...n)) {\n\t\tnGrams.add(token);\n\t}\n\treturn nGrams;\n}\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\nconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = createSearchIndex(postDataList);\n// console.log(\"Search Index: \", searchIndex);\nconsole.log(\"Search Index Size: \", searchIndex.size);\n```\n\nAfter implementing ngrams and adding these couple improvements my search index has 3833 keys now for 19 articles. Not sure how performant this will be, but we'll find out. A quick estimation showed this search index is around 340 kilobytes as JSON, so ideally I can lazy load it after the page renders?\n## Save index as a JSON file\n\nThe last step of this script is to simply save this search index to a JSON file that will be used later by our static site.\n\nFirst I need to convert this index map to a JSON string. `JSON.stringify` was acting weird with my index object, I think because I am using `Set`s 🤷🏻‍♂️. So I first convert my index to a more generic object with simple arrays instead of sets. Then I can pass this object to `JSON.stringify`. Heres the code in a little function:\n\n```typescript\nconst convertMapToJson = (map: Map\u003cstring, Set\u003cstring\u003e\u003e): string =\u003e {\n\tconst obj: { [key: string]: string[] } = {};\n\tmap.forEach((value, key) =\u003e {\n\t\tobj[key] = Array.from(value);\n\t});\n\treturn JSON.stringify(obj);\n}\n```\n\nIn my case I just saved this JSON file in my */public* directory in the project. May move this later if it's not the best place. Just use `fs` to save it.\n\n```typescript\nfs.writeFileSync(\"./public/search-index.json\", searchIndexJsonString, \"utf8\");\n```\n\nMy final search index preprocessor script looks like this:\n\n*preprocessors/search-index/search-index.ts*:\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, Set\u003cstring\u003e\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\tconst tagTokens = tokenizeText(tag);\n\t\t\ttagTokens.forEach((token: string) =\u003e {\n\t\t\t\tconst nGrams = createNGrams(token);\n\t\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\t\t// parse titles\n\t\tconst titleTokens = tokenizeText(post.title);\n\t\ttitleTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t\t// parse excerpts\n\t\tconst excerptTokens = tokenizeText(post.excerpt);\n\t\texcerptTokens.forEach((token: string) =\u003e {\n\t\t\t// addToIndex(searchIndex, token, post.slug);\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post.slug);\n\t\t\t})\n\t\t});\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e, key: string, value: string) =\u003e {\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Set());\n\t}\n\tsearchIndex.get(key).add(value);\n}\n\nexport const tokenizeText = (text: string): string[] =\u003e {\n\treturn text\n\t\t.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '')\n\t\t.replace(/-/g, ' ')\n\t\t.split(' ')\n\t\t.filter((token: string) =\u003e token.length \u003e 0)\n\t\t.map((token: string) =\u003e token.toLowerCase());\n}\n\nexport const createNGrams = (token: string): Set\u003cstring\u003e =\u003e {\n\tconst n = [2, 3, 4, 5];\n\tconst nGrams: Set\u003cstring\u003e = new Set();\n\tn.forEach((nx: number) =\u003e {\n\t\tfor (let i = 0; i \u003c token.length - nx + 1; i++) {\n\t\t\tconst nGram = token.slice(i, i + nx);\n\t\t\tnGrams.add(nGram);\n\t\t}\n\t});\n\tif (token.length \u003e Math.max(...n) || token.length \u003c Math.min(...n)) {\n\t\tnGrams.add(token);\n\t}\n\treturn nGrams;\n}\n\nconst convertMapToJson = (map: Map\u003cstring, Set\u003cstring\u003e\u003e): string =\u003e {\n\tconst obj: { [key: string]: string[] } = {};\n\tmap.forEach((value, key) =\u003e {\n\t\tobj[key] = Array.from(value);\n\t});\n\treturn JSON.stringify(obj);\n}\n\nconst postDataList: PostData[] = getPostData(\"../../posts\");\nconst searchIndex: Map\u003cstring, Set\u003cstring\u003e\u003e = createSearchIndex(postDataList);\n// console.log(\"Search Index: \", searchIndex);\nconsole.log(\"Search Index Size: \", searchIndex.size);\nfs.writeFileSync(\"./public/search-index.json\", searchIndexJsonString, \"utf8\");\n```\n## Add NPM script to run this easily from the project root\n\nThe last-last step is to be able to automate running this preprocessor script during my build process. It technically is not included in the build, it will be included in the deployment, so it can happed before or after the build. Since I called it a \"preprocessor\" lets run it before the build.\n\nFirst thing I did, to keep things a bit tidy, was add an out directory to my preprocessors *tsconfig.json*. The compiled Javascript is saved in *preprocessors/search-index/out/*. This is the tsconfig file located at *preprocessors/search-index/tsconfig.json*, not the one in the root of your project.\n```json\n{\n\t\"compilerOptions\": {\n\t\t\"esModuleInterop\": true,\n\t\t\"outDir\": \"./out\"\n\t}\n}\n```\n\nIn your *package.json*, add a new script definition to your `scripts` block. In my script I called `tsc` to compile my preprocessor and then `node` to immediately run the compiled files. My script looks like this:\n\n```json\n{\n\t...\n\t\"scripts\": {\n\t\t...\n\t\t\"compile-search-index\": \"tsc -p ./preprocessors/search-index/ \u0026\u0026 node ./preprocessors/search-index/out/preprocessors/search-index/search-index.js\"\n\t}\n}\n```\nThat path to the js file is a bit cumbersome, this is due to me storing the output in that *out* directory. But with this script you only need to run `npm run compile-search-index` and never need to type that path again. Much rather have that than compiled js all over the place.\n\nNext I add this into my existing build script so that it runs automatically when I run a build.\n\n```json\n{\n\t...\n\t\"scripts\": {\n\t\t...\n\t\t\"build\": \"npm run compile-search-index \u0026\u0026 next build\",\n\t\t...\n\t\t\"compile-search-index\": \"tsc -p ./preprocessors/search-index/ \u0026\u0026 node ./preprocessors/search-index/out/preprocessors/search-index/search-index.js\"\n\t}\n}\n```\n\nAnd there you go!\n\n## Including the post title\n\nAfter moving on to the next step of creating the search component itself that will use this index, I realized I need the post title to display in the search results.\n\nThe way I decided to do it for this first iteration is to just come back to this script and refactor the title into the index, alongside the post slug. This increases the byte size of the index substantially and isn't ideal.\n\nI'll show how I did it this way, but a better way to do it and something I might do in the future is simply store a unique post ID in the index, and then use that to reference any details I need from a separate list of post data. I'll save that optimization for a future blog post.\n\nFor now I essentially replaced the `Set\u003cstring\u003e` with a `{ title: string, slug: string }[]`. It's not a Set anymore, so I need make sure I'm not adding duplicates myself.\n\nThen in my `addToIndex` function I simply pass in the whole post object and inside I pull out the title and slug and add an entry to the index.\n\nHere is the full refactored code with these changes:\n\n*preprocessors/search-index/search-index.ts*\n```typescript\nimport { PostData } from \"../../dtos/PostData\";\nimport { getPostData } from \"../../utils/articleFileUtils\";\nimport * as fs from \"fs\";\n\nexport const createSearchIndex = (postDataList: PostData[]): Map\u003cstring, { title: string, slug: string }[]\u003e =\u003e {\n\tconst searchIndex: Map\u003cstring, { title: string, slug: string }[]\u003e = new Map();\n\tpostDataList.forEach((post: PostData) =\u003e {\n\t\t\n\t\t// parse tags\n\t\tpost.tags.forEach((tag: string) =\u003e {\n\t\t\tconst tagTokens = tokenizeText(tag);\n\t\t\ttagTokens.forEach((token: string) =\u003e {\n\t\t\t\tconst nGrams = createNGrams(token);\n\t\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\t\taddToIndex(searchIndex, nGram, post);\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\t\t\n\t\t// parse titles\n\t\tconst titleTokens = tokenizeText(post.title);\n\t\t\ttitleTokens.forEach((token: string) =\u003e {\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post);\n\t\t\t});\n\t\t});\n\t\t\n\t\t// parse excerpts\n\t\tconst excerptTokens = tokenizeText(post.excerpt);\n\t\texcerptTokens.forEach((token: string) =\u003e {\n\t\t\tconst nGrams = createNGrams(token);\n\t\t\tnGrams.forEach((nGram: string) =\u003e {\n\t\t\t\taddToIndex(searchIndex, nGram, post);\n\t\t\t});\n\t\t});\n\t\t\n\t});\n\treturn searchIndex;\n}\n\nconst addToIndex = (searchIndex: Map\u003cstring, { title: string, slug: string }[]\u003e, key: string, post: PostData) =\u003e {\n\tconst value = {\"title\": post.title, \"slug\": post.slug};\n\tif (!searchIndex.has(key)) {\n\t\tsearchIndex.set(key, new Array());\n\t}\n\tlet found = false;\n\tfor (let item of searchIndex.get(key)) {\n\t\tif (item.title === value.title) {\n\t\t\tfound = true;\n\t\t}\n\t}\n\tif (!found) {\n\t\tsearchIndex.get(key).push(value);\n\t}\n}\n\nexport const tokenizeText = (text: string): string[] =\u003e {\n\treturn text\n\t\t.replace(/[\".,?!:;'[\\]{\\/}@#$%^\u0026*(→)]/g, '')\n\t\t.replace(/-/g, ' ')\n\t\t.split(' ')\n\t\t.filter((token: string) =\u003e token.length \u003e 0)\n\t\t.map((token: string) =\u003e token.toLowerCase());\n}\n\nexport const createNGrams = (token: string): Set\u003cstring\u003e =\u003e {\n\tconst n = 10;\n\tconst nGrams: Set\u003cstring\u003e = new Set();\n\tfor (let nx = 1; nx \u003c= n; nx++) {\n\t\tfor (let i = 0; i \u003c token.length - nx + 1; i++) {\n\t\t\tconst nGram = token.slice(i, i + nx);\n\t\t\tnGrams.add(nGram);\n\t\t}\n\t};\n\tif (token.length \u003e n) {\n\t\tnGrams.add(token);\n\t}\n\treturn nGrams;\n}\n\nconst startTime = performance.now();\n\nconst postDataList: PostData[] = getPostData(\"./posts\");\n// console.log(\"Post Data List: \", postDataList);\nconst searchIndex: Map\u003cstring, { title: string, slug: string }[]\u003e = createSearchIndex(postDataList);\n// console.log(\"Search Index: \", searchIndex);\nconst searchIndexJsonString = JSON.stringify(Object.fromEntries(searchIndex.entries()));\n// console.log(\"Search Index JSON: \", searchIndexJsonString);\nconst searchIndexLocation = \"./components/elements/search-index.json\";\nfs.writeFileSync(searchIndexLocation, searchIndexJsonString, \"utf8\");\nconsole.log(`⏺ Search index saved to ${searchIndexLocation}\\n`);\n\nconst endTime = performance.now();\n\nconsole.log(`⏺ ${postDataList.length} posts`);\nconsole.log(`⏺ ${searchIndex.size} index entries`);\nconst sizeInBytes = searchIndexJsonString.length;\nconsole.log(`⏺ ${Number(sizeInBytes/1000).toFixed(1)} KB JSON size`);\nconsole.log(`⏺ ${Number(endTime - startTime).toFixed(1)} ms to process search index`);\nconsole.log(\"\\n✔ Done\")\n```\n\nI also refactored and simplified how I was converting the index to JSON, and added some nice console output as well.\n\n## References\n\n- [Writing full text search in Javascript for Next.js static site](https://ahmadrosid.com/blog/fulltext-search-with-inverted-index) - Great article from Ahmad Rosid on creating a static site search. Heavily inpired my implementation.\n- [Pagefind](https://pagefind.app/) - a static site search tool that I didn't end up using\n- [Add search to your Next.js static site with Pagefind](https://www.petemillspaugh.com/nextjs-search-with-pagefind) - article on using Pagefind with Next. Did not find it very helpful\n\n## Repository\n\nThis website in it's entirety is viewable on [GitHub](https://github.com/tyrelh/personal-site-nextjs).\n\nThe search logic doesn't have it's own repo yet. But I'll update that here if I ever split it out.\n\n## Conclusion\n\nWell thats it for the search index preprocessor. In an upcoming article I'll discuss how I built a search component to use this search index on my Next static site (this site!).\n\nGive the search a try! It's near the top on desktop or bottom on mobile.\n\nHope you found this interesting or useful. 🙌🏻\n\n\n"},"searchIndexJson":"[[\"1\",[2,8,22,20,21]],[\"2\",[2,3,4,10,14,9,22,21,12]],[\"3\",[3,8,22]],[\"4\",[2]],[\"5\",[8]],[\"7\",[8]],[\"10\",[2]],[\"13\",[8]],[\"20\",[2,4,10,14,22,12]],[\"24\",[9]],[\"30\",[8]],[\"40\",[2]],[\"58\",[8]],[\"100\",[2]],[\"135\",[8]],[\"201\",[2,4]],[\"202\",[10,14,12]],[\"240\",[9]],[\"308\",[8]],[\"400\",[2]],[\"580\",[8]],[\"1000\",[2]],[\"2018\",[2,4]],[\"2020\",[10]],[\"2021\",[10]],[\"2022\",[14,12]],[\"2023\",[14]],[\"3080\",[8]],[\"4000\",[2]],[\"5800\",[8]],[\"a\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"aw\",[11,6,12]],[\"aws\",[11,6,12]],[\"d\",[11,18,7,5,16,3,4,1,10,19,6,14,22,20,21,17,15,12,13]],[\"dd\",[11]],[\"ddn\",[11]],[\"ddns\",[11]],[\"n\",[11,18,5,16,4,1,10,19,6,14,22,20,21,17,15,12]],[\"no\",[11,18,5,4,1,10,6,22,17]],[\"nod\",[11,5,6]],[\"node\",[11,5,6]],[\"r\",[11,2,18,7,16,14,8,9,15,12,13]],[\"ra\",[11,14,9]],[\"ras\",[11,14]],[\"rasp\",[11,14]],[\"raspb\",[11,14]],[\"raspbe\",[11,14]],[\"raspber\",[11,14]],[\"raspberr\",[11,14]],[\"raspberry\",[11,14]],[\"p\",[11,2,18,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15]],[\"pi\",[11,3,10,6,14]],[\"i\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"in\",[11,2,18,5,4,1,10,6,14,8,22,20,21,17,15,12,13]],[\"inf\",[11,18,1]],[\"infr\",[11,18]],[\"infra\",[11,18]],[\"infras\",[11,18]],[\"infrast\",[11,18]],[\"infrastr\",[11,18]],[\"infrastru\",[11,18]],[\"infrastruc\",[11,18]],[\"infrastructure\",[11,18]],[\"dy\",[11]],[\"dyn\",[11]],[\"dyna\",[11]],[\"dynam\",[11]],[\"dynami\",[11]],[\"dynamic\",[11]],[\"dn\",[11]],[\"dns\",[11]],[\"is\",[11,2,3,1,10,6,22,21,17,15,12,13]],[\"h\",[11,2,18,3,4,1,10,6,14,8,9,20,21,17,15,12,13]],[\"ha\",[11,18,3,1,14,8,9,17,15,12]],[\"han\",[11,18]],[\"hand\",[11,18]],[\"handy\",[11]],[\"if\",[11]],[\"y\",[11]],[\"yo\",[11]],[\"you\",[11]],[\"w\",[11,2,18,7,5,16,4,1,19,6,14,9,22,20,21,17,15,12,13]],[\"wa\",[11,5,19,9,22]],[\"wan\",[11,5]],[\"want\",[11,5]],[\"t\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"to\",[11,2,7,5,16,3,4,1,10,19,14,9,22,20,21,17,12,13]],[\"ho\",[11,2,10,20,17,13]],[\"hos\",[11]],[\"host\",[11]],[\"s\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"so\",[11,18,5,14,22,17,12,13]],[\"som\",[11,18,5,14,22,17,12]],[\"some\",[11,18,14,22,17,12]],[\"somet\",[11]],[\"someth\",[11]],[\"somethi\",[11]],[\"somethin\",[11]],[\"something\",[11]],[\"o\",[11,2,7,5,3,4,1,10,19,9,22,20,21,17,15,12]],[\"or\",[11,4]],[\"ac\",[11,2,5,6,12,13]],[\"acc\",[11]],[\"acce\",[11]],[\"acces\",[11]],[\"access\",[11]],[\"on\",[11,3,19,22,21,15]],[\"your\",[11]],[\"hom\",[11,2]],[\"home\",[11,2]],[\"ne\",[11,16,19,14,22,20,21,12]],[\"net\",[11]],[\"netw\",[11]],[\"netwo\",[11]],[\"networ\",[11]],[\"network\",[11]],[\"b\",[11,2,18,7,5,16,3,4,1,10,19,6,8,9,20,21,15,13]],[\"bu\",[11,7,16,4,1,8,9,20,21,13]],[\"but\",[11,4,1,13]],[\"do\",[11,22,15,12,13]],[\"don\",[11]],[\"dont\",[11]],[\"hav\",[11,12]],[\"have\",[11,12]],[\"st\",[11,16,3,4,10,19,14,22,20,21,12]],[\"sta\",[11,16,3,4,10,19,22,20,21,12]],[\"stat\",[11,16,3,19,22,20,21,12]],[\"stati\",[11,16,3,19,22,20,21,12]],[\"static\",[11,16,3,19,22,20,21,12]],[\"ip\",[11]],[\"ad\",[11]],[\"add\",[11]],[\"addr\",[11]],[\"addre\",[11]],[\"addres\",[11]],[\"address\",[11]],[\"f\",[11,2,18,7,3,4,1,10,19,6,14,8,9,22,20,21,17,12]],[\"fr\",[11,2,18,3,4,1,10,14,8,9,22,20]],[\"fro\",[11,2,18,3,1,14,8,9,22,20]],[\"from\",[11,18,3,1,14,8,9,22,20]],[\"isp\",[11]],[\"bui\",[11,7,16,1,8,9,20,21]],[\"buil\",[11,7,16,1,8,9,20,21]],[\"built\",[11,7,16,21]],[\"l\",[11,2,18,7,3,4,1,10,19,20,21,17,12]],[\"li\",[11,2,7,4,1,10,19,21,17,12]],[\"lit\",[11,10]],[\"litt\",[11,10]],[\"littl\",[11,10]],[\"little\",[11,10]],[\"sc\",[11,1,20]],[\"scr\",[11,1,20]],[\"scri\",[11]],[\"scrip\",[11]],[\"script\",[11]],[\"fo\",[11,18,7,4,6,14,8,9,22,20,21,17,12]],[\"for\",[11,18,7,4,6,8,9,22,20,21,12]],[\"ro\",[11,2,13]],[\"rou\",[11,2]],[\"rout\",[11]],[\"route\",[11]],[\"route5\",[11]],[\"route53\",[11]],[\"u\",[11,2,7,5,3,4,10,6,8,9,21,17]],[\"us\",[11,7,5,4,6,8,17]],[\"usi\",[11,5,4,6]],[\"usin\",[11,5,4,6]],[\"using\",[11,5,4,6]],[\"th\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"tha\",[11,2,5,3,19,22,21,17,15,13]],[\"that\",[11,2,3,19,22,21,17,15,13]],[\"ru\",[11,12]],[\"run\",[11,12]],[\"runs\",[11]],[\"py\",[2]],[\"pyt\",[2]],[\"pyth\",[2]],[\"pytho\",[2]],[\"python\",[2]],[\"ai\",[2]],[\"e\",[2,5,16,4,6,8,9,20,17,15,13]],[\"ev\",[2,8,17,15,13]],[\"eve\",[2,17,15,13]],[\"even\",[2,15,13]],[\"event\",[2]],[\"events\",[2]],[\"ba\",[2,5,9]],[\"bat\",[2,5]],[\"batt\",[2,5]],[\"battl\",[2,5]],[\"battle\",[2,5]],[\"battles\",[2,5]],[\"battlesn\",[2,5]],[\"battlesna\",[2,5]],[\"battlesnak\",[2,5]],[\"battlesnake\",[2,5]],[\"pr\",[2,3,4,1,19,6,8,9,20,21,17]],[\"pro\",[2,3,4,1,19,6,8,9,20,21]],[\"prog\",[2,4,1]],[\"progr\",[2,4,1]],[\"progra\",[2,4,1]],[\"program\",[2,4,1]],[\"programm\",[2,4,1]],[\"programmi\",[2,4,1]],[\"programmin\",[2,4,1]],[\"programming\",[2,4,1]],[\"c\",[2,18,7,5,16,4,1,19,6,8,9,20,21,17,15,12,13]],[\"co\",[2,18,5,16,1,6,9,21,15]],[\"com\",[2,1,9,21]],[\"comp\",[2,1,9,21]],[\"compe\",[2]],[\"compet\",[2]],[\"competi\",[2]],[\"competit\",[2]],[\"competiti\",[2]],[\"competitio\",[2]],[\"competition\",[2]],[\"wh\",[2,9,17,15,12,13]],[\"whe\",[2,9]],[\"wher\",[2]],[\"where\",[2]],[\"pa\",[2,18,5,16,1,19,8,9,22,20,21,15]],[\"par\",[2,5,1,8,9,22,20,21,15]],[\"part\",[2,5,1,8,9,22,20,21,15]],[\"parti\",[2]],[\"partic\",[2]],[\"partici\",[2]],[\"particip\",[2]],[\"participa\",[2]],[\"participan\",[2]],[\"participants\",[2]],[\"cr\",[2,6,20,21]],[\"cre\",[2,6,20,21]],[\"crea\",[2,6,20,21]],[\"creat\",[2,6,20,21]],[\"create\",[2,20,21]],[\"an\",[2,18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"se\",[2,7,5,8,9,22,20,21,13]],[\"ser\",[2,20,21]],[\"serv\",[2]],[\"serve\",[2]],[\"server\",[2]],[\"act\",[2,5,6,12,13]],[\"acts\",[2]],[\"as\",[2,18,5,3,10,9,17,13]],[\"the\",[2,18,7,16,4,10,19,14,8,9,22,20,21,17,15]],[\"br\",[2,13]],[\"bra\",[2]],[\"brai\",[2]],[\"brain\",[2]],[\"of\",[2,5,3,10,9,20,21,17,15,12]],[\"sn\",[2]],[\"sna\",[2]],[\"snak\",[2]],[\"snake\",[2]],[\"cl\",[2,19,20,17]],[\"cla\",[2]],[\"clas\",[2]],[\"class\",[2]],[\"classi\",[2]],[\"classic\",[2]],[\"g\",[2,18,5,16,3,4,10,19,6,14,8,9,22,20,21,15,12,13]],[\"ga\",[2,4,10,8,9]],[\"gam\",[2,4,10,8,9]],[\"game\",[2,4,10]],[\"compete\",[2]],[\"roun\",[2]],[\"round\",[2]],[\"rob\",[2]],[\"robi\",[2]],[\"robin\",[2]],[\"tou\",[2]],[\"tour\",[2]],[\"tourn\",[2]],[\"tourna\",[2]],[\"tournam\",[2]],[\"tourname\",[2]],[\"tournamen\",[2]],[\"tournament\",[2]],[\"pl\",[2,17]],[\"pla\",[2]],[\"play\",[2]],[\"playe\",[2]],[\"played\",[2]],[\"ou\",[2,3,20]],[\"out\",[2,20]],[\"liv\",[2,21]],[\"live\",[2,21]],[\"fron\",[2,3]],[\"front\",[2,3]],[\"au\",[2,18,6,13]],[\"aud\",[2]],[\"audi\",[2]],[\"audie\",[2]],[\"audien\",[2]],[\"audienc\",[2]],[\"audience\",[2]],[\"roug\",[2]],[\"rough\",[2]],[\"roughl\",[2]],[\"roughly\",[2]],[\"pe\",[2,17]],[\"peo\",[2]],[\"peop\",[2]],[\"peopl\",[2]],[\"people\",[2]],[\"wi\",[2,18,16,4,1,19,9,21,15]],[\"win\",[2]],[\"winn\",[2]],[\"winne\",[2]],[\"winner\",[2]],[\"ta\",[2,18,10,19,17,15]],[\"tak\",[2,18,10,17]],[\"take\",[2,18]],[\"takes\",[2]],[\"up\",[2,3,4,10,9,17]],[\"bo\",[18,9]],[\"boo\",[18]],[\"book\",[18]],[\"not\",[18,4,1,17]],[\"note\",[18,17]],[\"notes\",[18]],[\"de\",[18,7,5,16,4,1,10,6,14,20,21,17,13]],[\"dev\",[18,7,5,4,10,14,13]],[\"devo\",[18,5,14,13]],[\"devop\",[18,5,14,13]],[\"devops\",[18,5,14,13]],[\"aut\",[18,6,13]],[\"auto\",[18,6,13]],[\"autom\",[18,6,13]],[\"automa\",[18,6,13]],[\"automat\",[18,6,13]],[\"automati\",[18,6,13]],[\"automatio\",[18,6,13]],[\"automation\",[18,6,13]],[\"te\",[18,5,4,13]],[\"tes\",[18,5]],[\"test\",[18,5]],[\"testi\",[18]],[\"testin\",[18]],[\"testing\",[18]],[\"con\",[18,5,16,6,9]],[\"cont\",[18,5,6]],[\"conti\",[18,5,6]],[\"contin\",[18,5,6]],[\"continu\",[18,5,6]],[\"continuo\",[18,5,6]],[\"continuou\",[18,5,6]],[\"continuous\",[18,5,6]],[\"int\",[18,5,10,6,20,21,17,13]],[\"inte\",[18,5,6,21,17,13]],[\"integ\",[18,5,6]],[\"integr\",[18,5,6]],[\"integra\",[18,5,6]],[\"integrat\",[18,5,6]],[\"integrati\",[18,5,6]],[\"integratio\",[18,5,6]],[\"integration\",[18,5,6]],[\"dep\",[18,16,6]],[\"depl\",[18,16,6]],[\"deplo\",[18,16,6]],[\"deploy\",[18,16,6]],[\"deploym\",[18,16,6]],[\"deployme\",[18,16,6]],[\"deploymen\",[18,16,6]],[\"deployment\",[18,16,6]],[\"ci\",[18,5,6,12]],[\"cic\",[18,5,6,12]],[\"cicd\",[18,5,6,12]],[\"cod\",[18]],[\"code\",[18]],[\"gi\",[18,5,16,6,12,13]],[\"git\",[18,5,16,6,12,13]],[\"fe\",[18,20]],[\"fee\",[18]],[\"feed\",[18]],[\"feedb\",[18]],[\"feedba\",[18]],[\"feedbac\",[18]],[\"feedback\",[18]],[\"lo\",[18,3,4,20]],[\"loo\",[18,4,20]],[\"loop\",[18,4]],[\"loops\",[18,4]],[\"le\",[18,10,12]],[\"lea\",[18,10,12]],[\"lear\",[18,10,12]],[\"learn\",[18,10,12]],[\"learni\",[18,10,12]],[\"learnin\",[18,10,12]],[\"learning\",[18,10,12]],[\"handb\",[18]],[\"handbo\",[18]],[\"handboo\",[18]],[\"handbook\",[18]],[\"he\",[18,4,6,14,21,12]],[\"her\",[18,6,14,21,12]],[\"here\",[18,6,14,21,12]],[\"ar\",[18,1,10,19,14,9,20,21]],[\"are\",[18,14,9]],[\"po\",[18,19,22,17]],[\"poi\",[18]],[\"poin\",[18]],[\"point\",[18]],[\"form\",[18,8,9]],[\"takea\",[18]],[\"takeaw\",[18]],[\"takeawa\",[18]],[\"takeaway\",[18]],[\"takeaways\",[18]],[\"m\",[18,7,5,3,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"my\",[18,5,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"re\",[18,7,16,14,15,13]],[\"rea\",[18,7,16]],[\"read\",[18]],[\"readi\",[18]],[\"readin\",[18]],[\"reading\",[18]],[\"by\",[18,19,9]],[\"j\",[18,7,5,16,3,4,1,19,6,22,20,21,12,13]],[\"jo\",[18,1,6,13]],[\"joh\",[18]],[\"john\",[18]],[\"wil\",[18]],[\"will\",[18]],[\"willi\",[18]],[\"willis\",[18]],[\"ge\",[18,16,4,19,22,20,21,12,13]],[\"gen\",[18,16,4,19,22,20,21,12]],[\"gene\",[18,16,4,19,22,20,21,12]],[\"k\",[18,1,14,12,13]],[\"ki\",[18,1,14]],[\"kim\",[18]],[\"and\",[18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"pat\",[18]],[\"patr\",[18]],[\"patri\",[18]],[\"patric\",[18]],[\"patrick\",[18]],[\"deb\",[18]],[\"debo\",[18]],[\"deboi\",[18]],[\"debois\",[18]],[\"reac\",[7,16]],[\"react\",[7,16]],[\"da\",[7,17,15,13]],[\"dar\",[7]],[\"dark\",[7]],[\"mo\",[7,10,20,17,13]],[\"mod\",[7]],[\"mode\",[7]],[\"ja\",[7,5,16,4,19,22,20,21]],[\"jav\",[7,5,16,4,19,22,20,21]],[\"java\",[7,5,16,4,19,22,20,21]],[\"javas\",[7,5,16,4,19,22,20,21]],[\"javasc\",[7,5,16,4,19,22,20,21]],[\"javascr\",[7,5,16,4,19,22,20,21]],[\"javascri\",[7,5,16,4,19,22,20,21]],[\"javascrip\",[7,5,16,4,19,22,20,21]],[\"javascript\",[7,5,16,4,19,22,20,21]],[\"we\",[7,19,14,20,21]],[\"web\",[7,19,14,20,21]],[\"webd\",[7,19,14]],[\"webde\",[7,19,14]],[\"webdev\",[7,19,14]],[\"tog\",[7]],[\"togg\",[7]],[\"toggl\",[7]],[\"toggle\",[7]],[\"deve\",[7,10,13]],[\"devel\",[7,10,13]],[\"develo\",[7,10,13]],[\"develop\",[7,10,13]],[\"develope\",[7,13]],[\"developed\",[7]],[\"lig\",[7,4,17]],[\"ligh\",[7,4,17]],[\"light\",[7,4,17]],[\"them\",[7]],[\"theme\",[7]],[\"thi\",[7,4,1,10,19,8,9,22,20,21,17,15,12,13]],[\"this\",[7,4,1,10,19,8,9,22,20,21,17,15,13]],[\"si\",[7,16,19,22,20,21,12]],[\"sit\",[7,16,19,22,20,21,12]],[\"site\",[7,16,19,22,20,21,12]],[\"sw\",[7]],[\"swi\",[7]],[\"swit\",[7]],[\"switc\",[7]],[\"switch\",[7]],[\"be\",[7,3,4,1,10,19,6,20,13]],[\"bet\",[7,4]],[\"betw\",[7]],[\"betwe\",[7]],[\"betwee\",[7]],[\"between\",[7]],[\"al\",[7,19,8,9,22]],[\"als\",[7]],[\"also\",[7]],[\"use\",[7,8,17]],[\"used\",[7]],[\"me\",[7,1,8,15,13]],[\"med\",[7]],[\"medi\",[7]],[\"media\",[7]],[\"q\",[7,21]],[\"qu\",[7,21]],[\"que\",[7]],[\"quer\",[7]],[\"queri\",[7]],[\"querie\",[7]],[\"queries\",[7]],[\"set\",[7,5]],[\"def\",[7]],[\"defa\",[7]],[\"defau\",[7]],[\"defaul\",[7]],[\"default\",[7]],[\"ma\",[7,19,8]],[\"mat\",[7]],[\"matc\",[7]],[\"match\",[7]],[\"v\",[7,4,14,12]],[\"vi\",[7]],[\"vis\",[7]],[\"visi\",[7]],[\"visit\",[7]],[\"visito\",[7]],[\"visitor\",[7]],[\"visitors\",[7]],[\"op\",[7,22,20]],[\"ope\",[7]],[\"oper\",[7]],[\"opera\",[7]],[\"operat\",[7]],[\"operati\",[7]],[\"operatin\",[7]],[\"operating\",[7]],[\"sy\",[7,14,9,17,15,12]],[\"sys\",[7,9]],[\"syst\",[7,9]],[\"syste\",[7,9]],[\"system\",[7,9]],[\"ch\",[7,20]],[\"cho\",[7]],[\"choi\",[7]],[\"choic\",[7]],[\"choice\",[7]],[\"ty\",[5,16,19,6,22,20,21]],[\"typ\",[5,16,19,6,22,20,21]],[\"type\",[5,16,19,6,22,20,21]],[\"types\",[5,16,19,6,22,20,21]],[\"typesc\",[5,16,19,6]],[\"typescr\",[5,16,19,6]],[\"typescri\",[5,16,19,6]],[\"typescrip\",[5,16,19,6]],[\"typescript\",[5,16,19,6]],[\"den\",[5]],[\"deno\",[5]],[\"gith\",[5,16,6,12,13]],[\"githu\",[5,16,6,12,13]],[\"github\",[5,16,6,12,13]],[\"acti\",[5,6,12,13]],[\"actio\",[5,6,12,13]],[\"action\",[5,6,12,13]],[\"actions\",[5,6,12,13]],[\"tests\",[5]],[\"tr\",[5,19,13]],[\"tra\",[5,13]],[\"tran\",[5]],[\"trans\",[5]],[\"transl\",[5]],[\"transla\",[5]],[\"translat\",[5]],[\"translati\",[5]],[\"translatin\",[5]],[\"translating\",[5]],[\"wante\",[5]],[\"wanted\",[5]],[\"setu\",[5]],[\"setup\",[5]],[\"it\",[5,10,9,21,13]],[\"was\",[5,19,22]],[\"mu\",[5]],[\"muc\",[5]],[\"much\",[5]],[\"ea\",[5,16]],[\"eas\",[5,16]],[\"easi\",[5,16]],[\"easie\",[5]],[\"easier\",[5]],[\"than\",[5]],[\"im\",[5,4,19,22,21,12]],[\"ima\",[5]],[\"imag\",[5]],[\"imagi\",[5]],[\"imagin\",[5]],[\"imagine\",[5]],[\"imagined\",[5]],[\"pag\",[16,19]],[\"page\",[16,19]],[\"pages\",[16,19]],[\"nex\",[16,19,14,22,20,21]],[\"next\",[16,19,14,22,20,21]],[\"nextj\",[16,19,14,22,20,21]],[\"nextjs\",[16,19,14,22,20,21]],[\"gener\",[16,4,19,22,20,21,12]],[\"genera\",[16,4,19,22,20,21,12]],[\"generat\",[16,19,22,20,21,12]],[\"generato\",[16,19,22,20,21,12]],[\"generator\",[16,19,22,20,21,12]],[\"generators\",[16,19,22,20,21,12]],[\"cov\",[16,9]],[\"cove\",[16,9]],[\"cover\",[16,9]],[\"conf\",[16]],[\"confi\",[16]],[\"config\",[16]],[\"ste\",[16]],[\"step\",[16]],[\"steps\",[16]],[\"nec\",[16]],[\"nece\",[16]],[\"neces\",[16]],[\"necess\",[16]],[\"necessa\",[16]],[\"necessar\",[16]],[\"necessary\",[16]],[\"easil\",[16]],[\"easily\",[16]],[\"wit\",[16,4,1,19,9,21,15]],[\"with\",[16,4,1,19,9,21,15]],[\"gr\",[3,8]],[\"gra\",[3,8]],[\"grai\",[3]],[\"grail\",[3]],[\"grails\",[3]],[\"mi\",[3,15]],[\"mig\",[3]],[\"migr\",[3]],[\"migra\",[3]],[\"migrat\",[3]],[\"migrati\",[3]],[\"migratin\",[3]],[\"migrating\",[3]],[\"fronte\",[3]],[\"fronten\",[3]],[\"frontend\",[3]],[\"ass\",[3,9]],[\"asse\",[3,9]],[\"asset\",[3]],[\"assets\",[3]],[\"du\",[3]],[\"dur\",[3]],[\"duri\",[3]],[\"durin\",[3]],[\"during\",[3]],[\"upg\",[3,9]],[\"upgr\",[3,9]],[\"upgra\",[3,9]],[\"upgrad\",[3,9]],[\"upgrade\",[3,9]],[\"upgradi\",[3]],[\"upgradin\",[3]],[\"upgrading\",[3]],[\"our\",[3]],[\"ap\",[3]],[\"app\",[3]],[\"appl\",[3]],[\"appli\",[3]],[\"applic\",[3]],[\"applica\",[3]],[\"applicat\",[3]],[\"applicati\",[3]],[\"applicatio\",[3]],[\"application\",[3]],[\"has\",[3]],[\"bee\",[3,13]],[\"been\",[3,13]],[\"lon\",[3]],[\"long\",[3]],[\"proc\",[3,8]],[\"proce\",[3,8]],[\"proces\",[3,8]],[\"process\",[3,8]],[\"ju\",[3,12]],[\"jus\",[3,12]],[\"just\",[3,12]],[\"one\",[3,19,15]],[\"pie\",[3]],[\"piec\",[3]],[\"piece\",[3]],[\"p5\",[4]],[\"p5j\",[4]],[\"p5js\",[4]],[\"lights\",[4]],[\"lightsh\",[4]],[\"lightshi\",[4]],[\"lightshif\",[4]],[\"lightshift\",[4]],[\"star\",[4,10]],[\"start\",[4,10]],[\"starte\",[4,10]],[\"started\",[4,10]],[\"proj\",[4,19,6,20,21]],[\"proje\",[4,19,6,20,21]],[\"projec\",[4,19,6,20,21]],[\"project\",[4,19,6,20,21]],[\"hel\",[4]],[\"help\",[4]],[\"tea\",[4,13]],[\"teac\",[4]],[\"teach\",[4]],[\"mys\",[4,15]],[\"myse\",[4,15]],[\"mysel\",[4,15]],[\"myself\",[4,15]],[\"bett\",[4]],[\"bette\",[4]],[\"better\",[4]],[\"ob\",[4,17]],[\"obj\",[4]],[\"obje\",[4]],[\"objec\",[4]],[\"object\",[4]],[\"ori\",[4]],[\"orie\",[4]],[\"orien\",[4]],[\"orient\",[4]],[\"oriente\",[4]],[\"oriented\",[4]],[\"str\",[4]],[\"stru\",[4]],[\"struc\",[4]],[\"struct\",[4]],[\"structu\",[4]],[\"structur\",[4]],[\"structure\",[4]],[\"upd\",[4]],[\"upda\",[4]],[\"updat\",[4]],[\"update\",[4]],[\"updated\",[4]],[\"updatedr\",[4]],[\"updatedra\",[4]],[\"updatedraw\",[4]],[\"general\",[4]],[\"imp\",[4,22,21]],[\"impl\",[4,22]],[\"imple\",[4,22]],[\"implem\",[4,22]],[\"impleme\",[4,22]],[\"implemen\",[4,22]],[\"implement\",[4,22]],[\"implemente\",[4,22]],[\"implemented\",[4,22]],[\"fra\",[4]],[\"fram\",[4]],[\"frame\",[4]],[\"framew\",[4]],[\"framewo\",[4]],[\"framewor\",[4]],[\"framework\",[4]],[\"dr\",[4]],[\"dra\",[4]],[\"draw\",[4]],[\"ca\",[4,8,13]],[\"can\",[4]],[\"canv\",[4]],[\"canva\",[4]],[\"canvas\",[4]],[\"drawi\",[4]],[\"drawin\",[4]],[\"drawing\",[4]],[\"fu\",[4,9,22,17]],[\"fun\",[4,22,17]],[\"func\",[4,22,17]],[\"funct\",[4,22,17]],[\"functi\",[4,22,17]],[\"functio\",[4,22,17]],[\"function\",[4,22,17]],[\"functiona\",[4,22,17]],[\"functional\",[4,22,17]],[\"functionality\",[4,22,17]],[\"noth\",[4]],[\"nothi\",[4]],[\"nothin\",[4]],[\"nothing\",[4]],[\"el\",[4,6]],[\"els\",[4]],[\"else\",[4]],[\"va\",[4,14]],[\"van\",[4]],[\"vani\",[4]],[\"vanil\",[4]],[\"vanill\",[4]],[\"vanilla\",[4]],[\"mec\",[1]],[\"mech\",[1]],[\"mecha\",[1]],[\"mechan\",[1]],[\"mechani\",[1]],[\"mechanic\",[1]],[\"mechanica\",[1]],[\"mechanical\",[1]],[\"ke\",[1]],[\"key\",[1]],[\"keyb\",[1]],[\"keybo\",[1]],[\"keyboa\",[1]],[\"keyboar\",[1]],[\"keyboard\",[1]],[\"keyboards\",[1]],[\"ard\",[1]],[\"ardu\",[1]],[\"ardui\",[1]],[\"arduin\",[1]],[\"arduino\",[1]],[\"c+\",[1]],[\"c++\",[1]],[\"har\",[1,14,8,9,17,15]],[\"hard\",[1,14,8,9,17,15]],[\"hardw\",[1,14,8,9,17,15]],[\"hardwa\",[1,14,8,9,17,15]],[\"hardwar\",[1,14,8,9,17,15]],[\"hardware\",[1,14,8,9,17,15]],[\"build\",[1,8,9,20,21]],[\"buildi\",[1,21]],[\"buildin\",[1,21]],[\"building\",[1,21]],[\"scra\",[1,20]],[\"scrat\",[1,20]],[\"scratc\",[1,20]],[\"scratch\",[1,20]],[\"af\",[1,20]],[\"aft\",[1,20]],[\"afte\",[1,20]],[\"after\",[1,20]],[\"bec\",[1]],[\"beco\",[1]],[\"becom\",[1]],[\"becomi\",[1]],[\"becomin\",[1]],[\"becoming\",[1]],[\"infa\",[1]],[\"infat\",[1]],[\"infatu\",[1]],[\"infatua\",[1]],[\"infatuat\",[1]],[\"infatuate\",[1]],[\"infatuated\",[1]],[\"cu\",[1,9]],[\"cus\",[1,9]],[\"cust\",[1,9]],[\"custo\",[1,9]],[\"custom\",[1,9]],[\"dec\",[1,20]],[\"deci\",[1,20]],[\"decid\",[1,20]],[\"decide\",[1,20]],[\"decided\",[1,20]],[\"ow\",[1,20,17,15]],[\"own\",[1,20,17,15]],[\"kit\",[1]],[\"lik\",[1,12]],[\"like\",[1,12]],[\"jou\",[1,6]],[\"jour\",[1,6]],[\"journ\",[1,6]],[\"journe\",[1,6]],[\"journey\",[1,6]],[\"thr\",[1]],[\"thro\",[1]],[\"throu\",[1]],[\"throug\",[1]],[\"through\",[1]],[\"des\",[1,21,17]],[\"desi\",[1]],[\"desig\",[1]],[\"design\",[1]],[\"designi\",[1]],[\"designin\",[1]],[\"designing\",[1]],[\"aq\",[1]],[\"aqu\",[1]],[\"aqui\",[1]],[\"aquir\",[1]],[\"aquiri\",[1]],[\"aquirin\",[1]],[\"aquiring\",[1]],[\"parts\",[1,9]],[\"compl\",[1]],[\"comple\",[1]],[\"complet\",[1]],[\"complete\",[1]],[\"la\",[1]],[\"lay\",[1]],[\"layo\",[1]],[\"layou\",[1]],[\"layout\",[1]],[\"designe\",[1]],[\"designed\",[1]],[\"un\",[10]],[\"uni\",[10]],[\"unit\",[10]],[\"unity\",[10]],[\"go\",[10,19,14,15]],[\"god\",[10]],[\"godo\",[10]],[\"godot\",[10]],[\"pix\",[10]],[\"pixe\",[10]],[\"pixel\",[10]],[\"art\",[10,19,20,21]],[\"intr\",[10]],[\"intro\",[10]],[\"introd\",[10]],[\"introdu\",[10]],[\"introduc\",[10]],[\"introduct\",[10]],[\"introducti\",[10]],[\"introduction\",[10]],[\"developm\",[10,13]],[\"developme\",[10,13]],[\"developmen\",[10,13]],[\"development\",[10,13]],[\"beg\",[10]],[\"bega\",[10]],[\"began\",[10]],[\"hob\",[10]],[\"hobb\",[10]],[\"hobby\",[10]],[\"now\",[10,22]],[\"begi\",[10]],[\"begin\",[10]],[\"beginn\",[10]],[\"beginni\",[10]],[\"beginnin\",[10]],[\"beginning\",[10]],[\"taki\",[10,17]],[\"takin\",[10,17]],[\"taking\",[10,17]],[\"mos\",[10]],[\"most\",[10]],[\"fre\",[10]],[\"free\",[10]],[\"ti\",[10,12]],[\"tim\",[10,12]],[\"time\",[10,12]],[\"into\",[10,6,20,21,13]],[\"how\",[10,20,17,13]],[\"got\",[10,14,15]],[\"too\",[10]],[\"tool\",[10]],[\"tools\",[10]],[\"learne\",[10]],[\"learned\",[10]],[\"tag\",[19]],[\"goa\",[19]],[\"goal\",[19]],[\"mak\",[19]],[\"make\",[19]],[\"tags\",[19]],[\"alr\",[19]],[\"alre\",[19]],[\"alrea\",[19]],[\"alread\",[19]],[\"already\",[19]],[\"di\",[19,20]],[\"dis\",[19,20]],[\"disp\",[19]],[\"displ\",[19]],[\"displa\",[19]],[\"display\",[19]],[\"displayi\",[19]],[\"displayin\",[19]],[\"displaying\",[19]],[\"alo\",[19]],[\"alon\",[19]],[\"along\",[19]],[\"alongs\",[19]],[\"alongsi\",[19]],[\"alongsid\",[19]],[\"alongside\",[19]],[\"arti\",[19,20,21]],[\"artic\",[19,20,21]],[\"articl\",[19,20,21]],[\"article\",[19,20,21]],[\"articles\",[19,20,21]],[\"cli\",[19,20]],[\"clic\",[19]],[\"click\",[19]],[\"clicka\",[19]],[\"clickab\",[19]],[\"clickabl\",[19]],[\"clickable\",[19]],[\"lin\",[19]],[\"link\",[19]],[\"links\",[19]],[\"fi\",[19,8,22,20,21]],[\"fil\",[19]],[\"filt\",[19]],[\"filte\",[19]],[\"filter\",[19]],[\"pos\",[19,22,17]],[\"post\",[19,22,17]],[\"posts\",[19,22]],[\"try\",[19]],[\"pip\",[6]],[\"pipe\",[6]],[\"pipel\",[6]],[\"pipeli\",[6]],[\"pipelin\",[6]],[\"pipeline\",[6]],[\"ela\",[6]],[\"elas\",[6]],[\"elast\",[6]],[\"elasti\",[6]],[\"elastic\",[6]],[\"bea\",[6]],[\"bean\",[6]],[\"beans\",[6]],[\"beanst\",[6]],[\"beansta\",[6]],[\"beanstal\",[6]],[\"beanstalk\",[6]],[\"creati\",[6]],[\"creatin\",[6]],[\"creating\",[6]],[\"automate\",[6]],[\"automated\",[6]],[\"wo\",[6,20,12]],[\"wor\",[6]],[\"work\",[6]],[\"workf\",[6]],[\"workfl\",[6]],[\"workflo\",[6]],[\"workflow\",[6]],[\"syn\",[14,17,15,12]],[\"syno\",[14,17,15,12]],[\"synol\",[14,17,15,12]],[\"synolo\",[14,17,15,12]],[\"synolog\",[14,17,15,12]],[\"synology\",[14,17,15,12]],[\"kid\",[14]],[\"kids\",[14]],[\"res\",[14]],[\"reso\",[14]],[\"resou\",[14]],[\"resour\",[14]],[\"resourc\",[14]],[\"resource\",[14]],[\"resources\",[14]],[\"fou\",[14]],[\"foun\",[14]],[\"found\",[14]],[\"val\",[14]],[\"valu\",[14]],[\"valua\",[14]],[\"valuab\",[14]],[\"valuabl\",[14]],[\"valuable\",[14]],[\"resouc\",[14]],[\"resouce\",[14]],[\"resouces\",[14]],[\"value\",[14]],[\"top\",[14]],[\"topi\",[14]],[\"topic\",[14]],[\"topics\",[14]],[\"inc\",[14]],[\"incl\",[14]],[\"inclu\",[14]],[\"includ\",[14]],[\"include\",[14]],[\"stu\",[14]],[\"stuf\",[14]],[\"stuff\",[14]],[\"pc\",[8,9]],[\"gami\",[8,9]],[\"gamin\",[8,9]],[\"gaming\",[8,9]],[\"sm\",[8,9,13]],[\"sma\",[8,9,13]],[\"smal\",[8,9,13]],[\"small\",[8,9,13]],[\"fa\",[8,9]],[\"fac\",[8,9]],[\"fact\",[8,9]],[\"facto\",[8,9]],[\"factor\",[8,9]],[\"fir\",[8,20,21]],[\"firs\",[8,20,21]],[\"first\",[8,20,21]],[\"sec\",[8,9]],[\"seco\",[8,9]],[\"secon\",[8,9]],[\"second\",[8,9]],[\"prop\",[8]],[\"prope\",[8]],[\"proper\",[8]],[\"mac\",[8]],[\"mach\",[8]],[\"machi\",[8]],[\"machin\",[8]],[\"machine\",[8]],[\"uses\",[8]],[\"ry\",[8]],[\"ryz\",[8]],[\"ryze\",[8]],[\"ryzen\",[8]],[\"5800x\",[8]],[\"processo\",[8]],[\"processor\",[8]],[\"evg\",[8]],[\"evga\",[8]],[\"rt\",[8]],[\"rtx\",[8]],[\"x\",[8]],[\"xc\",[8]],[\"xc3\",[8]],[\"ul\",[8]],[\"ult\",[8]],[\"ultr\",[8]],[\"ultra\",[8]],[\"grap\",[8]],[\"graph\",[8]],[\"graphi\",[8]],[\"graphic\",[8]],[\"graphics\",[8]],[\"car\",[8,13]],[\"card\",[8]],[\"all\",[8,9,22]],[\"135l\",[8]],[\"met\",[8]],[\"meta\",[8]],[\"metal\",[8]],[\"metalf\",[8]],[\"metalfi\",[8]],[\"metalfis\",[8]],[\"metalfish\",[8]],[\"s5\",[8]],[\"cas\",[8]],[\"case\",[8]],[\"ali\",[8]],[\"alie\",[8]],[\"aliex\",[8]],[\"aliexp\",[8]],[\"aliexpr\",[8]],[\"aliexpre\",[8]],[\"aliexpres\",[8]],[\"aliexpress\",[8]],[\"wat\",[9]],[\"wate\",[9]],[\"water\",[9]],[\"coo\",[9,15]],[\"cool\",[9,15]],[\"cooli\",[9]],[\"coolin\",[9]],[\"cooling\",[9]],[\"covers\",[9]],[\"ful\",[9]],[\"full\",[9]],[\"bot\",[9]],[\"both\",[9]],[\"cp\",[9]],[\"cpu\",[9]],[\"gp\",[9]],[\"gpu\",[9]],[\"coole\",[9]],[\"cooled\",[9]],[\"240m\",[9]],[\"240mm\",[9]],[\"rad\",[9]],[\"radi\",[9]],[\"radia\",[9]],[\"radiat\",[9]],[\"radiato\",[9]],[\"radiator\",[9]],[\"ek\",[9]],[\"ekw\",[9]],[\"ekwb\",[9]],[\"bar\",[9]],[\"barr\",[9]],[\"barro\",[9]],[\"barrow\",[9]],[\"compo\",[9,21]],[\"compon\",[9,21]],[\"compone\",[9,21]],[\"componen\",[9,21]],[\"component\",[9,21]],[\"components\",[9]],[\"pros\",[9]],[\"cons\",[9]],[\"en\",[9,20]],[\"enc\",[9]],[\"enco\",[9]],[\"encou\",[9]],[\"encoun\",[9]],[\"encount\",[9]],[\"encounte\",[9]],[\"encounter\",[9]],[\"encountere\",[9]],[\"encountered\",[9]],[\"when\",[9]],[\"assem\",[9]],[\"assemb\",[9]],[\"assembl\",[9]],[\"assembli\",[9]],[\"assemblin\",[9]],[\"assembling\",[9]],[\"typese\",[22,20,21]],[\"typesen\",[22,20,21]],[\"typesens\",[22,20,21]],[\"typesense\",[22,20,21]],[\"sea\",[22,20,21]],[\"sear\",[22,20,21]],[\"searc\",[22,20,21]],[\"search\",[22,20,21]],[\"opt\",[22,20]],[\"opti\",[22,20]],[\"optim\",[22]],[\"optimi\",[22]],[\"optimiz\",[22]],[\"optimizi\",[22]],[\"optimizin\",[22]],[\"optimizing\",[22]],[\"ind\",[22,20,21]],[\"inde\",[22,20,21]],[\"index\",[22,20,21]],[\"fin\",[22]],[\"fina\",[22]],[\"final\",[22]],[\"optimiza\",[22]],[\"optimizat\",[22]],[\"optimizati\",[22]],[\"optimizations\",[22]],[\"allu\",[22]],[\"allud\",[22]],[\"allude\",[22]],[\"alluded\",[22]],[\"ab\",[22,15]],[\"abl\",[22]],[\"able\",[22]],[\"get\",[22,13]],[\"ish\",[22]],[\"~\",[22]],[\"~7\",[22]],[\"~70\",[22]],[\"~700\",[22]],[\"~700k\",[22]],[\"~700kb\",[22]],[\"dow\",[22]],[\"down\",[22]],[\"~2\",[22]],[\"~22\",[22]],[\"~22k\",[22]],[\"~22kb\",[22]],[\"pre\",[20,17]],[\"prep\",[20]],[\"prepr\",[20]],[\"prepro\",[20]],[\"preproc\",[20]],[\"preproce\",[20]],[\"preproces\",[20]],[\"preprocess\",[20]],[\"preprocessing\",[20]],[\"seri\",[20,21]],[\"serie\",[20,21]],[\"series\",[20,21]],[\"disc\",[20]],[\"discu\",[20]],[\"discus\",[20]],[\"discuss\",[20]],[\"created\",[20]],[\"clie\",[20]],[\"clien\",[20]],[\"client\",[20]],[\"sid\",[20]],[\"side\",[20]],[\"webs\",[20,21]],[\"websi\",[20,21]],[\"websit\",[20,21]],[\"website\",[20,21]],[\"look\",[20]],[\"looki\",[20]],[\"lookin\",[20]],[\"looking\",[20]],[\"at\",[20,13]],[\"few\",[20]],[\"optio\",[20]],[\"option\",[20]],[\"options\",[20]],[\"ther\",[20]],[\"there\",[20]],[\"sites\",[20]],[\"projects\",[20]],[\"cha\",[20]],[\"chal\",[20]],[\"chall\",[20]],[\"challe\",[20]],[\"challen\",[20]],[\"challeng\",[20]],[\"challenge\",[20]],[\"wou\",[20]],[\"woul\",[20]],[\"would\",[20]],[\"mor\",[20,17,13]],[\"more\",[20,17,13]],[\"enj\",[20]],[\"enjo\",[20]],[\"enjoy\",[20]],[\"enjoya\",[20]],[\"enjoyab\",[20]],[\"enjoyabl\",[20]],[\"enjoyable\",[20]],[\"discusse\",[20]],[\"discusses\",[20]],[\"fol\",[21,17]],[\"foll\",[21,17]],[\"follo\",[21,17]],[\"follow\",[21,17]],[\"followu\",[21]],[\"followup\",[21]],[\"qui\",[21]],[\"quic\",[21]],[\"quick\",[21]],[\"searchi\",[21]],[\"searchin\",[21]],[\"searching\",[21]],[\"il\",[21,15]],[\"ill\",[21,15]],[\"impo\",[21]],[\"impor\",[21]],[\"import\",[21]],[\"ui\",[21]],[\"inter\",[21,17,13]],[\"intera\",[21]],[\"interac\",[21]],[\"interact\",[21]],[\"desc\",[21,17]],[\"descr\",[21,17]],[\"descri\",[21,17]],[\"describ\",[21,17]],[\"describe\",[21,17]],[\"described\",[21]],[\"na\",[17,15]],[\"nas\",[17,15]],[\"dat\",[17,15]],[\"data\",[17,15]],[\"owne\",[17,15]],[\"owner\",[17,15]],[\"owners\",[17,15]],[\"ownersh\",[17,15]],[\"ownershi\",[17,15]],[\"ownership\",[17,15]],[\"ph\",[17]],[\"pho\",[17]],[\"phot\",[17]],[\"photo\",[17]],[\"photos\",[17]],[\"obs\",[17]],[\"obsi\",[17]],[\"obsid\",[17]],[\"obsidi\",[17]],[\"obsidia\",[17]],[\"obsidian\",[17]],[\"ple\",[17]],[\"plex\",[17]],[\"lightr\",[17]],[\"lightro\",[17]],[\"lightroo\",[17]],[\"lightroom\",[17]],[\"per\",[17]],[\"pers\",[17]],[\"perso\",[17]],[\"person\",[17]],[\"persona\",[17]],[\"personal\",[17]],[\"clo\",[17]],[\"clou\",[17]],[\"cloud\",[17]],[\"prev\",[17]],[\"previ\",[17]],[\"previo\",[17]],[\"previou\",[17]],[\"previous\",[17]],[\"describi\",[17]],[\"describin\",[17]],[\"describing\",[17]],[\"wha\",[17,15,12,13]],[\"what\",[17,15,12,13]],[\"intere\",[17,13]],[\"interes\",[17,13]],[\"interest\",[17,13]],[\"interesti\",[17]],[\"interestin\",[17]],[\"interesting\",[17]],[\"ever\",[17]],[\"every\",[17]],[\"day\",[17,13]],[\"rec\",[15]],[\"rece\",[15]],[\"recen\",[15]],[\"recent\",[15]],[\"recentl\",[15]],[\"recently\",[15]],[\"doe\",[15,13]],[\"does\",[15,13]],[\"mea\",[15,13]],[\"mean\",[15,13]],[\"tw\",[15]],[\"two\",[15]],[\"tal\",[15]],[\"talk\",[15]],[\"bi\",[15]],[\"bit\",[15]],[\"abo\",[15]],[\"abou\",[15]],[\"about\",[15]],[\"thin\",[15,12]],[\"thing\",[15,12]],[\"things\",[15,12]],[\"min\",[15]],[\"mine\",[15]],[\"doc\",[12]],[\"dock\",[12]],[\"docke\",[12]],[\"docker\",[12]],[\"neo\",[12]],[\"neov\",[12]],[\"neovi\",[12]],[\"neovim\",[12]],[\"vp\",[12]],[\"vpn\",[12]],[\"ss\",[12]],[\"ssl\",[12]],[\"rund\",[12]],[\"rundo\",[12]],[\"rundow\",[12]],[\"rundown\",[12]],[\"id\",[12]],[\"kn\",[12,13]],[\"kno\",[12,13]],[\"know\",[12,13]],[\"won\",[12]],[\"wont\",[12]],[\"rol\",[13]],[\"role\",[13]],[\"sof\",[13]],[\"soft\",[13]],[\"softw\",[13]],[\"softwa\",[13]],[\"softwar\",[13]],[\"software\",[13]],[\"developer\",[13]],[\"job\",[13]],[\"i’\",[13]],[\"i’v\",[13]],[\"i’ve\",[13]],[\"gett\",[13]],[\"getti\",[13]],[\"gettin\",[13]],[\"getting\",[13]],[\"intereste\",[13]],[\"interested\",[13]],[\"care\",[13]],[\"caree\",[13]],[\"career\",[13]],[\"traj\",[13]],[\"traje\",[13]],[\"trajec\",[13]],[\"traject\",[13]],[\"trajecto\",[13]],[\"trajector\",[13]],[\"trajectory\",[13]],[\"bri\",[13]],[\"brie\",[13]],[\"brief\",[13]],[\"ex\",[13]],[\"exp\",[13]],[\"expl\",[13]],[\"explo\",[13]],[\"explor\",[13]],[\"explora\",[13]],[\"explorat\",[13]],[\"explorati\",[13]],[\"exploratio\",[13]],[\"exploration\",[13]],[\"see\",[13]],[\"rel\",[13]],[\"rela\",[13]],[\"relat\",[13]],[\"relati\",[13]],[\"relatin\",[13]],[\"relating\",[13]],[\"team\",[13]]]","postMetadataList":[{"title":"AWS Dynamic DNS","slug":"aws-ddns","date":"March 20, 2022","hero":"/images/posts/aws-ddns.jpg","excerpt":"A dynamic DNS is handy if you want to host something or access something on your home network but you don't have a static IP address from your ISP. I built a little dynamic DNS script for AWS Route53 using Node that runs on a Raspberry Pi.","tags":["aws","ddns","node","raspberry-pi","infrastructure"],"id":11,"readTimeInMinutes":5},{"title":"Battlesnake Programming Competition 2018","slug":"battlesnake-2018","date":"June 11, 2018","hero":"/images/posts/Battlesnake2018-1.jpg","excerpt":"Battlesnake is a programming competition where participants create an AI server that acts as the brain of a snake in the classic game Snake. Participants compete in a round-robin tournament played out live in front of an audience of roughly 1000 people. The winner takes home up to $4,000!","tags":["python","ai","events","battlesnake"],"id":2,"readTimeInMinutes":18},{"title":"Book Notes: DevOps Handbook, The","slug":"book-notes-devops-handbook","date":"August 27, 2023","hero":"/images/posts/devopshandbook.png","excerpt":"Here are some point-form takeaways from my notes from reading The DevOps Handbook by John Willis, Gene Kim, and Patrick Debois.","tags":["book-notes","devops","automation","testing","continuous-integration","continuous-deployment","cicd","infrastructure","infrastructure-as-code","git","feedback-loops","continuous-learning"],"id":18,"readTimeInMinutes":8},{"title":"Dark Mode React Toggle","slug":"dark-mode-react-toggle","date":"June 28, 2020","hero":"/images/posts/DarkModeToggle-1.svg","excerpt":"I developed a dark and light theme for this site and built a toggle to switch between them. Also I used media queries to set the default theme to match the visitors operating system choice.","tags":["react","dark-mode","javascript","webdev"],"id":7,"readTimeInMinutes":6},{"title":"Deno Tests \u0026 GitHub Actions CI","slug":"deno-and-github-actions","date":"May 23, 2020","hero":"/images/posts/DenoTestsAndGithubActionsCI.png","excerpt":"As part of translating my JavaScript and Node Battlesnake to TypeScript and Deno I wanted to setup continuous integration. It was som much easier than I imagined using GitHub Actions.","tags":["javascript","typescript","node","deno","github-actions","cicd","devops"],"id":5,"readTimeInMinutes":6},{"title":"Deploy a Next.js Static Site to GitHub Pages","slug":"github-pages-using-nextjs","date":"July 23, 2023","hero":"/images/posts/NextJSGitHubPagesHero.png","excerpt":"I cover the config and deployment steps necessary to easily deploy a static site built with Next.js to GitHub Pages.","tags":["github-pages","nextjs","react","static-site-generators","typescript","javascript"],"id":16,"readTimeInMinutes":8},{"title":"Migrating Frontend Assets During Grails 2 → 3 Upgrade","slug":"grails-asset-migration","date":"Dec 15, 2019","hero":"/images/posts/GrailsAssetMigration.svg","excerpt":"Upgrading our application from Grails 2 to Grails 3 has been a long process. Migrating our static frontend assets is just one piece of that process.","tags":["grails"],"id":3,"readTimeInMinutes":4},{"title":"Lightshift Game","slug":"lightshift-game","date":"Feb 1, 2020","hero":"/images/posts/lightshift-game-2.png","excerpt":"I started this project in 2018 to help teach myself better object-oriented programming structure, game update/draw loops, and JavaScript in general. Implemented using the P5.js framework for the draw loop and canvas drawing functionality with nothing else but vanilla JavaScript.","tags":["javascript","game-dev","p5js"],"id":4,"readTimeInMinutes":1},{"title":"Building a Mechanical Keyboard from Scratch","slug":"mechanical-keyboard","date":"Apr 20, 2017","hero":"/images/posts/MechanicalKeyboard-12.jpg","excerpt":"After becoming infatuated with custom mechanical keyboards I decided to build my own. Not from a kit, but like from scratch. This is my journey through designing, aquiring parts, building, and programming my own mechanical keyboard complete with a custom layout I designed.","tags":["mechanical-keyboards","arduino","c++","hardware"],"id":1,"readTimeInMinutes":17},{"title":"My Introduction to Game Development","slug":"my-introduction-to-game-development","date":"Mar 25, 2021","hero":"/images/posts/game-dev-godot.jpg","excerpt":"In 2020 I began learning game development as a hobby. Now in the beginning of 2021 it is taking up most of my free time. This is a little intro into how I got started and the tools I learned","tags":["game-dev","unity","godot","pixel-art"],"id":10,"readTimeInMinutes":8},{"title":"Next.js Tag Pages","slug":"nextjs-tag-pages","date":"March 25, 2024","hero":"/images/posts/tag-page-screenshot.png","excerpt":"My goal with this project was to make the tags I'm already displaying alongside articles to be clickable links that filter my posts by that tag. Try to click one!","tags":["nextjs","javascript","typescript","webdev","static-site-generators"],"id":19,"readTimeInMinutes":6},{"title":"Node CI/CD Pipeline using GitHub Actions \u0026 AWS Elastic Beanstalk","slug":"node-cicd-pipeline","date":"May 30, 2020","hero":"/images/posts/node-cicd-pipeline-hero.png","excerpt":"Here is my journey into creating an automated continuous integration and continuous deployment workflow for a project using GitHub Actions.","tags":["github-actions","cicd","typescript","aws","automation"],"id":6,"readTimeInMinutes":24},{"title":"Resources I Found Valuable in 2022","slug":"resources-2022","date":"Jan 20 2023","hero":"/images/posts/resources-2022-hero.jpg","excerpt":"Here are the resouces I got value from in 2023. Topics include kids, devops, web dev, and some hardware stuff.","tags":["devops","nextjs","hardware","raspberry-pi","synology","kids","webdev"],"id":14,"readTimeInMinutes":2},{"title":"Small Form Factor PC Build Part 1","slug":"sff-pc-part-1","date":"Jan 2 2021","hero":"/images/posts/sff-pc-part-1-5.jpg","excerpt":"My first small form factor gaming PC and my second proper gaming PC. This machine uses a Ryzen 7 5800X processor and a EVGA RTX 3080 XC3 Ultra graphics card, all in the 13.5L Metalfish S5 case from AliExpress.","tags":["pc","gaming","hardware"],"id":8,"readTimeInMinutes":5},{"title":"Small Form Factor PC Part 2 - Water Cooling","slug":"sff-pc-part-2","date":"Jan 25 2021","hero":"/images/posts/sff-pc-part-2-6.jpeg","excerpt":"This second part of my small form factor gaming PC build covers my upgrade to a full custom water cooling system. Both the CPU and GPU are cooled by a 240mm radiator with parts from EKWB and Barrow. I cover all of the components and all the pros and cons I encountered when assembling it.","tags":["pc","gaming","hardware"],"id":9,"readTimeInMinutes":29},{"title":"Static Site Search Part 3 - Optimizing the Index","slug":"static-site-search-optimizing-the-index","date":"April 18, 2024","hero":"/images/posts/static-site-search-optimizing-the-index.jpg","excerpt":"This is the final part (for now) on the search functionality for my site. I implemented some optimizations that I alluded to in part 1 \u0026 2. I was able to get my search index for my 20-ish posts from ~700kb down to ~22kb!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":22,"readTimeInMinutes":8},{"title":"Static Site Search Part 1 - Preprocessing Articles","slug":"static-site-search-preprocessing-articles","date":"April 3, 2024","hero":"/images/posts/static-site-search-preprocessing-articles.jpg","excerpt":"In this series of articles I discuss how I created a client-side search for my static website. After looking at a few options out there for static sites and Next.js projects, I decided the challenge to build my own search from scratch would be more enjoyable. This first article discusses how I preprocess my articles into a search index.","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":20,"readTimeInMinutes":15},{"title":"Static Site Search Part 2 - Search Component","slug":"static-site-search-search-component","date":"April 10, 2024","hero":"/images/posts/static-site-search-search-component.jpg","excerpt":"This is the followup to Part 1 in this series on building a Static Site Search for my website. In the first part I built a search index of my articles for quick searching. In this part I'll import that search index into my Next project and create a UI to interact with it. The search component described here is live on this site!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":21,"readTimeInMinutes":7},{"title":"How I use my Synology NAS as my personal cloud","slug":"synology-nas-how-i-use-it-as-my-personal-cloud","date":"August 15, 2023","hero":"/images/posts/synology-dsm-desktop.png","excerpt":"This is a follow-up to my previous post describing what a Synology NAS is. In this post I describe some of the more interesting functionality that I use every day.","tags":["synology","nas","data-ownership","hardware","photos","note-taking","obsidian","plex","lightroom"],"id":17,"readTimeInMinutes":10},{"title":"What is a Synology NAS?","slug":"synology-nas-what-is-it","date":"July 18, 2023","hero":"/images/posts/synology-nas.png","excerpt":"I recently got myself a Synology NAS. What does that even mean? In this part one of two, I talk a bit about what a Synology NAS is. In part two, I'll talk about the cool things I do with mine.","tags":["synology","nas","data-ownership","hardware"],"id":15,"readTimeInMinutes":3},{"title":"What I'm Learning in 2022","slug":"what-im-learning-in-2022","date":"March 23, 2022","hero":"/images/posts/what-im-learning-in-2022.jpg","excerpt":"Here is a rundown of what I'm learning in 2022, what I'd like to learn in 2022, and some things I know I just wont have time for in 2022.","tags":["docker","github-actions","neovim","vpn","synology","ssl","static-site-generators","cicd","aws"],"id":12,"readTimeInMinutes":5},{"title":"What is DevOps?","slug":"what-is-devops","date":"April 10, 2022","hero":"/images/posts/development-cycle.jpg","excerpt":"In my role as a software developer at my day job, I’ve been getting more interested in DevOps as a career trajectory. But what does that even mean? Do I even know? This is a brief exploration into what DevOps is and how I see it relating to a small development team.","tags":["devops","automation","github-actions"],"id":13,"readTimeInMinutes":7}]},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"static-site-search-preprocessing-articles"},"buildId":"MgYhWSqL3YClZtE0TZO2Y","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>