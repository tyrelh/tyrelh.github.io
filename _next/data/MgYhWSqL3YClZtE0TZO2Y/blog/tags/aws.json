{"pageProps":{"tag":"aws","postsForTag":[{"title":"What I'm Learning in 2022","slug":"what-im-learning-in-2022","date":"March 23, 2022","hero":"/images/posts/what-im-learning-in-2022.jpg","excerpt":"Here is a rundown of what I'm learning in 2022, what I'd like to learn in 2022, and some things I know I just wont have time for in 2022.","tags":["docker","github-actions","neovim","vpn","synology","ssl","static-site-generators","cicd","aws"],"id":12,"readTimeInMinutes":5,"content":"\nHere are some things that I'd like to learn more about in 2022. This is kindof a reference for myself. So I can look back at this next year and reflect on what I learned and what I wanted to learn. [Let me know on twitter](https://twitter.com/tyreldelaney) if you are learning these same things or you have any tips or resources to share!\n\n![Logo montage of all the technologies outlined in this article](what-im-learning-in-2022.jpg)\n\n## Index\n\n[Learning from scratch](#learning-from-scratch)\n\n* [Docker](#docker)\n* [Vim/NeoVim](#vimneovim)\n\n[Learning more of](#learning-more-of)\n\n* [Github Actions](#github-actions)\n* [AWS DynamoDB](#aws-dynamodb)\n* [AWS Client VPN, VPNs in general, and SSO](#aws-client-vpn-vpns-in-general-and-sso)\n* [SSH](#ssh)\n* [HTTPS/SSL](#httpsssl)\n* [Raspberry Pi](#raspberry-pi)\n* [Home Network](#home-network)\n\n[Things I'm interested in but might not get to this year](#things-im-interested-in-but-might-not-get-to-this-year)\n\n* [A better static site generator / CMS](#a-better-static-site-generator--cms)\n* [Webhooks](#webhooks)\n\n## Learning from scratch\n\n### Docker\nDocker really feels like one of those technologies that I've been conveniently ignoring for a little too long. I think what I'll do to start is simply try to containerize some smaller projects I'm working on this year to dip my toes in.\n\nI acquired a handful of second-hand Raspberry Pis not long ago and I've got a few ideas for some small home automation & monitoring projects that might be perfect simple projects to dockerize.\n\nA stretch goal would be to work up to containerizing our monolithic app at my day job.\n\n### Vim/NeoVim\nI've always just barely snuck by with my fluency in the terminal. The more I get into networking and Dev Ops the more this deficiency is showing. In general I'd just like to work in the terminal a bit more this year.\n\nSpecifically I'm going to try to develop a couple Node and Python projects I'm cooking up remotely on the Raspberry Pis I hope to run them on.\n\nReally two main goals I'd like to accomplish with this practice:\n1. Get proficient and comfortable using vim.\n2. Learn more about making a portable and lightweight dev environment. Something that I can easily spin up on a Raspberry Pi or AWS EC2 instance over SSH and feel comfortable doing real work in.\n\n## Learning more of\n\n### Github Actions\nAutomation is a big focus for me this year. And really just because I rely on Github both personally and professionally, Github Actions is a natural choice to skill up in.\n\nWe're now looking into automating and outsourcing our test suite at work and since we use Github for source control and code reviews/pull requests it makes total sense to use Github Actions.\n\nI've automated a few things using Github Actions already, namely [tests and deployment of my](https://github.com/tyrelh/battlesnake-typescript-node) [Battlesnake](https://play.battlesnake.com/) to AWS Elastic Beanstalk. Automating even just tests for our app at work will be a bit more of a challenge since it's a much older stack and has many more moving parts.\n\n### AWS DynamoDB\nI wasn't actually planning on learning DynamoDB at the start of the year. But a project idea came to mind and the possibility of using Dynamo to store data rather than something like S3 sounded intriguing.\n\nEssentially what I'm planning is building out a few Raspberry Pi temperature sensors for my house. Maybe 4 or 5 in total monitoring a few rooms in the house as well as the outdoor temperature.\n\nThe idea would be to collect data from all these sensors using Raspberry Pis maybe every 5 mins or so, and ship that data off to Dynamo. Then building an infrastructure to rotate through tables. Basically make a new table each day with a high write provision, and rotate down the previous days tables read and write provisions. Maybe after some period archive the data in S3.\n\nMight be over engineering for the task, but it's for learning.\n\n[Best Practices for Handling Time Series Data in DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-time-series.html)\n\n### AWS Client VPN, VPNs in general, and SSO\nWith my day job going fully remote this year, setting up secure remote tools has been high on our priority list. Part of that will be learning about AWS Client VPN which we may use to grant our devs access to some of our AWS infrastructure.\n\nPart of this work is also moving to more zero trust architecture, and leaning into SSO for authentication.\n\nAlso I recently acquired a Synology NAS for my home (which we actually use to use in our office before we gave that space up). I'm looking to centralize alot of my personal cloud use to the Synology and move away from services like Google Drive (office and documents), iCloud (photos), and Notion (notes). Part of that will be to setup a VPN at home so that I can use those services hosted in my home from anywhere. As well as accessing some of my Raspberry Pis for remote development.\n\n### SSH\nLearning more about SSH and tunneling goes hand-in-hand with a few other learning priorities I have. Learning best practices for connecting securely and crafting secure infrastructure. Also using SSH to practice remote development and learning terminal based tools.\n\n### HTTPS/SSL\nSame as above. Learning more about best practices around secure remote communication. Getting more confident understanding certs and how they work.\n\n### Raspberry Pi\nI've owned a Raspberry Pi 3 for a handful of years now, but I've never really had a project for it. I experimented a bit with retro game emulation on it, but those projects are pretty trivial to setup.\n\nNow I have a handful of Raspberry Pi 2s and 3s and I have some plans for some smaller single purpose projects for the house that will be perfect for them.\n\n### Home network\nThis kinda just happened organically, but I have a lot of computers in my house now! What I'd like to do is centralize a bunch of things into a proper rack. I have a few computers that are mining cryptocurrency that I'd like to transfer to rack-mountable server cases. Along with my new Synology NAS and a few Raspberry Pis.\n\nWiring my house with Cat-6 probably won't happen any time soon, but centralizing a bunch of things in a rack will let me hard-wire them all to a small switch without needing to run cables through all my walls.\n\nLike I mentioned above, also setting up network storage and remote access for my home network.\n\n## Things I'm interested in but might not get to\n\n### A better static site generator / CMS\nMy website currently is hand-built in Javascript and React with a few plugins that let me render my articles from markdown. There is still a fair amount of manual process to get each markdown file wired up to display as a page and route, but at least I don't need to reformat the article. I can just paste it in from my notes app and then wire it up.\n\nIdeally I'd like to learn a better static site generator to simplify this process even more. I've been thinking of learning [Gatsby](https://www.gatsbyjs.com/) for a while now, but I've just found it a bit cumbersome and hard to get into.\n\nSome alternatives I'm considering learning instead of Gatsby are [Jeckyll](https://jekyllrb.com/) or [Hexo](https://hexo.io/).\n\n### Webhooks\nJust something I'm interested in learning more about.\n\n## End\n\n[@ me on twitter](https://twitter.com/tyreldelaney) if you are learning these same things or you have any tips or resources to share!"},{"title":"AWS Dynamic DNS","slug":"aws-ddns","date":"March 20, 2022","hero":"/images/posts/aws-ddns.jpg","excerpt":"A dynamic DNS is handy if you want to host something or access something on your home network but you don't have a static IP address from your ISP. I built a little dynamic DNS script for AWS Route53 using Node that runs on a Raspberry Pi.","tags":["aws","ddns","node","raspberry-pi","infrastructure"],"id":11,"readTimeInMinutes":5,"content":"\nThis is a Dynamic DNS system built using AWS Route53 and a Node script running on a Raspberry Pi.\n\n![](./aws-ddns.jpg)\n\n## Index\n* [What is a DDNS?](#what-is-a-ddns)\n* [Prerequisites](#prerequisites)\n* [Getting your current IP](#getting-your-current-ip)\n* [Get the IP address from your DNS record to check if it needs to be updated](#get-the-ip-address-from-your-dns-record-to-check-if-it-needs-to-be-updated)\n* [Update IP in DNS record](#update-ip-in-dns-record)\n* [Run the script on a schedule](#run-the-script-on-a-schedule)\n* [Resources](#resources)\n\n## What is a DDNS?\nA dynamic DNS is handy if you want to host or access things on your home network from the internet but you don't have a static IP address from your service provider.\n\nEssentially what it does is update the IP address for a given DNS record to be the current public IP address of the machine running the script.\n\nSo for example, if you want to have a domain name always pointing to your home network, you run this script on a machine within your home network.\n\nLet's say your domain is `example.com`, you could create an A record for `home.example.com` that points to your home network. You could manually check what your current public IP address is and set it in the AWS console. But likely you have a dynamic IP at home, and it may randomly change at any moment, breaking your DNS record.\n\nLet's automate updating it\n\n## Prerequisites\nYou'll need:\n* An AWS account\n\t* With credentials set up in your environment of choice\n* A domain and hosted zone set up in Route53\n* Node installed\n* AWS-SDK node package\n* Some kind of machine running in your network of choice that will be always on so that it can run the script on a regular schedule. I use a Raspberry Pi as it's low power, easy to setup, and tiny.\n\nFirst setup your project. I used NPM to init a new project, then added the `aws-sdk` and `node-fetch` packages. Also add `\"type\": \"module\"` to your _package.json_ so node doesn't yell at you for using `import`.\n\n## Getting your current IP\nThere are many ways to do this. A trivial way that I chose is to use a service provided by AWS [checkip.amazonaws.com](http://checkip.amazonaws.com). Simply fetch that URL and trim the result to get your current public IP address.\n\nIt's probably a good idea to be validating the IP address returned is a valid IPV4 format. I make a simple helper function to validate an IP address\n\n```javascript\nimport fetch from \"node-fetch\";\n\nfunction validateIp(ipString) {\n\tconst re = /^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$/;\n\treturn !!ipString.match(re);\n}\n\nasync function getCurrentIp() {\n\tconsole.log(\"Fetching current ip...\");\n\tconst response = await fetch(\"http://checkip.amazonaws.com/\");\n\tconst ip = (await response.text()).trim();\n\tif (validateIp(ip)) {\n\t\tconsole.log(ip);\n\t\treturn ip;\n\t}\n\tconsole.error(\"Fetching ip failed\");\n\treturn false\n}\n\nasync function main() {\n\tconst ip = await getCurrentIp();\n\tif (!ip) {\n\t\treturn 1;\n\t}\n}\n\nmain();\n```\n\n## Get the IP address from your DNS record to check if it needs to be updated\n\nThis maybe isn't actually necessary. You're really just making a call to save yourself from making a call. But if this script got more complicated this might be a better idea.\n\nCheck out the [AWS Node SDK Docs](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-started-nodejs.html) and the [AWS JavaScript Route53 SDK Docs](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Route53.html) for more details on their usage.\n\nI made a function  `getIpFromDnsRecord` that fetches the current IP address from the A record of the given hostname and hosted zone id.\n\n```javascript\nimport fetch from \"node-fetch\";\nimport AWS from \"aws-sdk\";\n\nconst hostedZoneId = \"GETTHISIDFROMYOURAWSCONSOLE\";\nconst hostname = \"home.yourdomain.com\";\n\nconst route53 = new AWS.Route53({ apiVersion: \"2013-04-01\" });\n\nfunction validateIp(ipString) {\n\tconst re = /^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$/;\n\treturn !!ipString.match(re);\n}\n\nasync function getIpFromDnsRecord() {\n\tconsole.log(`Fetching ip currently set for ${hostname}...`);\n\tconst params = {\n\t\tHostedZoneId: hostedZoneId,\n\t\tStartRecordName: hostname,\n\t\tStartRecordType: \"A\",\n\t\tMaxItems: \"2\"\n\t}\n\tconst recordSets = await route53.listResourceRecordSets(params).promise()\n\tfor (let record of recordSets[\"ResourceRecordSets\"]) {\n\t\tif (record[\"Name\"] == hostname + \".\") {\n\t\t\tif (record[\"ResourceRecords\"].length == 1) {\n\t\t\t\tconst ip = record[\"ResourceRecords\"][0][\"Value\"].trim();\n\t\t\t\tif (validateIp(ip)) {\n\t\t\t\t\tconsole.log(ip);\n\t\t\t\t\treturn ip;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tconsole.error(`Fetching ip for hostname ${hostname} failed`)\n\treturn false;\n}\n\nasync function getCurrentIp() {\n\tconsole.log(\"Fetching current ip...\");\n\tconst response = await fetch(\"http://checkip.amazonaws.com/\");\n\tconst ip = (await response.text()).trim();\n\tif (validateIp(ip)) {\n\t\tconsole.log(ip);\n\t\treturn ip;\n\t}\n\tconsole.error(\"Fetching ip failed\");\n\treturn false\n}\n\nasync function main() {\n\tconst ip = await getCurrentIp();\n\tif (!ip) {\n\t\treturn 1;\n\t}\n\n\tconst previousIp = await getIpFromDnsRecord();\n\tif (!previousIp) {\n\t\treturn 1;\n\t}\n\n\tif (ip == previousIp) {\n\t\tconsole.log(\"Ip hasn't changed. No action required\")\n\t} else {\n\t\tconsole.log(\"Ip address has changed!\")\n\t}\n\t\n\treturn 0;\n}\n\nmain();\n```\n\n## Update IP in DNS record\nIf the current public IP address is different than the one set in your DNS record, you'll want to update it!\n\nI made a function `setIpInDnsRecord(ip)` that will update the DNS record in Route53.\n\n```javascript\nimport fetch from \"node-fetch\";\nimport AWS from \"aws-sdk\";\n\nconst hostedZoneId = \"GETTHISIDFROMYOURAWSCONSOLE\";\nconst hostname = \"home.yourdomain.com\";\n\nconst route53 = new AWS.Route53({ apiVersion: \"2013-04-01\" });\n\nfunction validateIp(ipString) {\n\tconst re = /^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$/;\n\treturn !!ipString.match(re);\n}\n\nasync function setIpInDnsRecord(ip) {\n\tconsole.log(`Updating DNS record for ${hostname} to ${ip}...`);\n\tconst date = new Date();\n\tconst params = {\n\t\tChangeBatch: {\n\t\t\tChanges: [{\n\t\t\t\tAction: \"UPSERT\", // this will update an existing record\n\t\t\t\tResourceRecordSet: {\n\t\t\t\t\tName: hostname,\n\t\t\t\t\tResourceRecords: [\n\t\t\t\t\t\t{ Value: ip }\n\t\t\t\t\t],\n\t\t\t\t\tTTL: 300,\n\t\t\t\t\tType: \"A\"\n\t\t\t\t}\n\t\t\t}],\n\t\t\tComment: `Updated IP address on ${date.toString()}`\n\t\t},\n\t\tHostedZoneId: hostedZoneId\n\t};\n\tconst response = await route53.changeResourceRecordSets(params).promise();\n\t// missing any error handling\n\tconsole.log(`DNS record for ${hostname} updated to ${ip}. Can take up to 60s to propogate`);\n}\n\nasync function getIpFromDnsRecord() {\n\tconsole.log(`Fetching ip currently set for ${hostname}...`);\n\tconst params = {\n\t\tHostedZoneId: hostedZoneId,\n\t\tStartRecordName: hostname,\n\t\tStartRecordType: \"A\",\n\t\tMaxItems: \"2\"\n\t}\n\tconst recordSets = await route53.listResourceRecordSets(params).promise()\n\tfor (let record of recordSets[\"ResourceRecordSets\"]) {\n\t\tif (record[\"Name\"] == hostname + \".\") {\n\t\t\tif (record[\"ResourceRecords\"].length == 1) {\n\t\t\t\tconst ip = record[\"ResourceRecords\"][0][\"Value\"].trim();\n\t\t\t\tif (validateIp(ip)) {\n\t\t\t\t\tconsole.log(ip);\n\t\t\t\t\treturn ip;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tconsole.error(`Fetching ip for hostname ${hostname} failed`)\n\treturn false;\n}\n\nasync function getCurrentIp() {\n\tconsole.log(\"Fetching current ip...\");\n\tconst response = await fetch(\"http://checkip.amazonaws.com/\");\n\tconst ip = (await response.text()).trim();\n\tif (validateIp(ip)) {\n\t\tconsole.log(ip);\n\t\treturn ip;\n\t}\n\tconsole.error(\"Fetching ip failed\");\n\treturn false\n}\n\nasync function main() {\n\tconst ip = await getCurrentIp();\n\tif (!ip) {\n\t\treturn 1;\n\t}\n\n\tconst previousIp = await getIpFromDnsRecord();\n\tif (!previousIp) {\n\t\treturn 1;\n\t}\n\n\tif (ip == previousIp) {\n\t\tconsole.log(\"Ip hasn't changed. No action required\")\n\t} else {\n\t\tconsole.log(\"Ip address has changed!\")\n\t\tawait setIpInDnsRecord(ip);\n\t}\n\t\n\treturn 0;\n}\n\nmain();\n```\n\nAnd that's about it for the script! You could make this simpler or more complex as you see fit.\n\nTry it out by running the script\n\n```bash\nnode script.js\n```\n\n## Run the script on a schedule\nI am running this on a Raspberry Pi running the Raspberry Pi OS. This should be similar to any Linux environment (I think? ü§∑üèª‚Äç‚ôÇÔ∏è).\n\nI used a cron to schedule the node script. Open your cron schedules with\n```bash\ncrontab -e\n```\n\nAdd a new schedule for your script. Google cron syntax if you're unfamiliar. I set mine to trigger ever 10 minutes.\n\n```crontab\n*/10 * * * * node /home/YOURUSERNAME/path/to/script.js\n```\n\nSave that file with the new entry at the bottom.\n\nNow just restart your machine and the cron should take effect.\n\nAs long as the device remains powered on and running inside your network, your DNS record will remain updated with your current IP address!\n\n## Resources\n*  [AWS Node SDK Docs](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-started-nodejs.html)\n*  [AWS JavaScript Route53 SDK Docs](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Route53.html)\n* [AWS DDNS Example](https://github.com/awslabs/route53-dynamic-dns-with-lambda/blob/master/v1/dynamic_dns_lambda.py)\n* [Crons on Raspberry Pi](https://bc-robotics.com/tutorials/setting-cron-job-raspberry-pi/)\n* [DDNS Example from Anthony Heddings](https://gist.github.com/anthonyheddings/f22967967bbf524ed510c356678b2651)"},{"title":"Node CI/CD Pipeline using GitHub Actions & AWS Elastic Beanstalk","slug":"node-cicd-pipeline","date":"May 30, 2020","hero":"/images/posts/node-cicd-pipeline-hero.png","excerpt":"Here is my journey into creating an automated continuous integration and continuous deployment workflow for a project using GitHub Actions.","tags":["github-actions","cicd","typescript","aws","automation"],"id":6,"readTimeInMinutes":24,"content":"\nHere is my journey into creating an automated workflow to test, build, and deploy a project I have been working on using Github Actions and Elastic Beanstalk.\n\n![Github Actions logo with colourful background and text that says GitHub Actions now with built-in CI/CD](node-cicd-pipeline-hero.png)\n\n## Tl;dr\n* [Background](#background-on-the-project): I was converting a JavaScript project to TypeScript and I decided to set up continuous integration and continuous deployment at the same time using [Github Actions](https://github.com/features/actions).\n* [Testing](#testing): I am using [Mocha](https://mochajs.org/) for the first time to run my TypeScript tests.\n* [Automation](#automation): The intention is to create a Github workflow that will test my code, build my project, and deploy it to Elastic Beanstalk automatically whenever I push to the master branch. \n* [Create a new IAM user](#create-a-new-iam-user): First step is to create a new AWS IAM User to automate interactions with AWS.\n* [Save AWS User credentials in Github](#save-aws-user-credentials-in-github): Github provides and encrypted secret store that you can use to securely access 3rd-party credentials within a Github Workflow.\n* [Create a S3 bucket to store deployment artifacts](#create-a-s3-bucket-to-store-deployment-artifacts): Setup a bucket to store our deployment artifacts so they can be easily deployed and archived.\n* [Create an Elastic Beanstalk Application and Environment](#create-an-elastic-beanstalk-application-and-environment): Create an new application and environment that we can deploy our app to.\n* [Create a Workflow file within your repo](#create-a-workflow-file-within-your-repo): Workflows live in your repo in the *.github/workflows/* directory.\n* [Setup the yaml file](#setup-the-yaml-file): Setup your workflow with a trigger and some environment variables for readability and maintainability.\n* [Test job](#test-job): A job that will test our project.\n* [Build job](#build-job): A job to build our code, bundle it in a zip, and push that to AWS S3.\n* [Deploy job](#deploy-job):  A job to deploy our project to Elastic Beanstalk\n* [Testing the workflow](#testing-the-workflow): Push this new workflow file to your master branch and see the workflow in action.\n\n## Background on the project\nI have recently been working on converting my JavaScript [battlesnake](https://play.battlesnake.com/) over to TypeScript. This can be done in a gradual process but I've been finding that difficult to do, so this was more of a tear of the band-aid quickly kind of situation.\n\nI decided that I would use [Deno](https://deno.land/) for this project rather than Node. Deno 1.0 had [just recently come out](https://deno.land/v1) and I was all over that hype train. I really think Deno makes sense in it's core philosophy. It also happens to not only have TypeScript support by default, but the strictest possible TypeScript support is default. This encouraged me to translate my JavaScript to TypeScript properly and to fix some of the wrong design choices I had made over the last two years.\n\nEventually I became frustrated with Deno's, frankly, lack of polish. It isn't a true 1.0 if basic features, like `fetch`, don't work correctly yet. Over the course of around two weeks of using Deno I got to the point where I decided to just take all the TypeScript I had just written and move it back to Node.\n\nHopefully I will have by now put together a small article here about migrating a JavaScript Node project to TypeScript. If not check back soon!\n\n## Testing\nDuring development of my Deno TypeScript battlesnake I actually [already set up automated testing using Github Actions](https://superflux.dev/blog/deno-tests-and-github-actions). That worked really well and Deno's included test runner is really simple and easy to use.\n\nBringing my tests over to Node I used what seems like the most popular option which is [Mocha](https://mochajs.org/). I've never used it before but it seems fine.\n\nI can run my tests with the following command which I entered as a `test` script within my *package.json*:\n\n```bash\nmocha -r ts-node/register src/tests/**/*-test.ts\n```\n\nGreat. So with this in place my project is back to a place where I can run it locally, test it, and build it for deployment to AWS.\n\n## Automation\nBeyond automating testing when pushing to my master branch I decided to give the whole CI/CD pipeline a try. I use AWS Elastic Beanstalk to host my project and up to this point I have always been manually zipping the production build and using the AWS Web Console to manually deploy that to Elastic Beanstalk.\n\nNow I have fully automated the whole process!\n\nUsing Github Actions, whenever I push to my master branch I have 3 jobs that run:\n\n1. The repo is tested with my suite of tests using Mocha\n2. If the tests pass, the project is built, zipped, and pushed to AWS S3\n3. If the tests and build are successful, the zip is deployed to AWS Elastic Beanstalk.\n\nIf this fails at any point I get an email and red warnings on Github notifying me.\n\nGithub actions are powerful and you can do far more complicated things than I am doing. But if this interests you, or lines up with a project you are working on, read on and I'll go over step-by-step how I did this.\n\n## Create a new IAM User\nI decided to create a specific IAM User for Github Actions, and specifically this repo.\n\nLog into you AWS Console using your admin account (you created an admin account right? Try not to use you root account) and navigate to IAM.\n\n![Screenshot of the amazon web services IAM page](node-cicd-pipeline-iam-1.png)\n\nClick on Users and then Add User.\n\nChoose a name that makes sense to you. For example `github-actions-battlesnake-test` makes sense in my case as this user exists to authenticate Github Actions for my Battlesnake project. Be as specific as you would like, the name doesn't matter too much.\n\nAlso choose *programmatic access* as the *access type*. This will allow us to generate an *access key ID* and *secret key* that we will pass to Github Actions so that we can use the AWS CLI.\n\n![Screenshot of the interface for entering a user name and choosing the access type](node-cicd-pipeline-iam-2.png)\n\nThen click *Next: Permissions*.\n\nOn the next screen choose *Attach existing policies directly*. In the future you may want to to create a Group or Role to house these permissions and add this User to that Group or grant them that Role. For now, applying the permissions directly to the User will work fine.\n\nYou want to grant this user permission to use S3 and Elastic Beanstalk. Search for \"s3\" and check the option called *AmazonS3FullAccess*. Next search for \"elasticbeanstalk\" and check the option for\n*AWSElasticBeanstalkFullAccess*. You can probably grant even more granular access than these for this account, but I'll let you sort that out if you like. Double check you have the correct permissions selected and then click *Next: Tags*.\n\n![Screenshot of list of possible permissions showing two selected](node-cicd-pipeline-iam-3.png)\n\nYou can give this User tags if you wish, or leave it blank. Click *Next: Review*.\n\nDouble check that everything looks as you expect and then click *Create user*.\n\nImportant‚ùóThis page shows your new user's *access key ID* and *secret key*. This is private information that you should strive to keep private. Someone who has access to this information has access to use this user and anything you have granted it permission to use.\n\nWe want to save this info as a secret on Github. I would recommend not saving this in any other way as you are likely to forget about it or mishandle it. The keys shown in this article and these screenshots have long been deactivated before this post went live.\n\n![Screenshot of user creation success screen showing the access key ID and secret key](node-cicd-pipeline-iam-4.png)\n\n**While leaving this tab open**, open a new tab and navigate to the Github repo of your project.\n\n## Save AWS User credentials in Github\nNext you want to save these AWS credentials as a Secret on your Github repo. This will allow you to securely access them in your Github Workflow later on.\n\nIn the Github repo of the project you want to automate, click the *Settings* tab near the top right of the page. Choose *Secrets* in the left menu. Then click the *New Secret* button in the upper right.\n\n![Screenshot of Github showing the secret creation screen with text fields for the secret and the name of the secret](node-cicd-pipeline-github-secret-creation.png)\n\nCopy your *access key ID* from the AWS Console tab you have open into the *Value* field. Give it a name that makes sense to you such as *AWS_ACCESS_KEY_ID*. I believe this name just needs to be unique to this repo and not your Github account. Double check that you copied the *access key ID* over correctly and then click *Add secret*.\n\nDo the same for the *secret key*, naming it something like *AWS_SECRET_KEY*. Make sure you double check that you copied the *secret key* over correctly as once we are done with this process these keys are no longer accessible. If you make a mistake somewhere through this key transfer you can invalidate those keys and generate new ones.\n\n![Screenshot of Github showing a list of all saved secrets for this repository](node-cicd-pipeline-github-secrets.png)\n\nThats it for the user creation! Next we want to prepare a couple other resources in AWS.\n\n## Create a S3 bucket to store deployment artifacts\nWe are going to store our deployment artifact in S3 so we can easily deploy it to Elastic Beanstalk. Let's create that bucket now.\n\nIn your AWS Console, navigate to S3. Click the *Create bucket* button.\n\nYou will need to choose a globally unique (or region unique? I can't remember) name for your bucket. The UI will warn you if you need to pick a different name. Call it whatever you like, and make note of the name you choose. Click *Create*.\n\n![Screenshot of AWS console showing s3 bucket creation where you are choosing a name](node-cicd-pipeline-s3.png)\n\n## Create an Elastic Beanstalk Application and Environment\nNext we want to create an Elastic Beanstalk Application. In the AWS Console, navigate to Elastic Beanstalk.\n\nThere are many different states your Elastic Beanstalk Console can be in so it is hard to say exactly where this option is but you want to *Create a new application*.\n\nChoose a name and click *Create*.\n\nNext you want to create an Environment within this Application. With the Application you just created selected, find the option to *Create a new environment*.\n\nChoose *Web server environment* and click *Select*.\n\nChoose a unique *Environment name* and *Domain*. I use this URL for my Battlesnake application so I choose something that is easy to use.\n\n![Screenshot of AWS console showing elastic beanstalk environment creation](node-cicd-pipeline-eb-environment-creation.png)\n\nIn the *Platform* section choose *Node.js* as the platform and leave the other options as their defaults. This will be different if you are running a different software stack or need a specific version of Node.\n\nIn the *Application code* section leave the *Sample application* selected. We will deploy our own application here in soon.\n\nClick *Create environment* after you double check your details are correct.\n\nNow we are done with the AWS setup. The last piece of this is to create a workflow in our repo that outlines the entire Github Action.\n\n## Create a Workflow file within your repo\nGithub Actions work off of [*workflows*](https://help.github.com/en/actions/configuring-and-managing-workflows). *Workflows* are yaml files that live within *.github/workflows/* on your master branch. These yaml files describe the series of actions you want to perform.\n\nThere are a few options for creating your first workflow yaml file. The simplest is to use the Github GUI. You can click the *Actions* tab from within your repo. Find the option that says *Skip this and set up a workflow yourself*. This will present you with a web editor and a skeleton workflow file.\n\n![Screenshot of AWS console showing elastic beanstalk environment creation](node-cicd-pipeline-github-actions-getting-started.png)\n\nThe other option is to just use whatever IDE or text editor you normally use and create a new yaml file in your repo within *.github/workflows/*.\n\nI am going to start from a blank file to describe what each piece means.\n\n## Setup the yaml file\nIf this yaml file gets confusing at all just reference the [Github docs](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions) for the proper syntax.\n\nThe first line of your workflow file is the name of your workflow. Choose a name that describes what this workflow is doing, be as specific as you like.\n\n```yaml\nname: CICD_Pipeline\n```\n\nNext we are going to set up some environment variables to make the rest of this file cleaner and more maintainable. I have seven environment variables total in my workflow. These get placed in the `env` namespace.\n\nThe first two are taken right from AWS Elastic Beanstalk. We want to save the Elastic Beanstalk Application name and Environment name that we created earlier. Make sure these are exactly the same as you used when setting up the Application and Environment.\n\n```yaml\nEB_APPLICATION: \"Battlesnake\"\nEB_ENVIRONMENT: \"Battlesnake-env\"\n```\n\nNext You want to create a variable for your S3 bucket name.\n\n```yaml\nEB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n```\n\nAdd a variable for the AWS region you are using.\n\n```yaml\nAWS_REGION: \"us-west-2\"\n```\n\nAnd lastly we will add 3 strings that we will use during the build and deploy process. These will use the the latest commit hash from our repo to create unique strings for deployment versioning. The commit hash can be accessed via `${{ github.sha }}`.\n\n```yaml\nEB_VERSION: \"Version-${{ github.sha }}\"\nEB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\nDEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\n```\n\nSo so far we have a name for our workflow and a series of environnement variables that we can use.\n\nNext we want to describe the trigger we want to use to initiate our workflow. This is one of the reasons Github Actions are so powerful as there are so many [different triggers available](https://help.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow#triggering-a-workflow-with-events). We simply want to trigger this action whenever we push to our master branch. You describe your triggers in the `on` namespace like so:\n\n```yaml\non:\n  push:\n    branches: [ master ]\n```\n\nSo putting all this together, our yaml workflow should look something like this so far:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n```\n\n## Test job\nWith the basics of our workflow file setup we can get into the interesting bits. A workflow file can have a series of [*jobs*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobs) that Github can run in parallel or in sequence. For our purposes we are going to have 3 jobs, *test*, *build*, and *deploy*, that we want to run in sequence where each job depends on the previous job succeeding.\n\nThe first job we will create is the *test* job. This will simply run our test suite and report back if tests passed or failed.\n\nJobs are defined in the `jobs` namespace which is essentially a list of jobs, each starting with their name. You don't need to use the `name` keyword. I called this first job `test`.\n\n```yaml\njobs:\n  test:\n```\n\nNow the first piece of a job describes what operating system you want to run this workflow on. [Github has options](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idruns-on) for Ubuntu, MacOS, and Windows. We will use Ubuntu for our workflow.\n\n```yaml\nruns-on: ubuntu-latest\n```\n\nNext we want to describe the [*steps*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idsteps) of this job. This is a list of steps each with a name describing what is being done. A step can be a predefined action that we reference from another repo or could be something like shell command. We can install almost any software we want and use it within our jobs via shell commands.\n\n```yaml\nsteps:\n```\n\nThe first step we want to do is to pull down our code from Github. For this we can use an action provided by Github to handle that easily. `actions` is a [Github owned organization](https://github.com/actions), `checkout` the [repo](https://github.com/actions/checkout) we want to use, and `@v2` is the version tag. By adding this action we now have access to all our code in our repo.\n\n```yaml\n- name: Git clone repo\n  uses: actions/checkout@v2\n```\n\nSince our project uses Node, we want to install that next. We will use another [provided action](https://github.com/actions/setup-node) called `setup-node`. We also specify the Node version that we want to use.\n\n```yaml\n- name: Install node\n  uses: actions/setup-node@v1\n  with:\n    node-version: '12.x'\n```\n\nNext let's install our project dependencies. We can use the `run` command to run `npm` as we would do on any other machine. We will use `npm ci` instead of `npm install` [since we are in an automated environment](https://docs.npmjs.com/cli/ci). It's effectively the same just a bit quicker and cleaner.\n\n```yaml\n- name: Install dependencies\n  run: npm ci\n```\n\nLastly, lets run our tests! Our environment is set up now so all we need to do is run our test command. I have this set up as a `test` script in my *package.json* to run my Mocha tests (`\"test\": \"mocha -r ts-node/register src/tests/**/*-test.ts\"`). So I just need to run `npm run test`. We pass an optional `CI: true` environment variable to ensure tests will fail the job if they throw warnings.\n\n```yaml\n- name: Run tests\n  run: npm run test\n  env:\n    CI: true\n```\n\nPutting this all together our workflow file should look like this:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n\njobs:\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm run test\n        env:\n          CI: true\n```\n\nGreat, that is our first job complete! If you are just looking to automate your tests this is all you really need. But we also want to build and deploy our app, so lets write the `build` job next.\n\n## Build job\nI'll get to the point a little quicker this time and then describe what you are seeing.\n\n```yaml\nbuild:\n  runs-on: ubuntu-latest\n  needs: [test]\n  steps:\n    - name: Git clone repo\n      uses: actions/checkout@v2\n\n    - name: Install node\n      uses: actions/setup-node@v1\n      with:\n        node-version: '12.x'\n\n    - name: Install dependencies\n      run: npm ci\n\n    - name: Build project\n      run: npm run build\n\n    - name: Create zip deployment artifact\n      run: zip -r ${{ env.DEPLOY_ARTIFACT }} build package.json package-lock.json\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Push deploy artifact to S3\n      run: aws s3 cp ${{ env.DEPLOY_ARTIFACT }} s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/\n```\n\nAt the top of this job we use the [*needs*](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idneeds) parameter on the previous `test` job. This is what allows us to run our jobs in sequence each relying on the previous job ending successfully.\n\nNext you can see that the first three steps are identical to the previous job. We checkout our code, install Node, and install our dependencies.\n\nThen we run our build script defined in our *package.json*. Since I am using TypeScript I am using the TypeScript compiler to build my code, so my build script is `\"build\": \"tsc -p .\"`.\n\nNext we use the zip command included with Ubuntu to package our code into a deployment artifact. `-r` in means we want to recurse into directories, `${{ env.DEPLOY_ARTIFACT }}` is the name of the file we are creating that we defined earlier as an environment variable, and lastly we pass the files we want to include. For my deployment I include everything in my *build/* directory as well as my *package.json* and *package-lock.json*. You need to include whatever files you want for your deployment.\n\nFor my deployment I want to store my deploy artifact in AWS S3. In order to push this file to S3 we first need to configure our credentials that we setup earlier with our IAM User and Github Secrets.\n\nThis next step uses an [action](https://github.com/aws-actions/configure-aws-credentials) [provided by AWS](https://github.com/aws-actions). We pass it our `aws-access-key-id` and `aws-secret-access-key` that we stored in our repo's secrets earlier. These are accessed by `${{ secrets.NAME_OF_SECRET }}` where `NAME_OF_SECRET` is what you named it when you created it. We also need to pass the `aws-region` that we set earlier in our environment variables.\n\nLastly, now that our AWS credentials are set up, we can push our deployment artifact up to S3. I believe as part of setting up the AWS credentials that action also installs the AWS CLI for us. So we want to copy our file to S3 using `aws s3 cp` and by passing the name of the file as `${{ env.DEPLOY_ARTIFACT }}` and the location we want to push to as `s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/`. Both the artifact name and bucket name we set earlier as environment variables.\n\n## Deploy job\nNow we have our deployment artifact built and saved to S3. We can write our last job to deploy this package to AWS Elastic Beanstalk.\n\n```yaml\ndeploy:\n  runs-on: ubuntu-latest\n  needs: [build]\n  steps:\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Create new ElasticBeanstalk Application version\n      run: |\n        aws elasticbeanstalk create-application-version \\\n        --application-name ${{ env.EB_APPLICATION }} \\\n        --source-bundle S3Bucket=\"${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}\",S3Key=\"${{ env.DEPLOY_ARTIFACT }}\" \\\n        --version-label ${{ env.EB_VERSION }} \\\n        --description ${{ env.EB_DESCRIPTION }}\n\n    - name: Deploy artifact to ElasticBeanstalk\n      run: |\n        aws elasticbeanstalk update-environment \\\n        --environment-name ${{ env.EB_ENVIRONMENT }} \\\n        --version-label ${{ env.EB_VERSION }}\n```\n\nYou can see at the beginning of this job that it depends on the `build` job. That way it will only start once the build has completed successfully.\n\nThe first step is just copied from the previous job. We are going to use the AWS CLI to deploy our app so we need to set up our credentials again.\n\nThe second step uses the AWS CLI to create a fresh Application version for this deployment. You can see it uses `aws elasticbeanstalk create-application-version` with a few flags. We pass in the `application-name`, `version-label`, and `description` we set earlier as environment variables. We also pass in the `source-bundle` which is the location in S3 that we stored our deployment artifact. Both the name of the bucket and the name of the file (the key) we saved in environment variables as well.\n\nThe last step is to update the environment version in Elastic Beanstalk. We use `aws elasticbeanstalk update-environment` and pass it the `environment-name` and `version-label` that we saved earlier as environment variables.\n\nAnd thats it! The workflow file all together should look something like this:\n\n```yaml\nname: CICD_Pipeline\nenv:\n  EB_APPLICATION: \"Battlesnake\"\n  EB_ENVIRONMENT: \"Battlesnake-env\"\n  EB_DEPLOY_ARTIFACT_S3_BUCKET: \"battlesnake-deployment-artifacts\"\n  AWS_REGION: \"us-west-2\"\n  EB_VERSION: \"Version-${{ github.sha }}\"\n  EB_DESCRIPTION: \"CommitSHA-${{ github.sha }}\"\n  DEPLOY_ARTIFACT: \"battlesnake-${{ github.sha }}.zip\"\non:\n  push:\n    branches: [ master ]\n\njobs:\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm run test\n        env:\n          CI: true\n\n  build:\n    runs-on: ubuntu-latest\n    needs: [test]\n    steps:\n      - name: Git clone repo\n        uses: actions/checkout@v2\n\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: '12.x'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build project\n        run: npm run build\n\n      - name: Create zip deployment artifact\n        run: zip -r ${{ env.DEPLOY_ARTIFACT }} build package.json package-lock.json\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Push deploy artifact to S3\n        run: aws s3 cp ${{ env.DEPLOY_ARTIFACT }} s3://${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}/\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [build]\n    steps:\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Create new ElasticBeanstalk Application version\n        run: |\n          aws elasticbeanstalk create-application-version \\\n          --application-name ${{ env.EB_APPLICATION }} \\\n          --source-bundle S3Bucket=\"${{ env.EB_DEPLOY_ARTIFACT_S3_BUCKET }}\",S3Key=\"${{ env.DEPLOY_ARTIFACT }}\" \\\n          --version-label ${{ env.EB_VERSION }} \\\n          --description ${{ env.EB_DESCRIPTION }}\n\n      - name: Deploy artifact to ElasticBeanstalk\n        run: |\n          aws elasticbeanstalk update-environment \\\n          --environment-name ${{ env.EB_ENVIRONMENT }} \\\n          --version-label ${{ env.EB_VERSION }}\n```\n\n## Testing the workflow\nLet's give it a try and see it in action. If you push this file to your master branch it should trigger the workflow.\n\nIn these screenshots I pushed a change where I removed some logging that I had previously in my workflow since it is triggered based on pushes to master. If for some reason it doesn't trigger when you push the workflow try pushing something else to master after the workflow already exists in master.\n\nYou can then navigate to the *Actions* tab of your repo to see the workflow running.\n\n![Screenshot of the Github Actions interface showing past executions of workflows](node-cicd-pipeline-github-running-actions.png)\n\nYou can click into the running workflow and see the console output of each job and step. If there are any errors along the way you should see some red failure symbols and console output describing what when wrong. If nothing goes wrong you should see green success messages.\n\n![Screenshot of completed Github action showing green check marks on the three jobs indicating they completed successfully](node-cicd-pipeline-github-workflow-success.png)\n\nIf you pop over to your AWS Console you can peek into S3 and see the deployment artifact just uploaded to your bucket.\n\n![Screenshot of AWS S three bucket showing list of successfully uploaded files](node-cicd-pipeline-s3-uploaded-files.png)\n\nAnd if you navigate to Elastic Beanstalk you should see your application running or perhaps in start-up.\n\n![Screenshot of AWS elastic beanstalk showing the running environment just deployed](node-cicd-pipeline-eb-running-environment.png)\n\nSo there you go! If that all went well now you have a completely automated CI/CD pipeline. Every time you push to your master branch your repo will be tested, built, and deployed automatically. You can change the triggers if you like depending on your workflow to instead trigger on pull request or whatever else.\n\nThis workflow is specific for a Node app being deployed to AWS Elastic Beanstalk but it can be adapted to basically any software stack and cloud provider. [Github has many Actions](https://github.com/actions) you can leverage for all kinds of things, and a lot of third parties are creating their own actions for their software as well.\n\nAutomate all the things!"}],"searchIndexJson":"[[\"1\",[2,8,22,20,21]],[\"2\",[2,3,4,10,14,9,22,21,12]],[\"3\",[3,8,22]],[\"4\",[2]],[\"5\",[8]],[\"7\",[8]],[\"10\",[2]],[\"13\",[8]],[\"20\",[2,4,10,14,22,12]],[\"24\",[9]],[\"30\",[8]],[\"40\",[2]],[\"58\",[8]],[\"100\",[2]],[\"135\",[8]],[\"201\",[2,4]],[\"202\",[10,14,12]],[\"240\",[9]],[\"308\",[8]],[\"400\",[2]],[\"580\",[8]],[\"1000\",[2]],[\"2018\",[2,4]],[\"2020\",[10]],[\"2021\",[10]],[\"2022\",[14,12]],[\"2023\",[14]],[\"3080\",[8]],[\"4000\",[2]],[\"5800\",[8]],[\"a\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"aw\",[11,6,12]],[\"aws\",[11,6,12]],[\"d\",[11,18,7,5,16,3,4,1,10,19,6,14,22,20,21,17,15,12,13]],[\"dd\",[11]],[\"ddn\",[11]],[\"ddns\",[11]],[\"n\",[11,18,5,16,4,1,10,19,6,14,22,20,21,17,15,12]],[\"no\",[11,18,5,4,1,10,6,22,17]],[\"nod\",[11,5,6]],[\"node\",[11,5,6]],[\"r\",[11,2,18,7,16,14,8,9,15,12,13]],[\"ra\",[11,14,9]],[\"ras\",[11,14]],[\"rasp\",[11,14]],[\"raspb\",[11,14]],[\"raspbe\",[11,14]],[\"raspber\",[11,14]],[\"raspberr\",[11,14]],[\"raspberry\",[11,14]],[\"p\",[11,2,18,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15]],[\"pi\",[11,3,10,6,14]],[\"i\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"in\",[11,2,18,5,4,1,10,6,14,8,22,20,21,17,15,12,13]],[\"inf\",[11,18,1]],[\"infr\",[11,18]],[\"infra\",[11,18]],[\"infras\",[11,18]],[\"infrast\",[11,18]],[\"infrastr\",[11,18]],[\"infrastru\",[11,18]],[\"infrastruc\",[11,18]],[\"infrastructure\",[11,18]],[\"dy\",[11]],[\"dyn\",[11]],[\"dyna\",[11]],[\"dynam\",[11]],[\"dynami\",[11]],[\"dynamic\",[11]],[\"dn\",[11]],[\"dns\",[11]],[\"is\",[11,2,3,1,10,6,22,21,17,15,12,13]],[\"h\",[11,2,18,3,4,1,10,6,14,8,9,20,21,17,15,12,13]],[\"ha\",[11,18,3,1,14,8,9,17,15,12]],[\"han\",[11,18]],[\"hand\",[11,18]],[\"handy\",[11]],[\"if\",[11]],[\"y\",[11]],[\"yo\",[11]],[\"you\",[11]],[\"w\",[11,2,18,7,5,16,4,1,19,6,14,9,22,20,21,17,15,12,13]],[\"wa\",[11,5,19,9,22]],[\"wan\",[11,5]],[\"want\",[11,5]],[\"t\",[11,2,18,7,5,16,3,4,1,10,19,6,14,8,9,22,20,21,17,15,12,13]],[\"to\",[11,2,7,5,16,3,4,1,10,19,14,9,22,20,21,17,12,13]],[\"ho\",[11,2,10,20,17,13]],[\"hos\",[11]],[\"host\",[11]],[\"s\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"so\",[11,18,5,14,22,17,12,13]],[\"som\",[11,18,5,14,22,17,12]],[\"some\",[11,18,14,22,17,12]],[\"somet\",[11]],[\"someth\",[11]],[\"somethi\",[11]],[\"somethin\",[11]],[\"something\",[11]],[\"o\",[11,2,7,5,3,4,1,10,19,9,22,20,21,17,15,12]],[\"or\",[11,4]],[\"ac\",[11,2,5,6,12,13]],[\"acc\",[11]],[\"acce\",[11]],[\"acces\",[11]],[\"access\",[11]],[\"on\",[11,3,19,22,21,15]],[\"your\",[11]],[\"hom\",[11,2]],[\"home\",[11,2]],[\"ne\",[11,16,19,14,22,20,21,12]],[\"net\",[11]],[\"netw\",[11]],[\"netwo\",[11]],[\"networ\",[11]],[\"network\",[11]],[\"b\",[11,2,18,7,5,16,3,4,1,10,19,6,8,9,20,21,15,13]],[\"bu\",[11,7,16,4,1,8,9,20,21,13]],[\"but\",[11,4,1,13]],[\"do\",[11,22,15,12,13]],[\"don\",[11]],[\"dont\",[11]],[\"hav\",[11,12]],[\"have\",[11,12]],[\"st\",[11,16,3,4,10,19,14,22,20,21,12]],[\"sta\",[11,16,3,4,10,19,22,20,21,12]],[\"stat\",[11,16,3,19,22,20,21,12]],[\"stati\",[11,16,3,19,22,20,21,12]],[\"static\",[11,16,3,19,22,20,21,12]],[\"ip\",[11]],[\"ad\",[11]],[\"add\",[11]],[\"addr\",[11]],[\"addre\",[11]],[\"addres\",[11]],[\"address\",[11]],[\"f\",[11,2,18,7,3,4,1,10,19,6,14,8,9,22,20,21,17,12]],[\"fr\",[11,2,18,3,4,1,10,14,8,9,22,20]],[\"fro\",[11,2,18,3,1,14,8,9,22,20]],[\"from\",[11,18,3,1,14,8,9,22,20]],[\"isp\",[11]],[\"bui\",[11,7,16,1,8,9,20,21]],[\"buil\",[11,7,16,1,8,9,20,21]],[\"built\",[11,7,16,21]],[\"l\",[11,2,18,7,3,4,1,10,19,20,21,17,12]],[\"li\",[11,2,7,4,1,10,19,21,17,12]],[\"lit\",[11,10]],[\"litt\",[11,10]],[\"littl\",[11,10]],[\"little\",[11,10]],[\"sc\",[11,1,20]],[\"scr\",[11,1,20]],[\"scri\",[11]],[\"scrip\",[11]],[\"script\",[11]],[\"fo\",[11,18,7,4,6,14,8,9,22,20,21,17,12]],[\"for\",[11,18,7,4,6,8,9,22,20,21,12]],[\"ro\",[11,2,13]],[\"rou\",[11,2]],[\"rout\",[11]],[\"route\",[11]],[\"route5\",[11]],[\"route53\",[11]],[\"u\",[11,2,7,5,3,4,10,6,8,9,21,17]],[\"us\",[11,7,5,4,6,8,17]],[\"usi\",[11,5,4,6]],[\"usin\",[11,5,4,6]],[\"using\",[11,5,4,6]],[\"th\",[11,2,18,7,5,16,3,4,1,10,19,14,8,9,22,20,21,17,15,12,13]],[\"tha\",[11,2,5,3,19,22,21,17,15,13]],[\"that\",[11,2,3,19,22,21,17,15,13]],[\"ru\",[11,12]],[\"run\",[11,12]],[\"runs\",[11]],[\"py\",[2]],[\"pyt\",[2]],[\"pyth\",[2]],[\"pytho\",[2]],[\"python\",[2]],[\"ai\",[2]],[\"e\",[2,5,16,4,6,8,9,20,17,15,13]],[\"ev\",[2,8,17,15,13]],[\"eve\",[2,17,15,13]],[\"even\",[2,15,13]],[\"event\",[2]],[\"events\",[2]],[\"ba\",[2,5,9]],[\"bat\",[2,5]],[\"batt\",[2,5]],[\"battl\",[2,5]],[\"battle\",[2,5]],[\"battles\",[2,5]],[\"battlesn\",[2,5]],[\"battlesna\",[2,5]],[\"battlesnak\",[2,5]],[\"battlesnake\",[2,5]],[\"pr\",[2,3,4,1,19,6,8,9,20,21,17]],[\"pro\",[2,3,4,1,19,6,8,9,20,21]],[\"prog\",[2,4,1]],[\"progr\",[2,4,1]],[\"progra\",[2,4,1]],[\"program\",[2,4,1]],[\"programm\",[2,4,1]],[\"programmi\",[2,4,1]],[\"programmin\",[2,4,1]],[\"programming\",[2,4,1]],[\"c\",[2,18,7,5,16,4,1,19,6,8,9,20,21,17,15,12,13]],[\"co\",[2,18,5,16,1,6,9,21,15]],[\"com\",[2,1,9,21]],[\"comp\",[2,1,9,21]],[\"compe\",[2]],[\"compet\",[2]],[\"competi\",[2]],[\"competit\",[2]],[\"competiti\",[2]],[\"competitio\",[2]],[\"competition\",[2]],[\"wh\",[2,9,17,15,12,13]],[\"whe\",[2,9]],[\"wher\",[2]],[\"where\",[2]],[\"pa\",[2,18,5,16,1,19,8,9,22,20,21,15]],[\"par\",[2,5,1,8,9,22,20,21,15]],[\"part\",[2,5,1,8,9,22,20,21,15]],[\"parti\",[2]],[\"partic\",[2]],[\"partici\",[2]],[\"particip\",[2]],[\"participa\",[2]],[\"participan\",[2]],[\"participants\",[2]],[\"cr\",[2,6,20,21]],[\"cre\",[2,6,20,21]],[\"crea\",[2,6,20,21]],[\"creat\",[2,6,20,21]],[\"create\",[2,20,21]],[\"an\",[2,18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"se\",[2,7,5,8,9,22,20,21,13]],[\"ser\",[2,20,21]],[\"serv\",[2]],[\"serve\",[2]],[\"server\",[2]],[\"act\",[2,5,6,12,13]],[\"acts\",[2]],[\"as\",[2,18,5,3,10,9,17,13]],[\"the\",[2,18,7,16,4,10,19,14,8,9,22,20,21,17,15]],[\"br\",[2,13]],[\"bra\",[2]],[\"brai\",[2]],[\"brain\",[2]],[\"of\",[2,5,3,10,9,20,21,17,15,12]],[\"sn\",[2]],[\"sna\",[2]],[\"snak\",[2]],[\"snake\",[2]],[\"cl\",[2,19,20,17]],[\"cla\",[2]],[\"clas\",[2]],[\"class\",[2]],[\"classi\",[2]],[\"classic\",[2]],[\"g\",[2,18,5,16,3,4,10,19,6,14,8,9,22,20,21,15,12,13]],[\"ga\",[2,4,10,8,9]],[\"gam\",[2,4,10,8,9]],[\"game\",[2,4,10]],[\"compete\",[2]],[\"roun\",[2]],[\"round\",[2]],[\"rob\",[2]],[\"robi\",[2]],[\"robin\",[2]],[\"tou\",[2]],[\"tour\",[2]],[\"tourn\",[2]],[\"tourna\",[2]],[\"tournam\",[2]],[\"tourname\",[2]],[\"tournamen\",[2]],[\"tournament\",[2]],[\"pl\",[2,17]],[\"pla\",[2]],[\"play\",[2]],[\"playe\",[2]],[\"played\",[2]],[\"ou\",[2,3,20]],[\"out\",[2,20]],[\"liv\",[2,21]],[\"live\",[2,21]],[\"fron\",[2,3]],[\"front\",[2,3]],[\"au\",[2,18,6,13]],[\"aud\",[2]],[\"audi\",[2]],[\"audie\",[2]],[\"audien\",[2]],[\"audienc\",[2]],[\"audience\",[2]],[\"roug\",[2]],[\"rough\",[2]],[\"roughl\",[2]],[\"roughly\",[2]],[\"pe\",[2,17]],[\"peo\",[2]],[\"peop\",[2]],[\"peopl\",[2]],[\"people\",[2]],[\"wi\",[2,18,16,4,1,19,9,21,15]],[\"win\",[2]],[\"winn\",[2]],[\"winne\",[2]],[\"winner\",[2]],[\"ta\",[2,18,10,19,17,15]],[\"tak\",[2,18,10,17]],[\"take\",[2,18]],[\"takes\",[2]],[\"up\",[2,3,4,10,9,17]],[\"bo\",[18,9]],[\"boo\",[18]],[\"book\",[18]],[\"not\",[18,4,1,17]],[\"note\",[18,17]],[\"notes\",[18]],[\"de\",[18,7,5,16,4,1,10,6,14,20,21,17,13]],[\"dev\",[18,7,5,4,10,14,13]],[\"devo\",[18,5,14,13]],[\"devop\",[18,5,14,13]],[\"devops\",[18,5,14,13]],[\"aut\",[18,6,13]],[\"auto\",[18,6,13]],[\"autom\",[18,6,13]],[\"automa\",[18,6,13]],[\"automat\",[18,6,13]],[\"automati\",[18,6,13]],[\"automatio\",[18,6,13]],[\"automation\",[18,6,13]],[\"te\",[18,5,4,13]],[\"tes\",[18,5]],[\"test\",[18,5]],[\"testi\",[18]],[\"testin\",[18]],[\"testing\",[18]],[\"con\",[18,5,16,6,9]],[\"cont\",[18,5,6]],[\"conti\",[18,5,6]],[\"contin\",[18,5,6]],[\"continu\",[18,5,6]],[\"continuo\",[18,5,6]],[\"continuou\",[18,5,6]],[\"continuous\",[18,5,6]],[\"int\",[18,5,10,6,20,21,17,13]],[\"inte\",[18,5,6,21,17,13]],[\"integ\",[18,5,6]],[\"integr\",[18,5,6]],[\"integra\",[18,5,6]],[\"integrat\",[18,5,6]],[\"integrati\",[18,5,6]],[\"integratio\",[18,5,6]],[\"integration\",[18,5,6]],[\"dep\",[18,16,6]],[\"depl\",[18,16,6]],[\"deplo\",[18,16,6]],[\"deploy\",[18,16,6]],[\"deploym\",[18,16,6]],[\"deployme\",[18,16,6]],[\"deploymen\",[18,16,6]],[\"deployment\",[18,16,6]],[\"ci\",[18,5,6,12]],[\"cic\",[18,5,6,12]],[\"cicd\",[18,5,6,12]],[\"cod\",[18]],[\"code\",[18]],[\"gi\",[18,5,16,6,12,13]],[\"git\",[18,5,16,6,12,13]],[\"fe\",[18,20]],[\"fee\",[18]],[\"feed\",[18]],[\"feedb\",[18]],[\"feedba\",[18]],[\"feedbac\",[18]],[\"feedback\",[18]],[\"lo\",[18,3,4,20]],[\"loo\",[18,4,20]],[\"loop\",[18,4]],[\"loops\",[18,4]],[\"le\",[18,10,12]],[\"lea\",[18,10,12]],[\"lear\",[18,10,12]],[\"learn\",[18,10,12]],[\"learni\",[18,10,12]],[\"learnin\",[18,10,12]],[\"learning\",[18,10,12]],[\"handb\",[18]],[\"handbo\",[18]],[\"handboo\",[18]],[\"handbook\",[18]],[\"he\",[18,4,6,14,21,12]],[\"her\",[18,6,14,21,12]],[\"here\",[18,6,14,21,12]],[\"ar\",[18,1,10,19,14,9,20,21]],[\"are\",[18,14,9]],[\"po\",[18,19,22,17]],[\"poi\",[18]],[\"poin\",[18]],[\"point\",[18]],[\"form\",[18,8,9]],[\"takea\",[18]],[\"takeaw\",[18]],[\"takeawa\",[18]],[\"takeaway\",[18]],[\"takeaways\",[18]],[\"m\",[18,7,5,3,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"my\",[18,5,4,1,10,19,6,8,9,22,20,21,17,15,13]],[\"re\",[18,7,16,14,15,13]],[\"rea\",[18,7,16]],[\"read\",[18]],[\"readi\",[18]],[\"readin\",[18]],[\"reading\",[18]],[\"by\",[18,19,9]],[\"j\",[18,7,5,16,3,4,1,19,6,22,20,21,12,13]],[\"jo\",[18,1,6,13]],[\"joh\",[18]],[\"john\",[18]],[\"wil\",[18]],[\"will\",[18]],[\"willi\",[18]],[\"willis\",[18]],[\"ge\",[18,16,4,19,22,20,21,12,13]],[\"gen\",[18,16,4,19,22,20,21,12]],[\"gene\",[18,16,4,19,22,20,21,12]],[\"k\",[18,1,14,12,13]],[\"ki\",[18,1,14]],[\"kim\",[18]],[\"and\",[18,7,5,16,4,1,10,6,14,8,9,20,21,12,13]],[\"pat\",[18]],[\"patr\",[18]],[\"patri\",[18]],[\"patric\",[18]],[\"patrick\",[18]],[\"deb\",[18]],[\"debo\",[18]],[\"deboi\",[18]],[\"debois\",[18]],[\"reac\",[7,16]],[\"react\",[7,16]],[\"da\",[7,17,15,13]],[\"dar\",[7]],[\"dark\",[7]],[\"mo\",[7,10,20,17,13]],[\"mod\",[7]],[\"mode\",[7]],[\"ja\",[7,5,16,4,19,22,20,21]],[\"jav\",[7,5,16,4,19,22,20,21]],[\"java\",[7,5,16,4,19,22,20,21]],[\"javas\",[7,5,16,4,19,22,20,21]],[\"javasc\",[7,5,16,4,19,22,20,21]],[\"javascr\",[7,5,16,4,19,22,20,21]],[\"javascri\",[7,5,16,4,19,22,20,21]],[\"javascrip\",[7,5,16,4,19,22,20,21]],[\"javascript\",[7,5,16,4,19,22,20,21]],[\"we\",[7,19,14,20,21]],[\"web\",[7,19,14,20,21]],[\"webd\",[7,19,14]],[\"webde\",[7,19,14]],[\"webdev\",[7,19,14]],[\"tog\",[7]],[\"togg\",[7]],[\"toggl\",[7]],[\"toggle\",[7]],[\"deve\",[7,10,13]],[\"devel\",[7,10,13]],[\"develo\",[7,10,13]],[\"develop\",[7,10,13]],[\"develope\",[7,13]],[\"developed\",[7]],[\"lig\",[7,4,17]],[\"ligh\",[7,4,17]],[\"light\",[7,4,17]],[\"them\",[7]],[\"theme\",[7]],[\"thi\",[7,4,1,10,19,8,9,22,20,21,17,15,12,13]],[\"this\",[7,4,1,10,19,8,9,22,20,21,17,15,13]],[\"si\",[7,16,19,22,20,21,12]],[\"sit\",[7,16,19,22,20,21,12]],[\"site\",[7,16,19,22,20,21,12]],[\"sw\",[7]],[\"swi\",[7]],[\"swit\",[7]],[\"switc\",[7]],[\"switch\",[7]],[\"be\",[7,3,4,1,10,19,6,20,13]],[\"bet\",[7,4]],[\"betw\",[7]],[\"betwe\",[7]],[\"betwee\",[7]],[\"between\",[7]],[\"al\",[7,19,8,9,22]],[\"als\",[7]],[\"also\",[7]],[\"use\",[7,8,17]],[\"used\",[7]],[\"me\",[7,1,8,15,13]],[\"med\",[7]],[\"medi\",[7]],[\"media\",[7]],[\"q\",[7,21]],[\"qu\",[7,21]],[\"que\",[7]],[\"quer\",[7]],[\"queri\",[7]],[\"querie\",[7]],[\"queries\",[7]],[\"set\",[7,5]],[\"def\",[7]],[\"defa\",[7]],[\"defau\",[7]],[\"defaul\",[7]],[\"default\",[7]],[\"ma\",[7,19,8]],[\"mat\",[7]],[\"matc\",[7]],[\"match\",[7]],[\"v\",[7,4,14,12]],[\"vi\",[7]],[\"vis\",[7]],[\"visi\",[7]],[\"visit\",[7]],[\"visito\",[7]],[\"visitor\",[7]],[\"visitors\",[7]],[\"op\",[7,22,20]],[\"ope\",[7]],[\"oper\",[7]],[\"opera\",[7]],[\"operat\",[7]],[\"operati\",[7]],[\"operatin\",[7]],[\"operating\",[7]],[\"sy\",[7,14,9,17,15,12]],[\"sys\",[7,9]],[\"syst\",[7,9]],[\"syste\",[7,9]],[\"system\",[7,9]],[\"ch\",[7,20]],[\"cho\",[7]],[\"choi\",[7]],[\"choic\",[7]],[\"choice\",[7]],[\"ty\",[5,16,19,6,22,20,21]],[\"typ\",[5,16,19,6,22,20,21]],[\"type\",[5,16,19,6,22,20,21]],[\"types\",[5,16,19,6,22,20,21]],[\"typesc\",[5,16,19,6]],[\"typescr\",[5,16,19,6]],[\"typescri\",[5,16,19,6]],[\"typescrip\",[5,16,19,6]],[\"typescript\",[5,16,19,6]],[\"den\",[5]],[\"deno\",[5]],[\"gith\",[5,16,6,12,13]],[\"githu\",[5,16,6,12,13]],[\"github\",[5,16,6,12,13]],[\"acti\",[5,6,12,13]],[\"actio\",[5,6,12,13]],[\"action\",[5,6,12,13]],[\"actions\",[5,6,12,13]],[\"tests\",[5]],[\"tr\",[5,19,13]],[\"tra\",[5,13]],[\"tran\",[5]],[\"trans\",[5]],[\"transl\",[5]],[\"transla\",[5]],[\"translat\",[5]],[\"translati\",[5]],[\"translatin\",[5]],[\"translating\",[5]],[\"wante\",[5]],[\"wanted\",[5]],[\"setu\",[5]],[\"setup\",[5]],[\"it\",[5,10,9,21,13]],[\"was\",[5,19,22]],[\"mu\",[5]],[\"muc\",[5]],[\"much\",[5]],[\"ea\",[5,16]],[\"eas\",[5,16]],[\"easi\",[5,16]],[\"easie\",[5]],[\"easier\",[5]],[\"than\",[5]],[\"im\",[5,4,19,22,21,12]],[\"ima\",[5]],[\"imag\",[5]],[\"imagi\",[5]],[\"imagin\",[5]],[\"imagine\",[5]],[\"imagined\",[5]],[\"pag\",[16,19]],[\"page\",[16,19]],[\"pages\",[16,19]],[\"nex\",[16,19,14,22,20,21]],[\"next\",[16,19,14,22,20,21]],[\"nextj\",[16,19,14,22,20,21]],[\"nextjs\",[16,19,14,22,20,21]],[\"gener\",[16,4,19,22,20,21,12]],[\"genera\",[16,4,19,22,20,21,12]],[\"generat\",[16,19,22,20,21,12]],[\"generato\",[16,19,22,20,21,12]],[\"generator\",[16,19,22,20,21,12]],[\"generators\",[16,19,22,20,21,12]],[\"cov\",[16,9]],[\"cove\",[16,9]],[\"cover\",[16,9]],[\"conf\",[16]],[\"confi\",[16]],[\"config\",[16]],[\"ste\",[16]],[\"step\",[16]],[\"steps\",[16]],[\"nec\",[16]],[\"nece\",[16]],[\"neces\",[16]],[\"necess\",[16]],[\"necessa\",[16]],[\"necessar\",[16]],[\"necessary\",[16]],[\"easil\",[16]],[\"easily\",[16]],[\"wit\",[16,4,1,19,9,21,15]],[\"with\",[16,4,1,19,9,21,15]],[\"gr\",[3,8]],[\"gra\",[3,8]],[\"grai\",[3]],[\"grail\",[3]],[\"grails\",[3]],[\"mi\",[3,15]],[\"mig\",[3]],[\"migr\",[3]],[\"migra\",[3]],[\"migrat\",[3]],[\"migrati\",[3]],[\"migratin\",[3]],[\"migrating\",[3]],[\"fronte\",[3]],[\"fronten\",[3]],[\"frontend\",[3]],[\"ass\",[3,9]],[\"asse\",[3,9]],[\"asset\",[3]],[\"assets\",[3]],[\"du\",[3]],[\"dur\",[3]],[\"duri\",[3]],[\"durin\",[3]],[\"during\",[3]],[\"upg\",[3,9]],[\"upgr\",[3,9]],[\"upgra\",[3,9]],[\"upgrad\",[3,9]],[\"upgrade\",[3,9]],[\"upgradi\",[3]],[\"upgradin\",[3]],[\"upgrading\",[3]],[\"our\",[3]],[\"ap\",[3]],[\"app\",[3]],[\"appl\",[3]],[\"appli\",[3]],[\"applic\",[3]],[\"applica\",[3]],[\"applicat\",[3]],[\"applicati\",[3]],[\"applicatio\",[3]],[\"application\",[3]],[\"has\",[3]],[\"bee\",[3,13]],[\"been\",[3,13]],[\"lon\",[3]],[\"long\",[3]],[\"proc\",[3,8]],[\"proce\",[3,8]],[\"proces\",[3,8]],[\"process\",[3,8]],[\"ju\",[3,12]],[\"jus\",[3,12]],[\"just\",[3,12]],[\"one\",[3,19,15]],[\"pie\",[3]],[\"piec\",[3]],[\"piece\",[3]],[\"p5\",[4]],[\"p5j\",[4]],[\"p5js\",[4]],[\"lights\",[4]],[\"lightsh\",[4]],[\"lightshi\",[4]],[\"lightshif\",[4]],[\"lightshift\",[4]],[\"star\",[4,10]],[\"start\",[4,10]],[\"starte\",[4,10]],[\"started\",[4,10]],[\"proj\",[4,19,6,20,21]],[\"proje\",[4,19,6,20,21]],[\"projec\",[4,19,6,20,21]],[\"project\",[4,19,6,20,21]],[\"hel\",[4]],[\"help\",[4]],[\"tea\",[4,13]],[\"teac\",[4]],[\"teach\",[4]],[\"mys\",[4,15]],[\"myse\",[4,15]],[\"mysel\",[4,15]],[\"myself\",[4,15]],[\"bett\",[4]],[\"bette\",[4]],[\"better\",[4]],[\"ob\",[4,17]],[\"obj\",[4]],[\"obje\",[4]],[\"objec\",[4]],[\"object\",[4]],[\"ori\",[4]],[\"orie\",[4]],[\"orien\",[4]],[\"orient\",[4]],[\"oriente\",[4]],[\"oriented\",[4]],[\"str\",[4]],[\"stru\",[4]],[\"struc\",[4]],[\"struct\",[4]],[\"structu\",[4]],[\"structur\",[4]],[\"structure\",[4]],[\"upd\",[4]],[\"upda\",[4]],[\"updat\",[4]],[\"update\",[4]],[\"updated\",[4]],[\"updatedr\",[4]],[\"updatedra\",[4]],[\"updatedraw\",[4]],[\"general\",[4]],[\"imp\",[4,22,21]],[\"impl\",[4,22]],[\"imple\",[4,22]],[\"implem\",[4,22]],[\"impleme\",[4,22]],[\"implemen\",[4,22]],[\"implement\",[4,22]],[\"implemente\",[4,22]],[\"implemented\",[4,22]],[\"fra\",[4]],[\"fram\",[4]],[\"frame\",[4]],[\"framew\",[4]],[\"framewo\",[4]],[\"framewor\",[4]],[\"framework\",[4]],[\"dr\",[4]],[\"dra\",[4]],[\"draw\",[4]],[\"ca\",[4,8,13]],[\"can\",[4]],[\"canv\",[4]],[\"canva\",[4]],[\"canvas\",[4]],[\"drawi\",[4]],[\"drawin\",[4]],[\"drawing\",[4]],[\"fu\",[4,9,22,17]],[\"fun\",[4,22,17]],[\"func\",[4,22,17]],[\"funct\",[4,22,17]],[\"functi\",[4,22,17]],[\"functio\",[4,22,17]],[\"function\",[4,22,17]],[\"functiona\",[4,22,17]],[\"functional\",[4,22,17]],[\"functionality\",[4,22,17]],[\"noth\",[4]],[\"nothi\",[4]],[\"nothin\",[4]],[\"nothing\",[4]],[\"el\",[4,6]],[\"els\",[4]],[\"else\",[4]],[\"va\",[4,14]],[\"van\",[4]],[\"vani\",[4]],[\"vanil\",[4]],[\"vanill\",[4]],[\"vanilla\",[4]],[\"mec\",[1]],[\"mech\",[1]],[\"mecha\",[1]],[\"mechan\",[1]],[\"mechani\",[1]],[\"mechanic\",[1]],[\"mechanica\",[1]],[\"mechanical\",[1]],[\"ke\",[1]],[\"key\",[1]],[\"keyb\",[1]],[\"keybo\",[1]],[\"keyboa\",[1]],[\"keyboar\",[1]],[\"keyboard\",[1]],[\"keyboards\",[1]],[\"ard\",[1]],[\"ardu\",[1]],[\"ardui\",[1]],[\"arduin\",[1]],[\"arduino\",[1]],[\"c+\",[1]],[\"c++\",[1]],[\"har\",[1,14,8,9,17,15]],[\"hard\",[1,14,8,9,17,15]],[\"hardw\",[1,14,8,9,17,15]],[\"hardwa\",[1,14,8,9,17,15]],[\"hardwar\",[1,14,8,9,17,15]],[\"hardware\",[1,14,8,9,17,15]],[\"build\",[1,8,9,20,21]],[\"buildi\",[1,21]],[\"buildin\",[1,21]],[\"building\",[1,21]],[\"scra\",[1,20]],[\"scrat\",[1,20]],[\"scratc\",[1,20]],[\"scratch\",[1,20]],[\"af\",[1,20]],[\"aft\",[1,20]],[\"afte\",[1,20]],[\"after\",[1,20]],[\"bec\",[1]],[\"beco\",[1]],[\"becom\",[1]],[\"becomi\",[1]],[\"becomin\",[1]],[\"becoming\",[1]],[\"infa\",[1]],[\"infat\",[1]],[\"infatu\",[1]],[\"infatua\",[1]],[\"infatuat\",[1]],[\"infatuate\",[1]],[\"infatuated\",[1]],[\"cu\",[1,9]],[\"cus\",[1,9]],[\"cust\",[1,9]],[\"custo\",[1,9]],[\"custom\",[1,9]],[\"dec\",[1,20]],[\"deci\",[1,20]],[\"decid\",[1,20]],[\"decide\",[1,20]],[\"decided\",[1,20]],[\"ow\",[1,20,17,15]],[\"own\",[1,20,17,15]],[\"kit\",[1]],[\"lik\",[1,12]],[\"like\",[1,12]],[\"jou\",[1,6]],[\"jour\",[1,6]],[\"journ\",[1,6]],[\"journe\",[1,6]],[\"journey\",[1,6]],[\"thr\",[1]],[\"thro\",[1]],[\"throu\",[1]],[\"throug\",[1]],[\"through\",[1]],[\"des\",[1,21,17]],[\"desi\",[1]],[\"desig\",[1]],[\"design\",[1]],[\"designi\",[1]],[\"designin\",[1]],[\"designing\",[1]],[\"aq\",[1]],[\"aqu\",[1]],[\"aqui\",[1]],[\"aquir\",[1]],[\"aquiri\",[1]],[\"aquirin\",[1]],[\"aquiring\",[1]],[\"parts\",[1,9]],[\"compl\",[1]],[\"comple\",[1]],[\"complet\",[1]],[\"complete\",[1]],[\"la\",[1]],[\"lay\",[1]],[\"layo\",[1]],[\"layou\",[1]],[\"layout\",[1]],[\"designe\",[1]],[\"designed\",[1]],[\"un\",[10]],[\"uni\",[10]],[\"unit\",[10]],[\"unity\",[10]],[\"go\",[10,19,14,15]],[\"god\",[10]],[\"godo\",[10]],[\"godot\",[10]],[\"pix\",[10]],[\"pixe\",[10]],[\"pixel\",[10]],[\"art\",[10,19,20,21]],[\"intr\",[10]],[\"intro\",[10]],[\"introd\",[10]],[\"introdu\",[10]],[\"introduc\",[10]],[\"introduct\",[10]],[\"introducti\",[10]],[\"introduction\",[10]],[\"developm\",[10,13]],[\"developme\",[10,13]],[\"developmen\",[10,13]],[\"development\",[10,13]],[\"beg\",[10]],[\"bega\",[10]],[\"began\",[10]],[\"hob\",[10]],[\"hobb\",[10]],[\"hobby\",[10]],[\"now\",[10,22]],[\"begi\",[10]],[\"begin\",[10]],[\"beginn\",[10]],[\"beginni\",[10]],[\"beginnin\",[10]],[\"beginning\",[10]],[\"taki\",[10,17]],[\"takin\",[10,17]],[\"taking\",[10,17]],[\"mos\",[10]],[\"most\",[10]],[\"fre\",[10]],[\"free\",[10]],[\"ti\",[10,12]],[\"tim\",[10,12]],[\"time\",[10,12]],[\"into\",[10,6,20,21,13]],[\"how\",[10,20,17,13]],[\"got\",[10,14,15]],[\"too\",[10]],[\"tool\",[10]],[\"tools\",[10]],[\"learne\",[10]],[\"learned\",[10]],[\"tag\",[19]],[\"goa\",[19]],[\"goal\",[19]],[\"mak\",[19]],[\"make\",[19]],[\"tags\",[19]],[\"alr\",[19]],[\"alre\",[19]],[\"alrea\",[19]],[\"alread\",[19]],[\"already\",[19]],[\"di\",[19,20]],[\"dis\",[19,20]],[\"disp\",[19]],[\"displ\",[19]],[\"displa\",[19]],[\"display\",[19]],[\"displayi\",[19]],[\"displayin\",[19]],[\"displaying\",[19]],[\"alo\",[19]],[\"alon\",[19]],[\"along\",[19]],[\"alongs\",[19]],[\"alongsi\",[19]],[\"alongsid\",[19]],[\"alongside\",[19]],[\"arti\",[19,20,21]],[\"artic\",[19,20,21]],[\"articl\",[19,20,21]],[\"article\",[19,20,21]],[\"articles\",[19,20,21]],[\"cli\",[19,20]],[\"clic\",[19]],[\"click\",[19]],[\"clicka\",[19]],[\"clickab\",[19]],[\"clickabl\",[19]],[\"clickable\",[19]],[\"lin\",[19]],[\"link\",[19]],[\"links\",[19]],[\"fi\",[19,8,22,20,21]],[\"fil\",[19]],[\"filt\",[19]],[\"filte\",[19]],[\"filter\",[19]],[\"pos\",[19,22,17]],[\"post\",[19,22,17]],[\"posts\",[19,22]],[\"try\",[19]],[\"pip\",[6]],[\"pipe\",[6]],[\"pipel\",[6]],[\"pipeli\",[6]],[\"pipelin\",[6]],[\"pipeline\",[6]],[\"ela\",[6]],[\"elas\",[6]],[\"elast\",[6]],[\"elasti\",[6]],[\"elastic\",[6]],[\"bea\",[6]],[\"bean\",[6]],[\"beans\",[6]],[\"beanst\",[6]],[\"beansta\",[6]],[\"beanstal\",[6]],[\"beanstalk\",[6]],[\"creati\",[6]],[\"creatin\",[6]],[\"creating\",[6]],[\"automate\",[6]],[\"automated\",[6]],[\"wo\",[6,20,12]],[\"wor\",[6]],[\"work\",[6]],[\"workf\",[6]],[\"workfl\",[6]],[\"workflo\",[6]],[\"workflow\",[6]],[\"syn\",[14,17,15,12]],[\"syno\",[14,17,15,12]],[\"synol\",[14,17,15,12]],[\"synolo\",[14,17,15,12]],[\"synolog\",[14,17,15,12]],[\"synology\",[14,17,15,12]],[\"kid\",[14]],[\"kids\",[14]],[\"res\",[14]],[\"reso\",[14]],[\"resou\",[14]],[\"resour\",[14]],[\"resourc\",[14]],[\"resource\",[14]],[\"resources\",[14]],[\"fou\",[14]],[\"foun\",[14]],[\"found\",[14]],[\"val\",[14]],[\"valu\",[14]],[\"valua\",[14]],[\"valuab\",[14]],[\"valuabl\",[14]],[\"valuable\",[14]],[\"resouc\",[14]],[\"resouce\",[14]],[\"resouces\",[14]],[\"value\",[14]],[\"top\",[14]],[\"topi\",[14]],[\"topic\",[14]],[\"topics\",[14]],[\"inc\",[14]],[\"incl\",[14]],[\"inclu\",[14]],[\"includ\",[14]],[\"include\",[14]],[\"stu\",[14]],[\"stuf\",[14]],[\"stuff\",[14]],[\"pc\",[8,9]],[\"gami\",[8,9]],[\"gamin\",[8,9]],[\"gaming\",[8,9]],[\"sm\",[8,9,13]],[\"sma\",[8,9,13]],[\"smal\",[8,9,13]],[\"small\",[8,9,13]],[\"fa\",[8,9]],[\"fac\",[8,9]],[\"fact\",[8,9]],[\"facto\",[8,9]],[\"factor\",[8,9]],[\"fir\",[8,20,21]],[\"firs\",[8,20,21]],[\"first\",[8,20,21]],[\"sec\",[8,9]],[\"seco\",[8,9]],[\"secon\",[8,9]],[\"second\",[8,9]],[\"prop\",[8]],[\"prope\",[8]],[\"proper\",[8]],[\"mac\",[8]],[\"mach\",[8]],[\"machi\",[8]],[\"machin\",[8]],[\"machine\",[8]],[\"uses\",[8]],[\"ry\",[8]],[\"ryz\",[8]],[\"ryze\",[8]],[\"ryzen\",[8]],[\"5800x\",[8]],[\"processo\",[8]],[\"processor\",[8]],[\"evg\",[8]],[\"evga\",[8]],[\"rt\",[8]],[\"rtx\",[8]],[\"x\",[8]],[\"xc\",[8]],[\"xc3\",[8]],[\"ul\",[8]],[\"ult\",[8]],[\"ultr\",[8]],[\"ultra\",[8]],[\"grap\",[8]],[\"graph\",[8]],[\"graphi\",[8]],[\"graphic\",[8]],[\"graphics\",[8]],[\"car\",[8,13]],[\"card\",[8]],[\"all\",[8,9,22]],[\"135l\",[8]],[\"met\",[8]],[\"meta\",[8]],[\"metal\",[8]],[\"metalf\",[8]],[\"metalfi\",[8]],[\"metalfis\",[8]],[\"metalfish\",[8]],[\"s5\",[8]],[\"cas\",[8]],[\"case\",[8]],[\"ali\",[8]],[\"alie\",[8]],[\"aliex\",[8]],[\"aliexp\",[8]],[\"aliexpr\",[8]],[\"aliexpre\",[8]],[\"aliexpres\",[8]],[\"aliexpress\",[8]],[\"wat\",[9]],[\"wate\",[9]],[\"water\",[9]],[\"coo\",[9,15]],[\"cool\",[9,15]],[\"cooli\",[9]],[\"coolin\",[9]],[\"cooling\",[9]],[\"covers\",[9]],[\"ful\",[9]],[\"full\",[9]],[\"bot\",[9]],[\"both\",[9]],[\"cp\",[9]],[\"cpu\",[9]],[\"gp\",[9]],[\"gpu\",[9]],[\"coole\",[9]],[\"cooled\",[9]],[\"240m\",[9]],[\"240mm\",[9]],[\"rad\",[9]],[\"radi\",[9]],[\"radia\",[9]],[\"radiat\",[9]],[\"radiato\",[9]],[\"radiator\",[9]],[\"ek\",[9]],[\"ekw\",[9]],[\"ekwb\",[9]],[\"bar\",[9]],[\"barr\",[9]],[\"barro\",[9]],[\"barrow\",[9]],[\"compo\",[9,21]],[\"compon\",[9,21]],[\"compone\",[9,21]],[\"componen\",[9,21]],[\"component\",[9,21]],[\"components\",[9]],[\"pros\",[9]],[\"cons\",[9]],[\"en\",[9,20]],[\"enc\",[9]],[\"enco\",[9]],[\"encou\",[9]],[\"encoun\",[9]],[\"encount\",[9]],[\"encounte\",[9]],[\"encounter\",[9]],[\"encountere\",[9]],[\"encountered\",[9]],[\"when\",[9]],[\"assem\",[9]],[\"assemb\",[9]],[\"assembl\",[9]],[\"assembli\",[9]],[\"assemblin\",[9]],[\"assembling\",[9]],[\"typese\",[22,20,21]],[\"typesen\",[22,20,21]],[\"typesens\",[22,20,21]],[\"typesense\",[22,20,21]],[\"sea\",[22,20,21]],[\"sear\",[22,20,21]],[\"searc\",[22,20,21]],[\"search\",[22,20,21]],[\"opt\",[22,20]],[\"opti\",[22,20]],[\"optim\",[22]],[\"optimi\",[22]],[\"optimiz\",[22]],[\"optimizi\",[22]],[\"optimizin\",[22]],[\"optimizing\",[22]],[\"ind\",[22,20,21]],[\"inde\",[22,20,21]],[\"index\",[22,20,21]],[\"fin\",[22]],[\"fina\",[22]],[\"final\",[22]],[\"optimiza\",[22]],[\"optimizat\",[22]],[\"optimizati\",[22]],[\"optimizations\",[22]],[\"allu\",[22]],[\"allud\",[22]],[\"allude\",[22]],[\"alluded\",[22]],[\"ab\",[22,15]],[\"abl\",[22]],[\"able\",[22]],[\"get\",[22,13]],[\"ish\",[22]],[\"~\",[22]],[\"~7\",[22]],[\"~70\",[22]],[\"~700\",[22]],[\"~700k\",[22]],[\"~700kb\",[22]],[\"dow\",[22]],[\"down\",[22]],[\"~2\",[22]],[\"~22\",[22]],[\"~22k\",[22]],[\"~22kb\",[22]],[\"pre\",[20,17]],[\"prep\",[20]],[\"prepr\",[20]],[\"prepro\",[20]],[\"preproc\",[20]],[\"preproce\",[20]],[\"preproces\",[20]],[\"preprocess\",[20]],[\"preprocessing\",[20]],[\"seri\",[20,21]],[\"serie\",[20,21]],[\"series\",[20,21]],[\"disc\",[20]],[\"discu\",[20]],[\"discus\",[20]],[\"discuss\",[20]],[\"created\",[20]],[\"clie\",[20]],[\"clien\",[20]],[\"client\",[20]],[\"sid\",[20]],[\"side\",[20]],[\"webs\",[20,21]],[\"websi\",[20,21]],[\"websit\",[20,21]],[\"website\",[20,21]],[\"look\",[20]],[\"looki\",[20]],[\"lookin\",[20]],[\"looking\",[20]],[\"at\",[20,13]],[\"few\",[20]],[\"optio\",[20]],[\"option\",[20]],[\"options\",[20]],[\"ther\",[20]],[\"there\",[20]],[\"sites\",[20]],[\"projects\",[20]],[\"cha\",[20]],[\"chal\",[20]],[\"chall\",[20]],[\"challe\",[20]],[\"challen\",[20]],[\"challeng\",[20]],[\"challenge\",[20]],[\"wou\",[20]],[\"woul\",[20]],[\"would\",[20]],[\"mor\",[20,17,13]],[\"more\",[20,17,13]],[\"enj\",[20]],[\"enjo\",[20]],[\"enjoy\",[20]],[\"enjoya\",[20]],[\"enjoyab\",[20]],[\"enjoyabl\",[20]],[\"enjoyable\",[20]],[\"discusse\",[20]],[\"discusses\",[20]],[\"fol\",[21,17]],[\"foll\",[21,17]],[\"follo\",[21,17]],[\"follow\",[21,17]],[\"followu\",[21]],[\"followup\",[21]],[\"qui\",[21]],[\"quic\",[21]],[\"quick\",[21]],[\"searchi\",[21]],[\"searchin\",[21]],[\"searching\",[21]],[\"il\",[21,15]],[\"ill\",[21,15]],[\"impo\",[21]],[\"impor\",[21]],[\"import\",[21]],[\"ui\",[21]],[\"inter\",[21,17,13]],[\"intera\",[21]],[\"interac\",[21]],[\"interact\",[21]],[\"desc\",[21,17]],[\"descr\",[21,17]],[\"descri\",[21,17]],[\"describ\",[21,17]],[\"describe\",[21,17]],[\"described\",[21]],[\"na\",[17,15]],[\"nas\",[17,15]],[\"dat\",[17,15]],[\"data\",[17,15]],[\"owne\",[17,15]],[\"owner\",[17,15]],[\"owners\",[17,15]],[\"ownersh\",[17,15]],[\"ownershi\",[17,15]],[\"ownership\",[17,15]],[\"ph\",[17]],[\"pho\",[17]],[\"phot\",[17]],[\"photo\",[17]],[\"photos\",[17]],[\"obs\",[17]],[\"obsi\",[17]],[\"obsid\",[17]],[\"obsidi\",[17]],[\"obsidia\",[17]],[\"obsidian\",[17]],[\"ple\",[17]],[\"plex\",[17]],[\"lightr\",[17]],[\"lightro\",[17]],[\"lightroo\",[17]],[\"lightroom\",[17]],[\"per\",[17]],[\"pers\",[17]],[\"perso\",[17]],[\"person\",[17]],[\"persona\",[17]],[\"personal\",[17]],[\"clo\",[17]],[\"clou\",[17]],[\"cloud\",[17]],[\"prev\",[17]],[\"previ\",[17]],[\"previo\",[17]],[\"previou\",[17]],[\"previous\",[17]],[\"describi\",[17]],[\"describin\",[17]],[\"describing\",[17]],[\"wha\",[17,15,12,13]],[\"what\",[17,15,12,13]],[\"intere\",[17,13]],[\"interes\",[17,13]],[\"interest\",[17,13]],[\"interesti\",[17]],[\"interestin\",[17]],[\"interesting\",[17]],[\"ever\",[17]],[\"every\",[17]],[\"day\",[17,13]],[\"rec\",[15]],[\"rece\",[15]],[\"recen\",[15]],[\"recent\",[15]],[\"recentl\",[15]],[\"recently\",[15]],[\"doe\",[15,13]],[\"does\",[15,13]],[\"mea\",[15,13]],[\"mean\",[15,13]],[\"tw\",[15]],[\"two\",[15]],[\"tal\",[15]],[\"talk\",[15]],[\"bi\",[15]],[\"bit\",[15]],[\"abo\",[15]],[\"abou\",[15]],[\"about\",[15]],[\"thin\",[15,12]],[\"thing\",[15,12]],[\"things\",[15,12]],[\"min\",[15]],[\"mine\",[15]],[\"doc\",[12]],[\"dock\",[12]],[\"docke\",[12]],[\"docker\",[12]],[\"neo\",[12]],[\"neov\",[12]],[\"neovi\",[12]],[\"neovim\",[12]],[\"vp\",[12]],[\"vpn\",[12]],[\"ss\",[12]],[\"ssl\",[12]],[\"rund\",[12]],[\"rundo\",[12]],[\"rundow\",[12]],[\"rundown\",[12]],[\"id\",[12]],[\"kn\",[12,13]],[\"kno\",[12,13]],[\"know\",[12,13]],[\"won\",[12]],[\"wont\",[12]],[\"rol\",[13]],[\"role\",[13]],[\"sof\",[13]],[\"soft\",[13]],[\"softw\",[13]],[\"softwa\",[13]],[\"softwar\",[13]],[\"software\",[13]],[\"developer\",[13]],[\"job\",[13]],[\"i‚Äô\",[13]],[\"i‚Äôv\",[13]],[\"i‚Äôve\",[13]],[\"gett\",[13]],[\"getti\",[13]],[\"gettin\",[13]],[\"getting\",[13]],[\"intereste\",[13]],[\"interested\",[13]],[\"care\",[13]],[\"caree\",[13]],[\"career\",[13]],[\"traj\",[13]],[\"traje\",[13]],[\"trajec\",[13]],[\"traject\",[13]],[\"trajecto\",[13]],[\"trajector\",[13]],[\"trajectory\",[13]],[\"bri\",[13]],[\"brie\",[13]],[\"brief\",[13]],[\"ex\",[13]],[\"exp\",[13]],[\"expl\",[13]],[\"explo\",[13]],[\"explor\",[13]],[\"explora\",[13]],[\"explorat\",[13]],[\"explorati\",[13]],[\"exploratio\",[13]],[\"exploration\",[13]],[\"see\",[13]],[\"rel\",[13]],[\"rela\",[13]],[\"relat\",[13]],[\"relati\",[13]],[\"relatin\",[13]],[\"relating\",[13]],[\"team\",[13]]]","postMetadataList":[{"title":"AWS Dynamic DNS","slug":"aws-ddns","date":"March 20, 2022","hero":"/images/posts/aws-ddns.jpg","excerpt":"A dynamic DNS is handy if you want to host something or access something on your home network but you don't have a static IP address from your ISP. I built a little dynamic DNS script for AWS Route53 using Node that runs on a Raspberry Pi.","tags":["aws","ddns","node","raspberry-pi","infrastructure"],"id":11,"readTimeInMinutes":5},{"title":"Battlesnake Programming Competition 2018","slug":"battlesnake-2018","date":"June 11, 2018","hero":"/images/posts/Battlesnake2018-1.jpg","excerpt":"Battlesnake is a programming competition where participants create an AI server that acts as the brain of a snake in the classic game Snake. Participants compete in a round-robin tournament played out live in front of an audience of roughly 1000 people. The winner takes home up to $4,000!","tags":["python","ai","events","battlesnake"],"id":2,"readTimeInMinutes":18},{"title":"Book Notes: DevOps Handbook, The","slug":"book-notes-devops-handbook","date":"August 27, 2023","hero":"/images/posts/devopshandbook.png","excerpt":"Here are some point-form takeaways from my notes from reading The DevOps Handbook by John Willis, Gene Kim, and Patrick Debois.","tags":["book-notes","devops","automation","testing","continuous-integration","continuous-deployment","cicd","infrastructure","infrastructure-as-code","git","feedback-loops","continuous-learning"],"id":18,"readTimeInMinutes":8},{"title":"Dark Mode React Toggle","slug":"dark-mode-react-toggle","date":"June 28, 2020","hero":"/images/posts/DarkModeToggle-1.svg","excerpt":"I developed a dark and light theme for this site and built a toggle to switch between them. Also I used media queries to set the default theme to match the visitors operating system choice.","tags":["react","dark-mode","javascript","webdev"],"id":7,"readTimeInMinutes":6},{"title":"Deno Tests & GitHub Actions CI","slug":"deno-and-github-actions","date":"May 23, 2020","hero":"/images/posts/DenoTestsAndGithubActionsCI.png","excerpt":"As part of translating my JavaScript and Node Battlesnake to TypeScript and Deno I wanted to setup continuous integration. It was som much easier than I imagined using GitHub Actions.","tags":["javascript","typescript","node","deno","github-actions","cicd","devops"],"id":5,"readTimeInMinutes":6},{"title":"Deploy a Next.js Static Site to GitHub Pages","slug":"github-pages-using-nextjs","date":"July 23, 2023","hero":"/images/posts/NextJSGitHubPagesHero.png","excerpt":"I cover the config and deployment steps necessary to easily deploy a static site built with Next.js to GitHub Pages.","tags":["github-pages","nextjs","react","static-site-generators","typescript","javascript"],"id":16,"readTimeInMinutes":8},{"title":"Migrating Frontend Assets During Grails 2 ‚Üí 3 Upgrade","slug":"grails-asset-migration","date":"Dec 15, 2019","hero":"/images/posts/GrailsAssetMigration.svg","excerpt":"Upgrading our application from Grails 2 to Grails 3 has been a long process. Migrating our static frontend assets is just one piece of that process.","tags":["grails"],"id":3,"readTimeInMinutes":4},{"title":"Lightshift Game","slug":"lightshift-game","date":"Feb 1, 2020","hero":"/images/posts/lightshift-game-2.png","excerpt":"I started this project in 2018 to help teach myself better object-oriented programming structure, game update/draw loops, and JavaScript in general. Implemented using the P5.js framework for the draw loop and canvas drawing functionality with nothing else but vanilla JavaScript.","tags":["javascript","game-dev","p5js"],"id":4,"readTimeInMinutes":1},{"title":"Building a Mechanical Keyboard from Scratch","slug":"mechanical-keyboard","date":"Apr 20, 2017","hero":"/images/posts/MechanicalKeyboard-12.jpg","excerpt":"After becoming infatuated with custom mechanical keyboards I decided to build my own. Not from a kit, but like from scratch. This is my journey through designing, aquiring parts, building, and programming my own mechanical keyboard complete with a custom layout I designed.","tags":["mechanical-keyboards","arduino","c++","hardware"],"id":1,"readTimeInMinutes":17},{"title":"My Introduction to Game Development","slug":"my-introduction-to-game-development","date":"Mar 25, 2021","hero":"/images/posts/game-dev-godot.jpg","excerpt":"In 2020 I began learning game development as a hobby. Now in the beginning of 2021 it is taking up most of my free time. This is a little intro into how I got started and the tools I learned","tags":["game-dev","unity","godot","pixel-art"],"id":10,"readTimeInMinutes":8},{"title":"Next.js Tag Pages","slug":"nextjs-tag-pages","date":"March 25, 2024","hero":"/images/posts/tag-page-screenshot.png","excerpt":"My goal with this project was to make the tags I'm already displaying alongside articles to be clickable links that filter my posts by that tag. Try to click one!","tags":["nextjs","javascript","typescript","webdev","static-site-generators"],"id":19,"readTimeInMinutes":6},{"title":"Node CI/CD Pipeline using GitHub Actions & AWS Elastic Beanstalk","slug":"node-cicd-pipeline","date":"May 30, 2020","hero":"/images/posts/node-cicd-pipeline-hero.png","excerpt":"Here is my journey into creating an automated continuous integration and continuous deployment workflow for a project using GitHub Actions.","tags":["github-actions","cicd","typescript","aws","automation"],"id":6,"readTimeInMinutes":24},{"title":"Resources I Found Valuable in 2022","slug":"resources-2022","date":"Jan 20 2023","hero":"/images/posts/resources-2022-hero.jpg","excerpt":"Here are the resouces I got value from in 2023. Topics include kids, devops, web dev, and some hardware stuff.","tags":["devops","nextjs","hardware","raspberry-pi","synology","kids","webdev"],"id":14,"readTimeInMinutes":2},{"title":"Small Form Factor PC Build Part 1","slug":"sff-pc-part-1","date":"Jan 2 2021","hero":"/images/posts/sff-pc-part-1-5.jpg","excerpt":"My first small form factor gaming PC and my second proper gaming PC. This machine uses a Ryzen 7 5800X processor and a EVGA RTX 3080 XC3 Ultra graphics card, all in the 13.5L Metalfish S5 case from AliExpress.","tags":["pc","gaming","hardware"],"id":8,"readTimeInMinutes":5},{"title":"Small Form Factor PC Part 2 - Water Cooling","slug":"sff-pc-part-2","date":"Jan 25 2021","hero":"/images/posts/sff-pc-part-2-6.jpeg","excerpt":"This second part of my small form factor gaming PC build covers my upgrade to a full custom water cooling system. Both the CPU and GPU are cooled by a 240mm radiator with parts from EKWB and Barrow. I cover all of the components and all the pros and cons I encountered when assembling it.","tags":["pc","gaming","hardware"],"id":9,"readTimeInMinutes":29},{"title":"Static Site Search Part 3 - Optimizing the Index","slug":"static-site-search-optimizing-the-index","date":"April 18, 2024","hero":"/images/posts/static-site-search-optimizing-the-index.jpg","excerpt":"This is the final part (for now) on the search functionality for my site. I implemented some optimizations that I alluded to in part 1 & 2. I was able to get my search index for my 20-ish posts from ~700kb down to ~22kb!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":22,"readTimeInMinutes":8},{"title":"Static Site Search Part 1 - Preprocessing Articles","slug":"static-site-search-preprocessing-articles","date":"April 3, 2024","hero":"/images/posts/static-site-search-preprocessing-articles.jpg","excerpt":"In this series of articles I discuss how I created a client-side search for my static website. After looking at a few options out there for static sites and Next.js projects, I decided the challenge to build my own search from scratch would be more enjoyable. This first article discusses how I preprocess my articles into a search index.","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":20,"readTimeInMinutes":15},{"title":"Static Site Search Part 2 - Search Component","slug":"static-site-search-search-component","date":"April 10, 2024","hero":"/images/posts/static-site-search-search-component.jpg","excerpt":"This is the followup to Part 1 in this series on building a Static Site Search for my website. In the first part I built a search index of my articles for quick searching. In this part I'll import that search index into my Next project and create a UI to interact with it. The search component described here is live on this site!","tags":["static-site-generators","nextjs","javascript","typesense","search"],"id":21,"readTimeInMinutes":7},{"title":"How I use my Synology NAS as my personal cloud","slug":"synology-nas-how-i-use-it-as-my-personal-cloud","date":"August 15, 2023","hero":"/images/posts/synology-dsm-desktop.png","excerpt":"This is a follow-up to my previous post describing what a Synology NAS is. In this post I describe some of the more interesting functionality that I use every day.","tags":["synology","nas","data-ownership","hardware","photos","note-taking","obsidian","plex","lightroom"],"id":17,"readTimeInMinutes":10},{"title":"What is a Synology NAS?","slug":"synology-nas-what-is-it","date":"July 18, 2023","hero":"/images/posts/synology-nas.png","excerpt":"I recently got myself a Synology NAS. What does that even mean? In this part one of two, I talk a bit about what a Synology NAS is. In part two, I'll talk about the cool things I do with mine.","tags":["synology","nas","data-ownership","hardware"],"id":15,"readTimeInMinutes":3},{"title":"What I'm Learning in 2022","slug":"what-im-learning-in-2022","date":"March 23, 2022","hero":"/images/posts/what-im-learning-in-2022.jpg","excerpt":"Here is a rundown of what I'm learning in 2022, what I'd like to learn in 2022, and some things I know I just wont have time for in 2022.","tags":["docker","github-actions","neovim","vpn","synology","ssl","static-site-generators","cicd","aws"],"id":12,"readTimeInMinutes":5},{"title":"What is DevOps?","slug":"what-is-devops","date":"April 10, 2022","hero":"/images/posts/development-cycle.jpg","excerpt":"In my role as a software developer at my day job, I‚Äôve been getting more interested in DevOps as a career trajectory. But what does that even mean? Do I even know? This is a brief exploration into what DevOps is and how I see it relating to a small development team.","tags":["devops","automation","github-actions"],"id":13,"readTimeInMinutes":7}]},"__N_SSG":true}